{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>696.0</td>\n",
       "      <td>65.440519</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.703359</td>\n",
       "      <td>-0.246387</td>\n",
       "      <td>...</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>696.0</td>\n",
       "      <td>65.707979</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.699256</td>\n",
       "      <td>-0.277091</td>\n",
       "      <td>783.821985</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>691.0</td>\n",
       "      <td>47.300458</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.884010</td>\n",
       "      <td>-0.332635</td>\n",
       "      <td>...</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>691.0</td>\n",
       "      <td>47.483330</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.894198</td>\n",
       "      <td>-0.355280</td>\n",
       "      <td>380.188159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1096.250000</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>8.150920</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.156675</td>\n",
       "      <td>-0.642487</td>\n",
       "      <td>...</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>8.426150</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.160466</td>\n",
       "      <td>-0.801230</td>\n",
       "      <td>808.359965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1169.714286</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>4.463000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.642283</td>\n",
       "      <td>-0.722722</td>\n",
       "      <td>...</td>\n",
       "      <td>1169.428571</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>4.237828</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.827427</td>\n",
       "      <td>-0.140248</td>\n",
       "      <td>1150.133430</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>585.333333</td>\n",
       "      <td>586.0</td>\n",
       "      <td>2.890598</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.196283</td>\n",
       "      <td>0.113400</td>\n",
       "      <td>...</td>\n",
       "      <td>585.333333</td>\n",
       "      <td>586.0</td>\n",
       "      <td>3.155243</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.354663</td>\n",
       "      <td>-0.484056</td>\n",
       "      <td>198.042444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8343</th>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>619.466667</td>\n",
       "      <td>592.0</td>\n",
       "      <td>139.659522</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.480046</td>\n",
       "      <td>-0.842798</td>\n",
       "      <td>...</td>\n",
       "      <td>619.466667</td>\n",
       "      <td>594.0</td>\n",
       "      <td>139.562109</td>\n",
       "      <td>482.0</td>\n",
       "      <td>0.472791</td>\n",
       "      <td>-0.825913</td>\n",
       "      <td>468.155165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8344</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>510.777778</td>\n",
       "      <td>512.0</td>\n",
       "      <td>7.091118</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-0.059891</td>\n",
       "      <td>-0.269851</td>\n",
       "      <td>...</td>\n",
       "      <td>510.888889</td>\n",
       "      <td>512.0</td>\n",
       "      <td>6.870944</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.081059</td>\n",
       "      <td>-0.433829</td>\n",
       "      <td>309.210006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8345</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1090.250000</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>9.769212</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.213875</td>\n",
       "      <td>-1.152589</td>\n",
       "      <td>...</td>\n",
       "      <td>1090.250000</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>8.742854</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.436427</td>\n",
       "      <td>-0.891096</td>\n",
       "      <td>940.155678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8346</th>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>370.320000</td>\n",
       "      <td>370.0</td>\n",
       "      <td>3.133305</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.358316</td>\n",
       "      <td>-0.885061</td>\n",
       "      <td>...</td>\n",
       "      <td>370.400000</td>\n",
       "      <td>370.0</td>\n",
       "      <td>3.098387</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.051640</td>\n",
       "      <td>-0.703333</td>\n",
       "      <td>856.813033</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8347</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1037.000000</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>28.372522</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-0.267952</td>\n",
       "      <td>-0.810638</td>\n",
       "      <td>...</td>\n",
       "      <td>1037.000000</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>28.705400</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-0.237050</td>\n",
       "      <td>-0.876580</td>\n",
       "      <td>495.494523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8348 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1    2     3            4       5           6      7         8  \\\n",
       "0     0.0  87.0  1.0  14.0   712.000000   696.0   65.440519  240.0  0.703359   \n",
       "1     2.0  49.0  1.0  13.0   712.000000   691.0   47.300458  158.0  0.884010   \n",
       "2     1.0  86.0  1.0   9.0  1096.250000  1098.0    8.150920   28.0 -0.156675   \n",
       "3     1.0  70.0  1.0   8.0  1169.714286  1168.0    4.463000   14.0  0.642283   \n",
       "4     3.0  61.0  0.0  16.0   585.333333   586.0    2.890598   12.0  0.196283   \n",
       "...   ...   ...  ...   ...          ...     ...         ...    ...       ...   \n",
       "8343  0.0  72.0  1.0  16.0   619.466667   592.0  139.659522  480.0  0.480046   \n",
       "8344  3.0  23.0  0.0  19.0   510.777778   512.0    7.091118   30.0 -0.059891   \n",
       "8345  1.0  51.0  0.0   9.0  1090.250000  1088.0    9.769212   30.0  0.213875   \n",
       "8346  3.0  45.0  0.0  26.0   370.320000   370.0    3.133305   10.0  0.358316   \n",
       "8347  1.0  28.0  1.0   9.0  1037.000000  1037.0   28.372522   94.0 -0.267952   \n",
       "\n",
       "             9  ...          114     115         116    117       118  \\\n",
       "0    -0.246387  ...   712.000000   696.0   65.707979  240.0  0.699256   \n",
       "1    -0.332635  ...   712.000000   691.0   47.483330  156.0  0.894198   \n",
       "2    -0.642487  ...  1096.000000  1098.0    8.426150   28.0 -0.160466   \n",
       "3    -0.722722  ...  1169.428571  1168.0    4.237828   14.0  0.827427   \n",
       "4     0.113400  ...   585.333333   586.0    3.155243   12.0  0.354663   \n",
       "...        ...  ...          ...     ...         ...    ...       ...   \n",
       "8343 -0.842798  ...   619.466667   594.0  139.562109  482.0  0.472791   \n",
       "8344 -0.269851  ...   510.888889   512.0    6.870944   28.0  0.081059   \n",
       "8345 -1.152589  ...  1090.250000  1088.0    8.742854   28.0  0.436427   \n",
       "8346 -0.885061  ...   370.400000   370.0    3.098387   12.0  0.051640   \n",
       "8347 -0.810638  ...  1037.000000  1037.0   28.705400   94.0 -0.237050   \n",
       "\n",
       "           119          120       121   122   123  \n",
       "0    -0.277091   783.821985  0.785714   9.0   6.0  \n",
       "1    -0.355280   380.188159  1.000000  13.0  12.0  \n",
       "2    -0.801230   808.359965  1.000000   8.0   6.0  \n",
       "3    -0.140248  1150.133430  1.000000   8.0   7.0  \n",
       "4    -0.484056   198.042444  1.000000  16.0  15.0  \n",
       "...        ...          ...       ...   ...   ...  \n",
       "8343 -0.825913   468.155165  1.000000  16.0   8.0  \n",
       "8344 -0.433829   309.210006  1.000000  19.0  18.0  \n",
       "8345 -0.891096   940.155678  1.000000   9.0   8.0  \n",
       "8346 -0.703333   856.813033  0.461538   1.0   6.0  \n",
       "8347 -0.876580   495.494523  1.000000   9.0   8.0  \n",
       "\n",
       "[8348 rows x 124 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_125ft.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.750000</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>22.280877</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.493022</td>\n",
       "      <td>-0.931472</td>\n",
       "      <td>...</td>\n",
       "      <td>1092.000000</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.521225</td>\n",
       "      <td>-0.913087</td>\n",
       "      <td>373.995302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1115.000000</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>59.841457</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.777480</td>\n",
       "      <td>-0.423745</td>\n",
       "      <td>...</td>\n",
       "      <td>1115.000000</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>60.728906</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.772436</td>\n",
       "      <td>-0.395166</td>\n",
       "      <td>477.271172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>806.000000</td>\n",
       "      <td>804.0</td>\n",
       "      <td>8.045326</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.293282</td>\n",
       "      <td>-0.392690</td>\n",
       "      <td>...</td>\n",
       "      <td>806.000000</td>\n",
       "      <td>804.0</td>\n",
       "      <td>7.722458</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.198976</td>\n",
       "      <td>-0.896193</td>\n",
       "      <td>277.972651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>458.300000</td>\n",
       "      <td>458.0</td>\n",
       "      <td>1.705872</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.192180</td>\n",
       "      <td>-0.770964</td>\n",
       "      <td>...</td>\n",
       "      <td>458.300000</td>\n",
       "      <td>458.0</td>\n",
       "      <td>1.926136</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.368600</td>\n",
       "      <td>-0.876527</td>\n",
       "      <td>361.998395</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>941.555556</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>220.140920</td>\n",
       "      <td>628.0</td>\n",
       "      <td>-1.482314</td>\n",
       "      <td>0.419095</td>\n",
       "      <td>...</td>\n",
       "      <td>1059.250000</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>10.341059</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-0.061463</td>\n",
       "      <td>-0.843856</td>\n",
       "      <td>586.261896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>3.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>485.789474</td>\n",
       "      <td>486.0</td>\n",
       "      <td>3.104817</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.415255</td>\n",
       "      <td>-0.874744</td>\n",
       "      <td>...</td>\n",
       "      <td>485.789474</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2.966106</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.496663</td>\n",
       "      <td>-0.494835</td>\n",
       "      <td>798.662084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1060.250000</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>14.677789</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.273677</td>\n",
       "      <td>-1.204916</td>\n",
       "      <td>...</td>\n",
       "      <td>1060.250000</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>13.872184</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.231747</td>\n",
       "      <td>-1.352375</td>\n",
       "      <td>603.272611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1070.250000</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>33.082284</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-0.016678</td>\n",
       "      <td>-1.320021</td>\n",
       "      <td>...</td>\n",
       "      <td>1070.250000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>32.686962</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.030170</td>\n",
       "      <td>-1.329810</td>\n",
       "      <td>692.057509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1021.750000</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>7.171994</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.898849</td>\n",
       "      <td>-0.581729</td>\n",
       "      <td>...</td>\n",
       "      <td>1021.750000</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>7.101936</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.839867</td>\n",
       "      <td>-0.281413</td>\n",
       "      <td>456.052143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1079.500000</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>20.826666</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-0.460865</td>\n",
       "      <td>-1.486785</td>\n",
       "      <td>...</td>\n",
       "      <td>1079.750000</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>21.574001</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-0.405116</td>\n",
       "      <td>-1.328357</td>\n",
       "      <td>324.178086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2088 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1    2     3            4       5           6      7         8  \\\n",
       "0     1.0  32.0  0.0   9.0  1091.750000  1091.0   22.280877   66.0  0.493022   \n",
       "1     1.0  17.0  0.0   9.0  1115.000000  1106.0   59.841457  186.0  0.777480   \n",
       "2     2.0  64.0  0.0  12.0   806.000000   804.0    8.045326   30.0  0.293282   \n",
       "3     3.0  61.0  0.0  21.0   458.300000   458.0    1.705872    6.0  0.192180   \n",
       "4     1.0  70.0  1.0  10.0   941.555556  1054.0  220.140920  628.0 -1.482314   \n",
       "...   ...   ...  ...   ...          ...     ...         ...    ...       ...   \n",
       "2083  3.0  71.0  0.0  20.0   485.789474   486.0    3.104817   10.0 -0.415255   \n",
       "2084  1.0  51.0  1.0   9.0  1060.250000  1056.0   14.677789   44.0  0.273677   \n",
       "2085  1.0  61.0  1.0   9.0  1070.250000  1076.0   33.082284   98.0 -0.016678   \n",
       "2086  1.0  74.0  1.0   9.0  1021.750000  1018.0    7.171994   22.0  0.898849   \n",
       "2087  1.0  63.0  0.0   9.0  1079.500000  1089.0   20.826666   54.0 -0.460865   \n",
       "\n",
       "             9  ...          114     115        116    117       118  \\\n",
       "0    -0.931472  ...  1092.000000  1091.0  22.000000   66.0  0.521225   \n",
       "1    -0.423745  ...  1115.000000  1107.0  60.728906  192.0  0.772436   \n",
       "2    -0.392690  ...   806.000000   804.0   7.722458   26.0  0.198976   \n",
       "3    -0.770964  ...   458.300000   458.0   1.926136    6.0  0.368600   \n",
       "4     0.419095  ...  1059.250000  1059.0  10.341059   34.0 -0.061463   \n",
       "...        ...  ...          ...     ...        ...    ...       ...   \n",
       "2083 -0.874744  ...   485.789474   486.0   2.966106   10.0 -0.496663   \n",
       "2084 -1.204916  ...  1060.250000  1056.0  13.872184   40.0  0.231747   \n",
       "2085 -1.320021  ...  1070.250000  1075.0  32.686962   96.0  0.030170   \n",
       "2086 -0.581729  ...  1021.750000  1020.0   7.101936   24.0  0.839867   \n",
       "2087 -1.486785  ...  1079.750000  1087.0  21.574001   60.0 -0.405116   \n",
       "\n",
       "           119         120  121   122   123  \n",
       "0    -0.913087  373.995302  1.0   9.0   7.0  \n",
       "1    -0.395166  477.271172  1.0   9.0   8.0  \n",
       "2    -0.896193  277.972651  1.0  12.0  11.0  \n",
       "3    -0.876527  361.998395  1.0   0.0  20.0  \n",
       "4    -0.843856  586.261896  1.0   9.0   7.0  \n",
       "...        ...         ...  ...   ...   ...  \n",
       "2083 -0.494835  798.662084  1.0  10.0  19.0  \n",
       "2084 -1.352375  603.272611  1.0   9.0   8.0  \n",
       "2085 -1.329810  692.057509  1.0   9.0   4.0  \n",
       "2086 -0.281413  456.052143  1.0   9.0   8.0  \n",
       "2087 -1.328357  324.178086  1.0   9.0   8.0  \n",
       "\n",
       "[2088 rows x 124 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_125ft.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4174, 123)\n",
      "Vallidation: (4174, 123)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 5, max_features= 'sqrt', n_estimators= 1000)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 50)\n",
    "# knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 100, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.1,max_depth= 5,min_child_weight= 1,n_estimators= 1000)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 5,max_features= 'sqrt',splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features='sqrt')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "# knn_clf.fit(x_train, y_train)\n",
    "svc_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    # knn_clf.predict_proba(x_val),\n",
    "    svc_clf.predict_proba(x_val),\n",
    "    xgb_clf.predict_proba(x_val),\n",
    "    dt_clf.predict_proba(x_val)\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    # knn_clf.predict_proba(x_test),\n",
    "    svc_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    dt_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4174, 20)\n",
      "X_test_meta:(2088, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=(train=0.960, test=0.945) total time=   0.1s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=(train=0.958, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=(train=0.960, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=(train=0.957, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.949) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=(train=0.958, test=0.946) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=(train=0.957, test=0.950) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=(train=0.959, test=0.946) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.949) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.946) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=(train=0.957, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=(train=0.958, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=(train=0.962, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=(train=0.957, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=(train=0.955, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=(train=0.955, test=0.948) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=(train=0.955, test=0.953) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=(train=0.959, test=0.945) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.948) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.945) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=(train=0.957, test=0.946) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=(train=0.957, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=(train=0.959, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=(train=0.955, test=0.943) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=(train=0.954, test=0.949) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=(train=0.959, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=(train=0.954, test=0.944) total time=   0.2s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=(train=0.953, test=0.949) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=(train=0.956, test=0.946) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.948) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.952) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.947) total time=   0.4s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.960, test=0.945) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.958, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.960, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.957, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.949) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.958, test=0.946) total time=   0.6s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.957, test=0.950) total time=   0.6s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.959, test=0.946) total time=   0.6s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.949) total time=   0.4s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.5s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.946) total time=   0.4s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.957, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.958, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.962, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.957, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.955, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.955, test=0.948) total time=   0.4s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.955, test=0.953) total time=   0.4s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.959, test=0.945) total time=   0.4s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.948) total time=   0.4s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.3s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.945) total time=   0.4s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.957, test=0.946) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.957, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.959, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.955, test=0.943) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.954, test=0.949) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.959, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.954, test=0.944) total time=   0.4s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.953, test=0.949) total time=   0.4s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.956, test=0.946) total time=   0.4s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.948) total time=   0.4s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.952) total time=   0.4s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.947) total time=   0.4s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.960, test=0.945) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.958, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.960, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.957, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.949) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.958, test=0.946) total time=   0.1s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.957, test=0.950) total time=   0.1s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.959, test=0.946) total time=   0.1s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.949) total time=   0.1s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.1s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.946) total time=   0.1s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.957, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.958, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.962, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.957, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.955, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.955, test=0.948) total time=   0.1s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.955, test=0.953) total time=   0.1s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.959, test=0.945) total time=   0.1s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.948) total time=   0.1s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.1s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.945) total time=   0.1s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.957, test=0.946) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.957, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.959, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.955, test=0.943) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.954, test=0.949) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.959, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.954, test=0.944) total time=   0.1s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.953, test=0.949) total time=   0.1s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.956, test=0.946) total time=   0.1s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.948) total time=   0.1s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.952) total time=   0.1s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.947) total time=   0.1s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=(train=0.960, test=0.945) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=(train=0.958, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=(train=0.960, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=(train=0.957, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.949) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=(train=0.958, test=0.946) total time=   0.3s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=(train=0.957, test=0.950) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=(train=0.959, test=0.946) total time=   0.2s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.949) total time=   0.3s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.946) total time=   0.3s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=(train=0.957, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=(train=0.958, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=(train=0.962, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=(train=0.957, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=(train=0.955, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=(train=0.959, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=(train=0.955, test=0.948) total time=   0.3s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=(train=0.955, test=0.953) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=(train=0.959, test=0.945) total time=   0.3s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.948) total time=   0.3s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.945) total time=   0.3s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=(train=0.957, test=0.946) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=(train=0.957, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=(train=0.959, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=(train=0.955, test=0.943) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=(train=0.954, test=0.949) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=(train=0.959, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=(train=0.954, test=0.944) total time=   0.3s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=(train=0.953, test=0.949) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=(train=0.956, test=0.946) total time=   0.3s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.948) total time=   0.3s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.952) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.947) total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = KNeighborsClassifier()\n",
    "params = {\n",
    "    'n_neighbors': [4,5,6],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1,2,3]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9508862046930046"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.961686</td>\n",
       "      <td>0.896789</td>\n",
       "      <td>0.917840</td>\n",
       "      <td>0.907193</td>\n",
       "      <td>0.978814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.991858</td>\n",
       "      <td>0.990968</td>\n",
       "      <td>0.987147</td>\n",
       "      <td>0.989053</td>\n",
       "      <td>0.992384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.983716</td>\n",
       "      <td>0.961712</td>\n",
       "      <td>0.961712</td>\n",
       "      <td>0.961712</td>\n",
       "      <td>0.989659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.970785</td>\n",
       "      <td>0.937644</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>0.930126</td>\n",
       "      <td>0.979456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947021</td>\n",
       "      <td>0.947356</td>\n",
       "      <td>0.946778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953926</td>\n",
       "      <td>0.953907</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.961686  0.896789   0.917840  0.907193     0.978814\n",
       "1            SB  0.991858  0.990968   0.987147  0.989053     0.992384\n",
       "2            SR  0.983716  0.961712   0.961712  0.961712     0.989659\n",
       "3          GSVT  0.970785  0.937644   0.922727  0.930126     0.979456\n",
       "4     macro avg       NaN  0.947021   0.947356  0.946778          NaN\n",
       "5     micro avg       NaN  0.954023   0.954023  0.954023          NaN\n",
       "6  weighted avg       NaN  0.953926   0.953907  0.954023          NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"../Result/Blending_KNN_125ft.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
