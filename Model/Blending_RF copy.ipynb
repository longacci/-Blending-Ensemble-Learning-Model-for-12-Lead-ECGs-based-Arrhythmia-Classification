{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>918.222222</td>\n",
       "      <td>882.0</td>\n",
       "      <td>94.903200</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.472670</td>\n",
       "      <td>-0.949065</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>11430.000000</td>\n",
       "      <td>147.250000</td>\n",
       "      <td>3440.937500</td>\n",
       "      <td>71.250000</td>\n",
       "      <td>2477.937500</td>\n",
       "      <td>171.200000</td>\n",
       "      <td>1482.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1138.500000</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>22.555487</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-0.461107</td>\n",
       "      <td>-1.286145</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>146.285714</td>\n",
       "      <td>10377.632653</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>12749.750000</td>\n",
       "      <td>168.250000</td>\n",
       "      <td>461.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>896.666667</td>\n",
       "      <td>944.0</td>\n",
       "      <td>204.320010</td>\n",
       "      <td>646.0</td>\n",
       "      <td>-1.350073</td>\n",
       "      <td>0.489157</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>478.400000</td>\n",
       "      <td>1852.640000</td>\n",
       "      <td>123.600000</td>\n",
       "      <td>5864.640000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>7330.560000</td>\n",
       "      <td>124.909091</td>\n",
       "      <td>3343.537190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>587.333333</td>\n",
       "      <td>588.0</td>\n",
       "      <td>22.623488</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-1.644839</td>\n",
       "      <td>4.250959</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>395.142857</td>\n",
       "      <td>4358.693878</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>2091.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>3449.142857</td>\n",
       "      <td>42.333333</td>\n",
       "      <td>11889.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1035.000000</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>31.336879</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.346377</td>\n",
       "      <td>-1.297847</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>410.895810</td>\n",
       "      <td>2039.462769</td>\n",
       "      <td>122.920761</td>\n",
       "      <td>3154.034717</td>\n",
       "      <td>21.669423</td>\n",
       "      <td>3522.522691</td>\n",
       "      <td>206.666667</td>\n",
       "      <td>552.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>914.200000</td>\n",
       "      <td>912.0</td>\n",
       "      <td>15.810123</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.592631</td>\n",
       "      <td>-0.592510</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>423.555556</td>\n",
       "      <td>364.246914</td>\n",
       "      <td>62.444444</td>\n",
       "      <td>236.246914</td>\n",
       "      <td>-28.888889</td>\n",
       "      <td>295.209877</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>2024.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1131.142857</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>123.417328</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.939151</td>\n",
       "      <td>-1.104222</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>517.714286</td>\n",
       "      <td>70.204082</td>\n",
       "      <td>128.285714</td>\n",
       "      <td>10653.061224</td>\n",
       "      <td>58.857143</td>\n",
       "      <td>11244.408163</td>\n",
       "      <td>175.500000</td>\n",
       "      <td>576.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>3.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>130.133333</td>\n",
       "      <td>26.382222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>488.105263</td>\n",
       "      <td>488.0</td>\n",
       "      <td>3.006917</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>-0.463470</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>273.200000</td>\n",
       "      <td>1626.560000</td>\n",
       "      <td>130.421053</td>\n",
       "      <td>656.243767</td>\n",
       "      <td>57.684211</td>\n",
       "      <td>1234.216066</td>\n",
       "      <td>110.133333</td>\n",
       "      <td>1379.448889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>474.842105</td>\n",
       "      <td>474.0</td>\n",
       "      <td>3.133237</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.187241</td>\n",
       "      <td>0.047356</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>321.555556</td>\n",
       "      <td>2834.913580</td>\n",
       "      <td>109.222222</td>\n",
       "      <td>3185.395062</td>\n",
       "      <td>-1.777778</td>\n",
       "      <td>2341.728395</td>\n",
       "      <td>52.421053</td>\n",
       "      <td>2678.980609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1    2     3            4       5           6      7         8  \\\n",
       "0     0.0  52.0  0.0  10.0   918.222222   882.0   94.903200  310.0  0.472670   \n",
       "1     1.0  35.0  1.0   9.0  1138.500000  1145.0   22.555487   64.0 -0.461107   \n",
       "2     2.0  45.0  1.0  10.0   896.666667   944.0  204.320010  646.0 -1.350073   \n",
       "3     3.0  72.0  0.0  16.0   587.333333   588.0   22.623488  106.0 -1.644839   \n",
       "4     1.0  68.0  0.0   9.0  1035.000000  1032.0   31.336879   90.0  0.346377   \n",
       "...   ...   ...  ...   ...          ...     ...         ...    ...       ...   \n",
       "8511  2.0  53.0  0.0  11.0   914.200000   912.0   15.810123   52.0  0.592631   \n",
       "8512  1.0  78.0  1.0   8.0  1131.142857  1056.0  123.417328  282.0  0.939151   \n",
       "8513  3.0  71.0  1.0  15.0   612.000000   612.0    2.000000    6.0  0.857143   \n",
       "8514  3.0  28.0  1.0  20.0   488.105263   488.0    3.006917   12.0  0.003346   \n",
       "8515  3.0  41.0  0.0  20.0   474.842105   474.0    3.133237   14.0  0.187241   \n",
       "\n",
       "             9  ...   233   234         235           236         237  \\\n",
       "0    -0.949065  ...  10.0   9.0  524.000000  11430.000000  147.250000   \n",
       "1    -1.286145  ...   8.0   8.0  469.000000   1016.000000  146.285714   \n",
       "2     0.489157  ...  11.0  10.0  478.400000   1852.640000  123.600000   \n",
       "3     4.250959  ...  12.0  11.0  395.142857   4358.693878   76.000000   \n",
       "4    -1.297847  ...   9.0   0.0  410.895810   2039.462769  122.920761   \n",
       "...        ...  ...   ...   ...         ...           ...         ...   \n",
       "8511 -0.592510  ...  11.0  10.0  423.555556    364.246914   62.444444   \n",
       "8512 -1.104222  ...   8.0   7.0  517.714286     70.204082  128.285714   \n",
       "8513 -0.285714  ...  15.0   1.0  394.000000      0.000000  156.000000   \n",
       "8514 -0.463470  ...  15.0  19.0  273.200000   1626.560000  130.421053   \n",
       "8515  0.047356  ...  19.0  18.0  321.555556   2834.913580  109.222222   \n",
       "\n",
       "               238        239           240         241           242  \n",
       "0      3440.937500  71.250000   2477.937500  171.200000   1482.560000  \n",
       "1     10377.632653  55.500000  12749.750000  168.250000    461.437500  \n",
       "2      5864.640000  20.800000   7330.560000  124.909091   3343.537190  \n",
       "3      2091.000000 -40.000000   3449.142857   42.333333  11889.222222  \n",
       "4      3154.034717  21.669423   3522.522691  206.666667    552.888889  \n",
       "...            ...        ...           ...         ...           ...  \n",
       "8511    236.246914 -28.888889    295.209877  124.000000   2024.727273  \n",
       "8512  10653.061224  58.857143  11244.408163  175.500000    576.750000  \n",
       "8513      0.000000  86.000000      0.000000  130.133333     26.382222  \n",
       "8514    656.243767  57.684211   1234.216066  110.133333   1379.448889  \n",
       "8515   3185.395062  -1.777778   2341.728395   52.421053   2678.980609  \n",
       "\n",
       "[8516 rows x 243 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_fillna.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1170.571429</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>16.273178</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.650965</td>\n",
       "      <td>-1.237999</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>458.571429</td>\n",
       "      <td>24.816327</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>43.428571</td>\n",
       "      <td>33.428571</td>\n",
       "      <td>62.530612</td>\n",
       "      <td>164.500000</td>\n",
       "      <td>235.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>533.647059</td>\n",
       "      <td>532.0</td>\n",
       "      <td>4.405093</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.290425</td>\n",
       "      <td>-1.358307</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>353.571429</td>\n",
       "      <td>952.673469</td>\n",
       "      <td>144.823529</td>\n",
       "      <td>195.792388</td>\n",
       "      <td>40.352941</td>\n",
       "      <td>911.640138</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>284.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>571.375000</td>\n",
       "      <td>573.0</td>\n",
       "      <td>5.372092</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.962004</td>\n",
       "      <td>-0.290856</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>427.500000</td>\n",
       "      <td>1328.750000</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1640.346939</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2415.918367</td>\n",
       "      <td>102.153846</td>\n",
       "      <td>69.207101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1038.000000</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>19.442222</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-0.563330</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>513.200000</td>\n",
       "      <td>2108.160000</td>\n",
       "      <td>110.400000</td>\n",
       "      <td>2899.840000</td>\n",
       "      <td>-31.600000</td>\n",
       "      <td>2002.240000</td>\n",
       "      <td>171.333333</td>\n",
       "      <td>49.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>393.333333</td>\n",
       "      <td>392.0</td>\n",
       "      <td>3.248931</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.537888</td>\n",
       "      <td>2.495402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>410.895810</td>\n",
       "      <td>2039.462769</td>\n",
       "      <td>122.920761</td>\n",
       "      <td>3154.034717</td>\n",
       "      <td>21.669423</td>\n",
       "      <td>3522.522691</td>\n",
       "      <td>99.852469</td>\n",
       "      <td>2078.683018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1031.777778</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>60.003292</td>\n",
       "      <td>248.0</td>\n",
       "      <td>0.096327</td>\n",
       "      <td>1.069329</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>1331.555556</td>\n",
       "      <td>108.888889</td>\n",
       "      <td>1453.432099</td>\n",
       "      <td>-4.444444</td>\n",
       "      <td>1383.802469</td>\n",
       "      <td>93.600000</td>\n",
       "      <td>135.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>722.166667</td>\n",
       "      <td>723.0</td>\n",
       "      <td>6.504272</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.859445</td>\n",
       "      <td>-0.264470</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>413.500000</td>\n",
       "      <td>389.416667</td>\n",
       "      <td>132.666667</td>\n",
       "      <td>2414.888889</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>2498.888889</td>\n",
       "      <td>181.384615</td>\n",
       "      <td>2109.159763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.0</td>\n",
       "      <td>6.855655</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.046553</td>\n",
       "      <td>-0.258488</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>412.875000</td>\n",
       "      <td>768.984375</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>1077.250000</td>\n",
       "      <td>-41.625000</td>\n",
       "      <td>779.109375</td>\n",
       "      <td>44.800000</td>\n",
       "      <td>6084.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>918.222222</td>\n",
       "      <td>840.0</td>\n",
       "      <td>214.508108</td>\n",
       "      <td>684.0</td>\n",
       "      <td>1.333096</td>\n",
       "      <td>0.602620</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>16614.000000</td>\n",
       "      <td>253.500000</td>\n",
       "      <td>2402.750000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>1650.000000</td>\n",
       "      <td>108.800000</td>\n",
       "      <td>4868.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>592.800000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>29.237419</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.272553</td>\n",
       "      <td>-0.573703</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>367.733333</td>\n",
       "      <td>2697.528889</td>\n",
       "      <td>91.733333</td>\n",
       "      <td>906.062222</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>813.582222</td>\n",
       "      <td>130.250000</td>\n",
       "      <td>2168.437500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1    2     3            4       5           6      7         8  \\\n",
       "0     1.0  62.0  1.0   8.0  1170.571429  1168.0   16.273178   42.0  0.650965   \n",
       "1     3.0  74.0  1.0  18.0   533.647059   532.0    4.405093   12.0  0.290425   \n",
       "2     3.0  79.0  1.0  17.0   571.375000   573.0    5.372092   18.0 -0.962004   \n",
       "3     1.0  56.0  1.0   9.0  1038.000000  1039.0   19.442222   68.0 -0.563330   \n",
       "4     0.0  70.0  1.0  25.0   393.333333   392.0    3.248931   14.0  1.537888   \n",
       "...   ...   ...  ...   ...          ...     ...         ...    ...       ...   \n",
       "2125  1.0  64.0  0.0  10.0  1031.777778  1034.0   60.003292  248.0  0.096327   \n",
       "2126  2.0  67.0  1.0  13.0   722.166667   723.0    6.504272   22.0 -0.859445   \n",
       "2127  3.0  46.0  1.0  17.0   586.000000   586.0    6.855655   28.0 -0.046553   \n",
       "2128  0.0  69.0  1.0  10.0   918.222222   840.0  214.508108  684.0  1.333096   \n",
       "2129  3.0  38.0  0.0  16.0   592.800000   590.0   29.237419  108.0  0.272553   \n",
       "\n",
       "             9  ...   233   234         235           236         237  \\\n",
       "0    -1.237999  ...   8.0   8.0  458.571429     24.816327  132.000000   \n",
       "1    -1.358307  ...  14.0  17.0  353.571429    952.673469  144.823529   \n",
       "2    -0.290856  ...  13.0  14.0  427.500000   1328.750000  102.714286   \n",
       "3     0.000420  ...   9.0   5.0  513.200000   2108.160000  110.400000   \n",
       "4     2.495402  ...   0.0  23.0  410.895810   2039.462769  122.920761   \n",
       "...        ...  ...   ...   ...         ...           ...         ...   \n",
       "2125  1.069329  ...   9.0   9.0  414.000000   1331.555556  108.888889   \n",
       "2126 -0.264470  ...  13.0  12.0  413.500000    389.416667  132.666667   \n",
       "2127 -0.258488  ...  16.0  16.0  412.875000    768.984375   57.500000   \n",
       "2128  0.602620  ...  10.0   5.0  370.000000  16614.000000  253.500000   \n",
       "2129 -0.573703  ...  16.0  15.0  367.733333   2697.528889   91.733333   \n",
       "\n",
       "              238         239          240         241          242  \n",
       "0       43.428571   33.428571    62.530612  164.500000   235.750000  \n",
       "1      195.792388   40.352941   911.640138   69.000000   284.428571  \n",
       "2     1640.346939    1.714286  2415.918367  102.153846    69.207101  \n",
       "3     2899.840000  -31.600000  2002.240000  171.333333    49.777778  \n",
       "4     3154.034717   21.669423  3522.522691   99.852469  2078.683018  \n",
       "...           ...         ...          ...         ...          ...  \n",
       "2125  1453.432099   -4.444444  1383.802469   93.600000   135.040000  \n",
       "2126  2414.888889   76.666667  2498.888889  181.384615  2109.159763  \n",
       "2127  1077.250000  -41.625000   779.109375   44.800000  6084.693333  \n",
       "2128  2402.750000  158.000000  1650.000000  108.800000  4868.160000  \n",
       "2129   906.062222    0.133333   813.582222  130.250000  2168.437500  \n",
       "\n",
       "[2130 rows x 243 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_fillna.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(C= 1, max_iter= 200, penalty= 'l2', solver= 'sag')\n",
    "rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 5, max_features= 'sqrt', n_estimators= 1000)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 50)\n",
    "knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 6, p= 1, weights= 'distance')\n",
    "svc_clf = SVC(C= 10, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.1,max_depth= 4,min_child_weight= 1,n_estimators= 1000)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'gini',max_depth= 5,max_features= 'sqrt',splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, max_features=&#x27;sqrt&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=5, max_features=&#x27;sqrt&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, max_features='sqrt')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "# lr_clf.fit(x_train,y_train)\n",
    "# rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "svc_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    # lr_clf.predict_proba(x_train),\n",
    "    # rf_clf.predict_proba(x_train),\n",
    "    ab_clf.predict_proba(x_train),\n",
    "    knn_clf.predict_proba(x_train),\n",
    "    svc_clf.predict_proba(x_train),\n",
    "    xgb_clf.predict_proba(x_train),\n",
    "    dt_clf.predict_proba(x_train)\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    # lr_clf.predict_proba(x_test),\n",
    "    # rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    knn_clf.predict_proba(x_test),\n",
    "    svc_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    dt_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(8516, 20)\n",
      "X_test_meta:(2130, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.998, test=0.999) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   2.8s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   2.8s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   2.8s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.999, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.999, test=0.999) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.999, test=0.999) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.999, test=1.000) total time=   0.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   2.7s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   2.8s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   2.8s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.2s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.2s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.5s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   5.7s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.2s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.999, test=0.999) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.999, test=0.999) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.5s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.5s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.5s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.997, test=0.997) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.999, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.999, test=0.999) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.5s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.6s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.5s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.7s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.7s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.7s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.7s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.7s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.7s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   4.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   5.3s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   6.2s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.8s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.8s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.8s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.999, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.999, test=0.999) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.5s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.4s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.5s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.4s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.4s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.4s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.7s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.7s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.7s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.7s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.8s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.7s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.8s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.8s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.8s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.9s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.8s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=1.000, test=1.000) total time=   3.8s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = RandomForestClassifier()\n",
    "params = {\n",
    "    'n_estimators': [10,50,100,1000],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [3,4,5],\n",
    "    'max_features':['sqrt', 'log2'],\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 3,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.961033</td>\n",
       "      <td>0.923596</td>\n",
       "      <td>0.893478</td>\n",
       "      <td>0.908287</td>\n",
       "      <td>0.970920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.988263</td>\n",
       "      <td>0.983290</td>\n",
       "      <td>0.984556</td>\n",
       "      <td>0.983923</td>\n",
       "      <td>0.991124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.983099</td>\n",
       "      <td>0.952809</td>\n",
       "      <td>0.965831</td>\n",
       "      <td>0.959276</td>\n",
       "      <td>0.991098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.970892</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.940529</td>\n",
       "      <td>0.932314</td>\n",
       "      <td>0.983813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.945950</td>\n",
       "      <td>0.946099</td>\n",
       "      <td>0.945984</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.951643</td>\n",
       "      <td>0.951643</td>\n",
       "      <td>0.951643</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.951778</td>\n",
       "      <td>0.952066</td>\n",
       "      <td>0.951643</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.961033  0.923596   0.893478  0.908287     0.970920\n",
       "1            SB  0.988263  0.983290   0.984556  0.983923     0.991124\n",
       "2            SR  0.983099  0.952809   0.965831  0.959276     0.991098\n",
       "3          GSVT  0.970892  0.924242   0.940529  0.932314     0.983813\n",
       "4     macro avg       NaN  0.945950   0.946099  0.945984          NaN\n",
       "5     micro avg       NaN  0.951643   0.951643  0.951643          NaN\n",
       "6  weighted avg       NaN  0.951778   0.952066  0.951643          NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_evaluation_test.to_csv(\"../Result/Blending_RF_fillna.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
