{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Rcount_lead1</th>\n",
       "      <th>RRInterval_mean_lead1</th>\n",
       "      <th>RRInterval_std_lead1</th>\n",
       "      <th>QT_intervals_var_lead1</th>\n",
       "      <th>PR_intervals_mean_lead1</th>\n",
       "      <th>PR_segment_mean_lead1</th>\n",
       "      <th>PR_segment_var_lead1</th>\n",
       "      <th>...</th>\n",
       "      <th>Qcount_lead11</th>\n",
       "      <th>ST_segment_mean_lead11</th>\n",
       "      <th>Rcount_lead12</th>\n",
       "      <th>RRInterval_median_lead12</th>\n",
       "      <th>RRInterval_range_lead12</th>\n",
       "      <th>RRInterval_skew_lead12</th>\n",
       "      <th>RRInterval_kurtosis_lead12</th>\n",
       "      <th>R_peaks_amplitude_from_isoelectric_mean_lead12</th>\n",
       "      <th>Qcount_lead12</th>\n",
       "      <th>PR_segment_mean_lead12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.456183</td>\n",
       "      <td>1</td>\n",
       "      <td>2.313163</td>\n",
       "      <td>0.381475</td>\n",
       "      <td>0.041064</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.124970</td>\n",
       "      <td>-0.618281</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-0.184178</td>\n",
       "      <td>2.314183</td>\n",
       "      <td>0.380859</td>\n",
       "      <td>0.058467</td>\n",
       "      <td>1.456159</td>\n",
       "      <td>1.804519</td>\n",
       "      <td>0.764069</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.002074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.402339</td>\n",
       "      <td>1</td>\n",
       "      <td>1.044654</td>\n",
       "      <td>0.880707</td>\n",
       "      <td>1.874749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.715935</td>\n",
       "      <td>4.769596</td>\n",
       "      <td>2.236628</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.225579</td>\n",
       "      <td>1.045115</td>\n",
       "      <td>0.873007</td>\n",
       "      <td>1.882629</td>\n",
       "      <td>0.025357</td>\n",
       "      <td>-1.223340</td>\n",
       "      <td>3.526872</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.996510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.368548</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671563</td>\n",
       "      <td>1.334546</td>\n",
       "      <td>0.250454</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>2.122088</td>\n",
       "      <td>4.074030</td>\n",
       "      <td>0.087646</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.489339</td>\n",
       "      <td>0.671860</td>\n",
       "      <td>1.341661</td>\n",
       "      <td>0.233867</td>\n",
       "      <td>-0.752008</td>\n",
       "      <td>-0.916225</td>\n",
       "      <td>1.287138</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.491185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.844783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671563</td>\n",
       "      <td>1.262942</td>\n",
       "      <td>0.276685</td>\n",
       "      <td>0.429776</td>\n",
       "      <td>0.884404</td>\n",
       "      <td>-1.402173</td>\n",
       "      <td>0.225874</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.803774</td>\n",
       "      <td>0.746511</td>\n",
       "      <td>1.261285</td>\n",
       "      <td>3.391071</td>\n",
       "      <td>-2.440756</td>\n",
       "      <td>4.027672</td>\n",
       "      <td>1.151314</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.592259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.115113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671563</td>\n",
       "      <td>1.391335</td>\n",
       "      <td>8.379536</td>\n",
       "      <td>0.589014</td>\n",
       "      <td>2.523434</td>\n",
       "      <td>7.364169</td>\n",
       "      <td>2.511923</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.826430</td>\n",
       "      <td>0.671860</td>\n",
       "      <td>1.293435</td>\n",
       "      <td>7.881317</td>\n",
       "      <td>0.684815</td>\n",
       "      <td>-0.853637</td>\n",
       "      <td>2.071577</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.468224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>2</td>\n",
       "      <td>1.351652</td>\n",
       "      <td>0</td>\n",
       "      <td>0.895418</td>\n",
       "      <td>1.001106</td>\n",
       "      <td>0.341096</td>\n",
       "      <td>2.768143</td>\n",
       "      <td>1.071422</td>\n",
       "      <td>1.228532</td>\n",
       "      <td>0.882024</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.354048</td>\n",
       "      <td>0.895813</td>\n",
       "      <td>1.001609</td>\n",
       "      <td>0.339107</td>\n",
       "      <td>-0.250734</td>\n",
       "      <td>-1.102293</td>\n",
       "      <td>0.693319</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.473416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>0</td>\n",
       "      <td>1.081322</td>\n",
       "      <td>1</td>\n",
       "      <td>1.044654</td>\n",
       "      <td>0.851458</td>\n",
       "      <td>1.631888</td>\n",
       "      <td>3.190118</td>\n",
       "      <td>1.323401</td>\n",
       "      <td>3.282778</td>\n",
       "      <td>0.342559</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.409284</td>\n",
       "      <td>1.045115</td>\n",
       "      <td>0.855695</td>\n",
       "      <td>1.917709</td>\n",
       "      <td>0.372443</td>\n",
       "      <td>-0.373761</td>\n",
       "      <td>2.989072</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.494766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2</td>\n",
       "      <td>0.067583</td>\n",
       "      <td>0</td>\n",
       "      <td>1.044654</td>\n",
       "      <td>0.854877</td>\n",
       "      <td>0.987437</td>\n",
       "      <td>0.399927</td>\n",
       "      <td>0.780878</td>\n",
       "      <td>0.896847</td>\n",
       "      <td>0.087124</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.960356</td>\n",
       "      <td>1.045115</td>\n",
       "      <td>0.885373</td>\n",
       "      <td>0.935468</td>\n",
       "      <td>-0.553992</td>\n",
       "      <td>-1.246738</td>\n",
       "      <td>0.667144</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.099376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1</td>\n",
       "      <td>0.642035</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671563</td>\n",
       "      <td>1.249054</td>\n",
       "      <td>0.722168</td>\n",
       "      <td>0.425762</td>\n",
       "      <td>0.586398</td>\n",
       "      <td>-0.971584</td>\n",
       "      <td>0.360905</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.286971</td>\n",
       "      <td>0.746511</td>\n",
       "      <td>1.276124</td>\n",
       "      <td>0.818534</td>\n",
       "      <td>-1.033128</td>\n",
       "      <td>0.224218</td>\n",
       "      <td>1.014954</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.496880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>2</td>\n",
       "      <td>0.861678</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820800</td>\n",
       "      <td>1.134549</td>\n",
       "      <td>0.160306</td>\n",
       "      <td>0.316036</td>\n",
       "      <td>1.318915</td>\n",
       "      <td>2.243477</td>\n",
       "      <td>0.180930</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.555280</td>\n",
       "      <td>0.821162</td>\n",
       "      <td>1.135157</td>\n",
       "      <td>0.152014</td>\n",
       "      <td>0.269224</td>\n",
       "      <td>-1.005418</td>\n",
       "      <td>0.450950</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.336703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rhythm  PatientAge  Gender  Rcount_lead1  RRInterval_mean_lead1  \\\n",
       "0          3    0.456183       1      2.313163               0.381475   \n",
       "1          0    1.402339       1      1.044654               0.880707   \n",
       "2          1    1.368548       1      0.671563               1.334546   \n",
       "3          1    0.844783       0      0.671563               1.262942   \n",
       "4          0    1.115113       1      0.671563               1.391335   \n",
       "...      ...         ...     ...           ...                    ...   \n",
       "8511       2    1.351652       0      0.895418               1.001106   \n",
       "8512       0    1.081322       1      1.044654               0.851458   \n",
       "8513       2    0.067583       0      1.044654               0.854877   \n",
       "8514       1    0.642035       1      0.671563               1.249054   \n",
       "8515       2    0.861678       1      0.820800               1.134549   \n",
       "\n",
       "      RRInterval_std_lead1  QT_intervals_var_lead1  PR_intervals_mean_lead1  \\\n",
       "0                 0.041064                0.000019                 0.124970   \n",
       "1                 1.874749                0.000000                 1.715935   \n",
       "2                 0.250454                0.002375                 2.122088   \n",
       "3                 0.276685                0.429776                 0.884404   \n",
       "4                 8.379536                0.589014                 2.523434   \n",
       "...                    ...                     ...                      ...   \n",
       "8511              0.341096                2.768143                 1.071422   \n",
       "8512              1.631888                3.190118                 1.323401   \n",
       "8513              0.987437                0.399927                 0.780878   \n",
       "8514              0.722168                0.425762                 0.586398   \n",
       "8515              0.160306                0.316036                 1.318915   \n",
       "\n",
       "      PR_segment_mean_lead1  PR_segment_var_lead1  ...  Qcount_lead11  \\\n",
       "0                 -0.618281              0.001515  ...           29.0   \n",
       "1                  4.769596              2.236628  ...            4.0   \n",
       "2                  4.074030              0.087646  ...            7.0   \n",
       "3                 -1.402173              0.225874  ...            8.0   \n",
       "4                  7.364169              2.511923  ...            8.0   \n",
       "...                     ...                   ...  ...            ...   \n",
       "8511               1.228532              0.882024  ...           11.0   \n",
       "8512               3.282778              0.342559  ...            1.0   \n",
       "8513               0.896847              0.087124  ...           10.0   \n",
       "8514              -0.971584              0.360905  ...            7.0   \n",
       "8515               2.243477              0.180930  ...           10.0   \n",
       "\n",
       "      ST_segment_mean_lead11  Rcount_lead12  RRInterval_median_lead12  \\\n",
       "0                  -0.184178       2.314183                  0.380859   \n",
       "1                   1.225579       1.045115                  0.873007   \n",
       "2                   1.489339       0.671860                  1.341661   \n",
       "3                   1.803774       0.746511                  1.261285   \n",
       "4                   1.826430       0.671860                  1.293435   \n",
       "...                      ...            ...                       ...   \n",
       "8511                1.354048       0.895813                  1.001609   \n",
       "8512               -0.409284       1.045115                  0.855695   \n",
       "8513                0.960356       1.045115                  0.885373   \n",
       "8514                1.286971       0.746511                  1.276124   \n",
       "8515                1.555280       0.821162                  1.135157   \n",
       "\n",
       "      RRInterval_range_lead12  RRInterval_skew_lead12  \\\n",
       "0                    0.058467                1.456159   \n",
       "1                    1.882629                0.025357   \n",
       "2                    0.233867               -0.752008   \n",
       "3                    3.391071               -2.440756   \n",
       "4                    7.881317                0.684815   \n",
       "...                       ...                     ...   \n",
       "8511                 0.339107               -0.250734   \n",
       "8512                 1.917709                0.372443   \n",
       "8513                 0.935468               -0.553992   \n",
       "8514                 0.818534               -1.033128   \n",
       "8515                 0.152014                0.269224   \n",
       "\n",
       "      RRInterval_kurtosis_lead12  \\\n",
       "0                       1.804519   \n",
       "1                      -1.223340   \n",
       "2                      -0.916225   \n",
       "3                       4.027672   \n",
       "4                      -0.853637   \n",
       "...                          ...   \n",
       "8511                   -1.102293   \n",
       "8512                   -0.373761   \n",
       "8513                   -1.246738   \n",
       "8514                    0.224218   \n",
       "8515                   -1.005418   \n",
       "\n",
       "      R_peaks_amplitude_from_isoelectric_mean_lead12  Qcount_lead12  \\\n",
       "0                                           0.764069           30.0   \n",
       "1                                           3.526872            3.0   \n",
       "2                                           1.287138            7.0   \n",
       "3                                           1.151314            8.0   \n",
       "4                                           2.071577            6.0   \n",
       "...                                              ...            ...   \n",
       "8511                                        0.693319           11.0   \n",
       "8512                                        2.989072            4.0   \n",
       "8513                                        0.667144           10.0   \n",
       "8514                                        1.014954            9.0   \n",
       "8515                                        0.450950           10.0   \n",
       "\n",
       "      PR_segment_mean_lead12  \n",
       "0                   0.002074  \n",
       "1                   0.996510  \n",
       "2                   4.491185  \n",
       "3                   3.592259  \n",
       "4                   4.468224  \n",
       "...                      ...  \n",
       "8511               -0.473416  \n",
       "8512               -1.494766  \n",
       "8513                1.099376  \n",
       "8514                5.496880  \n",
       "8515                3.336703  \n",
       "\n",
       "[8516 rows x 107 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../df_train_pso.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Rcount_lead1</th>\n",
       "      <th>RRInterval_mean_lead1</th>\n",
       "      <th>RRInterval_std_lead1</th>\n",
       "      <th>QT_intervals_var_lead1</th>\n",
       "      <th>PR_intervals_mean_lead1</th>\n",
       "      <th>PR_segment_mean_lead1</th>\n",
       "      <th>PR_segment_var_lead1</th>\n",
       "      <th>...</th>\n",
       "      <th>Qcount_lead11</th>\n",
       "      <th>ST_segment_mean_lead11</th>\n",
       "      <th>Rcount_lead12</th>\n",
       "      <th>RRInterval_median_lead12</th>\n",
       "      <th>RRInterval_range_lead12</th>\n",
       "      <th>RRInterval_skew_lead12</th>\n",
       "      <th>RRInterval_kurtosis_lead12</th>\n",
       "      <th>R_peaks_amplitude_from_isoelectric_mean_lead12</th>\n",
       "      <th>Qcount_lead12</th>\n",
       "      <th>PR_segment_mean_lead12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.436130</td>\n",
       "      <td>1</td>\n",
       "      <td>1.790836</td>\n",
       "      <td>0.489525</td>\n",
       "      <td>1.005687</td>\n",
       "      <td>1.136613</td>\n",
       "      <td>0.667261</td>\n",
       "      <td>1.324888</td>\n",
       "      <td>0.497929</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.426137</td>\n",
       "      <td>1.791626</td>\n",
       "      <td>0.489675</td>\n",
       "      <td>1.052401</td>\n",
       "      <td>-0.009576</td>\n",
       "      <td>-1.247569</td>\n",
       "      <td>1.980089</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.458073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.182696</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820800</td>\n",
       "      <td>1.116772</td>\n",
       "      <td>3.179971</td>\n",
       "      <td>0.619290</td>\n",
       "      <td>1.695107</td>\n",
       "      <td>4.784317</td>\n",
       "      <td>1.824051</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.443657</td>\n",
       "      <td>0.821162</td>\n",
       "      <td>1.081985</td>\n",
       "      <td>3.964045</td>\n",
       "      <td>1.644825</td>\n",
       "      <td>2.326858</td>\n",
       "      <td>0.828798</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.576232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.726513</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820800</td>\n",
       "      <td>1.141216</td>\n",
       "      <td>0.361658</td>\n",
       "      <td>0.204018</td>\n",
       "      <td>1.083074</td>\n",
       "      <td>1.236562</td>\n",
       "      <td>0.446568</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.211109</td>\n",
       "      <td>0.821162</td>\n",
       "      <td>1.145049</td>\n",
       "      <td>0.327414</td>\n",
       "      <td>-0.079076</td>\n",
       "      <td>-1.543403</td>\n",
       "      <td>0.794161</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.892038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.098217</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671563</td>\n",
       "      <td>1.287325</td>\n",
       "      <td>0.175123</td>\n",
       "      <td>0.629861</td>\n",
       "      <td>0.908436</td>\n",
       "      <td>-0.121448</td>\n",
       "      <td>1.277346</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.848128</td>\n",
       "      <td>0.671860</td>\n",
       "      <td>1.284780</td>\n",
       "      <td>0.187094</td>\n",
       "      <td>0.910720</td>\n",
       "      <td>-0.450520</td>\n",
       "      <td>1.107166</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.458602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.692722</td>\n",
       "      <td>0</td>\n",
       "      <td>0.746182</td>\n",
       "      <td>1.280363</td>\n",
       "      <td>0.338447</td>\n",
       "      <td>0.636173</td>\n",
       "      <td>0.954099</td>\n",
       "      <td>0.451443</td>\n",
       "      <td>1.742526</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.690343</td>\n",
       "      <td>0.746511</td>\n",
       "      <td>1.278597</td>\n",
       "      <td>0.362494</td>\n",
       "      <td>0.275635</td>\n",
       "      <td>-1.027188</td>\n",
       "      <td>0.405492</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.650946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>0</td>\n",
       "      <td>1.165800</td>\n",
       "      <td>0</td>\n",
       "      <td>1.343127</td>\n",
       "      <td>0.677113</td>\n",
       "      <td>3.219273</td>\n",
       "      <td>1.376637</td>\n",
       "      <td>1.200434</td>\n",
       "      <td>2.473124</td>\n",
       "      <td>0.497239</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.285295</td>\n",
       "      <td>1.343719</td>\n",
       "      <td>0.586127</td>\n",
       "      <td>3.262444</td>\n",
       "      <td>0.953688</td>\n",
       "      <td>-0.590095</td>\n",
       "      <td>0.951139</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.301893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>0</td>\n",
       "      <td>1.250278</td>\n",
       "      <td>1</td>\n",
       "      <td>1.492363</td>\n",
       "      <td>0.588944</td>\n",
       "      <td>1.094960</td>\n",
       "      <td>0.293431</td>\n",
       "      <td>0.935673</td>\n",
       "      <td>2.257216</td>\n",
       "      <td>0.448087</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.574858</td>\n",
       "      <td>1.493021</td>\n",
       "      <td>0.566342</td>\n",
       "      <td>1.192722</td>\n",
       "      <td>2.522238</td>\n",
       "      <td>4.465922</td>\n",
       "      <td>0.750163</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.762725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>1</td>\n",
       "      <td>0.895469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671563</td>\n",
       "      <td>1.289177</td>\n",
       "      <td>0.474791</td>\n",
       "      <td>0.019671</td>\n",
       "      <td>1.619805</td>\n",
       "      <td>2.572491</td>\n",
       "      <td>0.042581</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.800850</td>\n",
       "      <td>0.671860</td>\n",
       "      <td>1.290962</td>\n",
       "      <td>0.479427</td>\n",
       "      <td>0.356419</td>\n",
       "      <td>-0.924803</td>\n",
       "      <td>0.809545</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.582848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1</td>\n",
       "      <td>1.334756</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596945</td>\n",
       "      <td>1.426785</td>\n",
       "      <td>0.318640</td>\n",
       "      <td>0.351651</td>\n",
       "      <td>0.590518</td>\n",
       "      <td>-0.656135</td>\n",
       "      <td>0.365226</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.470499</td>\n",
       "      <td>0.597209</td>\n",
       "      <td>1.422037</td>\n",
       "      <td>0.268947</td>\n",
       "      <td>0.074376</td>\n",
       "      <td>-1.533974</td>\n",
       "      <td>0.843326</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.220426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>2</td>\n",
       "      <td>1.385443</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820800</td>\n",
       "      <td>1.088871</td>\n",
       "      <td>1.334511</td>\n",
       "      <td>1.566274</td>\n",
       "      <td>0.907902</td>\n",
       "      <td>1.266004</td>\n",
       "      <td>3.125237</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.428402</td>\n",
       "      <td>0.821162</td>\n",
       "      <td>1.103006</td>\n",
       "      <td>0.292334</td>\n",
       "      <td>-0.331329</td>\n",
       "      <td>-1.715118</td>\n",
       "      <td>0.937993</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.758636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rhythm  PatientAge  Gender  Rcount_lead1  RRInterval_mean_lead1  \\\n",
       "0          0    1.436130       1      1.790836               0.489525   \n",
       "1          0    1.182696       1      0.820800               1.116772   \n",
       "2          2    0.726513       0      0.820800               1.141216   \n",
       "3          1    1.098217       1      0.671563               1.287325   \n",
       "4          1    0.692722       0      0.746182               1.280363   \n",
       "...      ...         ...     ...           ...                    ...   \n",
       "2125       0    1.165800       0      1.343127               0.677113   \n",
       "2126       0    1.250278       1      1.492363               0.588944   \n",
       "2127       1    0.895469       0      0.671563               1.289177   \n",
       "2128       1    1.334756       1      0.596945               1.426785   \n",
       "2129       2    1.385443       1      0.820800               1.088871   \n",
       "\n",
       "      RRInterval_std_lead1  QT_intervals_var_lead1  PR_intervals_mean_lead1  \\\n",
       "0                 1.005687                1.136613                 0.667261   \n",
       "1                 3.179971                0.619290                 1.695107   \n",
       "2                 0.361658                0.204018                 1.083074   \n",
       "3                 0.175123                0.629861                 0.908436   \n",
       "4                 0.338447                0.636173                 0.954099   \n",
       "...                    ...                     ...                      ...   \n",
       "2125              3.219273                1.376637                 1.200434   \n",
       "2126              1.094960                0.293431                 0.935673   \n",
       "2127              0.474791                0.019671                 1.619805   \n",
       "2128              0.318640                0.351651                 0.590518   \n",
       "2129              1.334511                1.566274                 0.907902   \n",
       "\n",
       "      PR_segment_mean_lead1  PR_segment_var_lead1  ...  Qcount_lead11  \\\n",
       "0                  1.324888              0.497929  ...           11.0   \n",
       "1                  4.784317              1.824051  ...            7.0   \n",
       "2                  1.236562              0.446568  ...           10.0   \n",
       "3                 -0.121448              1.277346  ...            2.0   \n",
       "4                  0.451443              1.742526  ...            9.0   \n",
       "...                     ...                   ...  ...            ...   \n",
       "2125               2.473124              0.497239  ...           14.0   \n",
       "2126               2.257216              0.448087  ...           13.0   \n",
       "2127               2.572491              0.042581  ...            2.0   \n",
       "2128              -0.656135              0.365226  ...            7.0   \n",
       "2129               1.266004              3.125237  ...            7.0   \n",
       "\n",
       "      ST_segment_mean_lead11  Rcount_lead12  RRInterval_median_lead12  \\\n",
       "0                   0.426137       1.791626                  0.489675   \n",
       "1                   1.443657       0.821162                  1.081985   \n",
       "2                   1.211109       0.821162                  1.145049   \n",
       "3                   0.848128       0.671860                  1.284780   \n",
       "4                   1.690343       0.746511                  1.278597   \n",
       "...                      ...            ...                       ...   \n",
       "2125                0.285295       1.343719                  0.586127   \n",
       "2126                0.574858       1.493021                  0.566342   \n",
       "2127                1.800850       0.671860                  1.290962   \n",
       "2128                1.470499       0.597209                  1.422037   \n",
       "2129                1.428402       0.821162                  1.103006   \n",
       "\n",
       "      RRInterval_range_lead12  RRInterval_skew_lead12  \\\n",
       "0                    1.052401               -0.009576   \n",
       "1                    3.964045                1.644825   \n",
       "2                    0.327414               -0.079076   \n",
       "3                    0.187094                0.910720   \n",
       "4                    0.362494                0.275635   \n",
       "...                       ...                     ...   \n",
       "2125                 3.262444                0.953688   \n",
       "2126                 1.192722                2.522238   \n",
       "2127                 0.479427                0.356419   \n",
       "2128                 0.268947                0.074376   \n",
       "2129                 0.292334               -0.331329   \n",
       "\n",
       "      RRInterval_kurtosis_lead12  \\\n",
       "0                      -1.247569   \n",
       "1                       2.326858   \n",
       "2                      -1.543403   \n",
       "3                      -0.450520   \n",
       "4                      -1.027188   \n",
       "...                          ...   \n",
       "2125                   -0.590095   \n",
       "2126                    4.465922   \n",
       "2127                   -0.924803   \n",
       "2128                   -1.533974   \n",
       "2129                   -1.715118   \n",
       "\n",
       "      R_peaks_amplitude_from_isoelectric_mean_lead12  Qcount_lead12  \\\n",
       "0                                           1.980089           10.0   \n",
       "1                                           0.828798            8.0   \n",
       "2                                           0.794161            4.0   \n",
       "3                                           1.107166            8.0   \n",
       "4                                           0.405492            9.0   \n",
       "...                                              ...            ...   \n",
       "2125                                        0.951139           17.0   \n",
       "2126                                        0.750163           15.0   \n",
       "2127                                        0.809545            3.0   \n",
       "2128                                        0.843326            7.0   \n",
       "2129                                        0.937993            7.0   \n",
       "\n",
       "      PR_segment_mean_lead12  \n",
       "0                   0.458073  \n",
       "1                   2.576232  \n",
       "2                   0.892038  \n",
       "3                  -1.458602  \n",
       "4                   0.650946  \n",
       "...                      ...  \n",
       "2125                1.301893  \n",
       "2126                0.762725  \n",
       "2127                8.582848  \n",
       "2128               -0.220426  \n",
       "2129                5.758636  \n",
       "\n",
       "[2130 rows x 107 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../df_test_psos.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4258, 106)\n",
      "Vallidation: (4258, 106)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 5, max_features= 'sqrt', n_estimators= 1000)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 50)\n",
    "knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 100, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.1,max_depth= 5,min_child_weight= 1,n_estimators= 1000)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 5,max_features= 'sqrt',splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features='sqrt')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "# rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "svc_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    # rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    knn_clf.predict_proba(x_val),\n",
    "    svc_clf.predict_proba(x_val),\n",
    "    xgb_clf.predict_proba(x_val),\n",
    "    dt_clf.predict_proba(x_val)\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    # rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    knn_clf.predict_proba(x_test),\n",
    "    svc_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    dt_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4258, 20)\n",
      "X_test_meta:(2130, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.952, test=0.954) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.959, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.960, test=0.952) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.956, test=0.961) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.958, test=0.952) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.963, test=0.949) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.956, test=0.962) total time=   0.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.961, test=0.953) total time=   0.2s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.963, test=0.951) total time=   0.2s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.957, test=0.961) total time=   2.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.960, test=0.953) total time=   2.2s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.962, test=0.949) total time=   2.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.954, test=0.961) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.958, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.958, test=0.949) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.956, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.959, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.962, test=0.949) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.955, test=0.961) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.959, test=0.953) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.962, test=0.949) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.956, test=0.961) total time=   2.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.961, test=0.954) total time=   2.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.962, test=0.949) total time=   2.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.957, test=0.965) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.962, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.966, test=0.951) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.960, test=0.963) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.964, test=0.957) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.965, test=0.951) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.958, test=0.963) total time=   0.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.964, test=0.956) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.966, test=0.951) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.959, test=0.963) total time=   2.4s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.964, test=0.957) total time=   2.6s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.965, test=0.952) total time=   2.4s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.959, test=0.965) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.961, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.965, test=0.953) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.959, test=0.963) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.963, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.966, test=0.952) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.959, test=0.962) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.964, test=0.956) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.965, test=0.951) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.959, test=0.963) total time=   2.4s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.964, test=0.957) total time=   2.3s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.965, test=0.951) total time=   2.4s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.962, test=0.965) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.967, test=0.952) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.968, test=0.951) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.963, test=0.965) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.969, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.969, test=0.952) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.963, test=0.965) total time=   0.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.968, test=0.955) total time=   0.2s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.970, test=0.951) total time=   0.2s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.964, test=0.963) total time=   2.7s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.968, test=0.954) total time=   2.9s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.970, test=0.953) total time=   3.3s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.962, test=0.961) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.966, test=0.957) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.967, test=0.949) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.964, test=0.963) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.968, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.970, test=0.953) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.963, test=0.965) total time=   0.2s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.969, test=0.953) total time=   0.2s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.971, test=0.953) total time=   0.2s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.964, test=0.965) total time=   2.9s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.968, test=0.955) total time=   2.9s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.970, test=0.952) total time=   2.7s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.955, test=0.956) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.962, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.961, test=0.949) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.954, test=0.961) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.959, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.962, test=0.950) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.955, test=0.961) total time=   0.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.958, test=0.953) total time=   0.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.961, test=0.951) total time=   0.2s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.955, test=0.961) total time=   2.7s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.961, test=0.954) total time=   2.6s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.962, test=0.951) total time=   2.5s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.955, test=0.960) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.958, test=0.952) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.959, test=0.949) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.955, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.960, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.962, test=0.949) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.953, test=0.961) total time=   0.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.960, test=0.953) total time=   0.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.961, test=0.952) total time=   0.2s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.955, test=0.961) total time=   2.8s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.959, test=0.953) total time=   2.8s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.962, test=0.950) total time=   2.7s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.958, test=0.963) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.964, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.962, test=0.952) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.959, test=0.963) total time=   0.1s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.965, test=0.955) total time=   0.1s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.964, test=0.951) total time=   0.1s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.958, test=0.963) total time=   0.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.963, test=0.954) total time=   0.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.964, test=0.952) total time=   0.2s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.957, test=0.963) total time=   3.3s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.963, test=0.955) total time=   3.3s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.964, test=0.951) total time=   3.2s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.958, test=0.959) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.966, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.965, test=0.954) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.958, test=0.963) total time=   0.1s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.964, test=0.955) total time=   0.1s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.963, test=0.951) total time=   0.1s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.958, test=0.963) total time=   0.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.965, test=0.955) total time=   0.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.965, test=0.951) total time=   0.4s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.957, test=0.963) total time=   7.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.965, test=0.956) total time=   6.7s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.964, test=0.951) total time=   6.6s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.962, test=0.961) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.966, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.970, test=0.953) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.961, test=0.967) total time=   0.3s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.968, test=0.955) total time=   0.3s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.968, test=0.951) total time=   0.3s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.962, test=0.963) total time=   0.7s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.968, test=0.956) total time=   0.7s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.970, test=0.951) total time=   0.7s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.963, test=0.965) total time=   7.5s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.968, test=0.954) total time=   7.1s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.969, test=0.951) total time=   7.3s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.961, test=0.963) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.967, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.969, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.963, test=0.963) total time=   0.3s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.968, test=0.956) total time=   0.3s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.969, test=0.951) total time=   0.3s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.963, test=0.965) total time=   0.7s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.969, test=0.954) total time=   0.6s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.969, test=0.952) total time=   0.7s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.964, test=0.963) total time=   5.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.968, test=0.954) total time=   3.4s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.969, test=0.951) total time=   3.4s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.956, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.955, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.961, test=0.951) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.955, test=0.961) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.959, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.960, test=0.951) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.956, test=0.961) total time=   0.2s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.959, test=0.953) total time=   0.2s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.960, test=0.949) total time=   0.2s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.955, test=0.961) total time=   2.6s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.960, test=0.953) total time=   2.5s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.961, test=0.951) total time=   2.5s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.955, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.961, test=0.952) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.962, test=0.953) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.954, test=0.962) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.958, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.962, test=0.949) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.954, test=0.961) total time=   0.2s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.959, test=0.953) total time=   0.2s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.963, test=0.950) total time=   0.2s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.955, test=0.961) total time=   2.6s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.959, test=0.953) total time=   2.8s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.961, test=0.950) total time=   2.8s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.959, test=0.964) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.958, test=0.952) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.964, test=0.951) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.958, test=0.963) total time=   0.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.965, test=0.956) total time=   0.1s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.963, test=0.952) total time=   0.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.958, test=0.963) total time=   0.2s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.963, test=0.955) total time=   0.3s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.964, test=0.951) total time=   0.2s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.958, test=0.963) total time=   3.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.964, test=0.955) total time=   3.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.964, test=0.951) total time=   3.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.957, test=0.964) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.965, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.965, test=0.951) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.958, test=0.963) total time=   0.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.964, test=0.952) total time=   0.1s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.964, test=0.949) total time=   0.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.958, test=0.963) total time=   0.3s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.963, test=0.954) total time=   0.2s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.964, test=0.951) total time=   0.2s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.958, test=0.962) total time=   3.6s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.964, test=0.956) total time=   6.7s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.964, test=0.952) total time=   5.5s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.962, test=0.964) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.969, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.967, test=0.949) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.961, test=0.963) total time=   0.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.968, test=0.954) total time=   0.1s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.970, test=0.949) total time=   0.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.962, test=0.965) total time=   0.3s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.968, test=0.956) total time=   0.3s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.970, test=0.953) total time=   0.3s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.962, test=0.965) total time=   3.5s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.968, test=0.954) total time=   3.4s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.968, test=0.951) total time=   3.3s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.961, test=0.964) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.965, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.966, test=0.949) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.963, test=0.965) total time=   0.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.967, test=0.955) total time=   0.1s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.971, test=0.951) total time=   0.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.962, test=0.963) total time=   0.2s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.968, test=0.955) total time=   0.2s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.970, test=0.951) total time=   0.2s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.963, test=0.965) total time=   3.4s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.968, test=0.954) total time=   3.3s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.969, test=0.951) total time=   3.4s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = RandomForestClassifier()\n",
    "params = {\n",
    "    'n_estimators': [10,50,100,1000],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [3,4,5],\n",
    "    'max_features':['sqrt', 'log2'],\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'log_loss',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9584295294907808"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.962441</td>\n",
       "      <td>0.892135</td>\n",
       "      <td>0.925408</td>\n",
       "      <td>0.908467</td>\n",
       "      <td>0.981009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.992488</td>\n",
       "      <td>0.992288</td>\n",
       "      <td>0.987212</td>\n",
       "      <td>0.989744</td>\n",
       "      <td>0.992604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.985446</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>0.965208</td>\n",
       "      <td>0.990504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.968545</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.917548</td>\n",
       "      <td>0.928342</td>\n",
       "      <td>0.976619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947940</td>\n",
       "      <td>0.948573</td>\n",
       "      <td>0.947527</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.954460</td>\n",
       "      <td>0.954460</td>\n",
       "      <td>0.954460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.954319</td>\n",
       "      <td>0.954366</td>\n",
       "      <td>0.954460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.962441  0.892135   0.925408  0.908467     0.981009\n",
       "1            SB  0.992488  0.992288   0.987212  0.989744     0.992604\n",
       "2            SR  0.985446  0.966292   0.964126  0.965208     0.990504\n",
       "3          GSVT  0.968545  0.939394   0.917548  0.928342     0.976619\n",
       "4     macro avg       NaN  0.947940   0.948573  0.947527          NaN\n",
       "5     micro avg       NaN  0.954460   0.954460  0.954460          NaN\n",
       "6  weighted avg       NaN  0.954319   0.954366  0.954460          NaN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_evaluation_test.to_csv(\"../Result/Blending_RF_182ft.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
