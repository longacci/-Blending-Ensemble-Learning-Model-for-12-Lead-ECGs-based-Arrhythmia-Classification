{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Features</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>118</td>\n",
       "      <td>0.051969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181</td>\n",
       "      <td>183</td>\n",
       "      <td>0.051825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>0.049422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>197</td>\n",
       "      <td>0.044167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>98</td>\n",
       "      <td>0.043881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>211</td>\n",
       "      <td>213</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>113</td>\n",
       "      <td>115</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  Features    Scores\n",
       "0      116       118  0.051969\n",
       "1      181       183  0.051825\n",
       "2       60        62  0.049422\n",
       "3      195       197  0.044167\n",
       "4       96        98  0.043881\n",
       "..     ...       ...       ...\n",
       "190     73        75  0.000013\n",
       "191    211       213  0.000013\n",
       "192     70        72  0.000011\n",
       "193     93        95  0.000010\n",
       "194    113       115  0.000005\n",
       "\n",
       "[195 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score = pd.read_csv(\"../Feature_selection/ft_important.csv\")\n",
    "df_score.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([116, 181,  60, 195,  96, 136,   2, 152, 168,   1, 151,  76, 135,\n",
       "       182,  40, 196,  21,  22, 170, 154, 194, 184,  39, 115,   4,  38,\n",
       "        61, 198,  95, 183,  59, 137,  31, 169, 153, 180, 138,   3, 134,\n",
       "       145, 197, 167,  23, 117, 118,  98,  24,  77,  78,  20,  94, 109,\n",
       "        11,  62,  33,  97, 128,  35,  42, 146,  15,  16, 162, 158,  75,\n",
       "        41, 205, 202,  28,  34, 148,  17, 189, 142,   5,  29, 174,  14,\n",
       "       131,  74,  55, 191, 110,  32,   0, 166, 108, 125,  79, 129, 130,\n",
       "        53, 150, 185, 164, 160, 155,  30,  12, 171,  88, 114, 199, 144,\n",
       "       104, 149, 175, 147, 188, 102, 107,  91, 161,  37,   9, 111,  63,\n",
       "       124, 200, 186, 105, 159, 206, 119, 203,  13, 133, 178, 103,  47,\n",
       "       123,  19, 106,  52, 190,  58, 139,   7,  43,  25,  72, 126,  69,\n",
       "        49,  48,  10, 100, 127,  85,  80,  86, 210,  54,  44,  90,  99,\n",
       "       179,  26,  51, 132, 208,  83, 176, 157, 172, 140, 192,  36,  71,\n",
       "       141,  18,  64,  87,  68, 207,  84,  81, 156, 122,  67,   6, 209,\n",
       "       120, 173,  27,  57, 177,  89,  56, 187,  73, 211,  70,  93, 113],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score[\"index\"].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Features</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Features    Scores\n",
       "84      0         2  0.000491"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score[df_score[\"index\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.19689985e-02, 5.18246747e-02, 4.94218848e-02, 4.41671430e-02,\n",
       "       4.38811585e-02, 4.03799799e-02, 3.74673762e-02, 3.57353090e-02,\n",
       "       3.48713687e-02, 3.09943466e-02, 3.09405326e-02, 3.03716843e-02,\n",
       "       2.55201550e-02, 2.54071527e-02, 2.52945346e-02, 2.50757547e-02,\n",
       "       2.11646913e-02, 2.05128248e-02, 2.00165862e-02, 1.77962312e-02,\n",
       "       1.69675024e-02, 1.57791574e-02, 1.46609554e-02, 1.26505979e-02,\n",
       "       1.22327995e-02, 1.20738013e-02, 1.20198411e-02, 1.14802629e-02,\n",
       "       1.09465541e-02, 1.05439461e-02, 1.02223980e-02, 8.87954118e-03,\n",
       "       8.75259418e-03, 8.65524544e-03, 8.41784225e-03, 8.30704179e-03,\n",
       "       8.19566958e-03, 7.97599203e-03, 7.69019886e-03, 6.89933746e-03,\n",
       "       6.59076846e-03, 6.40441187e-03, 6.39753082e-03, 6.33181013e-03,\n",
       "       5.79961873e-03, 5.49326791e-03, 5.23740774e-03, 4.73085137e-03,\n",
       "       4.37046464e-03, 4.24369728e-03, 4.17564127e-03, 3.33456722e-03,\n",
       "       2.98127341e-03, 2.92721490e-03, 2.83974601e-03, 2.76284083e-03,\n",
       "       2.73845849e-03, 2.63665939e-03, 2.51684766e-03, 2.34005156e-03,\n",
       "       2.27103380e-03, 2.06326229e-03, 1.87815446e-03, 1.64778365e-03,\n",
       "       1.63833763e-03, 1.46832256e-03, 1.22680318e-03, 1.13006615e-03,\n",
       "       1.06024177e-03, 9.47465380e-04, 8.31099430e-04, 8.13506644e-04,\n",
       "       7.62597219e-04, 7.43648435e-04, 7.17259561e-04, 7.09597023e-04,\n",
       "       6.87236295e-04, 6.36146919e-04, 6.20838681e-04, 5.88338913e-04,\n",
       "       5.69974631e-04, 5.44188395e-04, 5.42639195e-04, 5.20706177e-04,\n",
       "       4.90929970e-04, 4.59725691e-04, 4.18399305e-04, 3.89926334e-04,\n",
       "       3.75150936e-04, 3.71078338e-04, 3.70467612e-04, 3.51018049e-04,\n",
       "       3.50090121e-04, 3.42741597e-04, 3.40032393e-04, 3.30615889e-04,\n",
       "       3.06273497e-04, 3.02109825e-04, 2.75785008e-04, 2.70811623e-04,\n",
       "       2.67263268e-04, 2.62248764e-04, 2.40404154e-04, 2.38209190e-04,\n",
       "       2.29689641e-04, 2.28972602e-04, 2.16291371e-04, 2.08700977e-04,\n",
       "       2.05845855e-04, 2.01579825e-04, 1.92809016e-04, 1.89811638e-04,\n",
       "       1.81972220e-04, 1.78924952e-04, 1.75271944e-04, 1.70070621e-04,\n",
       "       1.63008615e-04, 1.50108750e-04, 1.47426242e-04, 1.46919919e-04,\n",
       "       1.46642221e-04, 1.43217891e-04, 1.36166551e-04, 1.34238172e-04,\n",
       "       1.31577609e-04, 1.30662812e-04, 1.30309245e-04, 1.27042142e-04,\n",
       "       1.26069699e-04, 1.20993100e-04, 1.15656520e-04, 1.15334756e-04,\n",
       "       1.10197460e-04, 1.03684453e-04, 9.86012086e-05, 9.71859455e-05,\n",
       "       9.69341101e-05, 9.61590715e-05, 9.54584298e-05, 9.34181755e-05,\n",
       "       9.09327577e-05, 8.83090361e-05, 8.55806666e-05, 8.47483300e-05,\n",
       "       7.98884597e-05, 7.83177728e-05, 7.74301384e-05, 7.35973878e-05,\n",
       "       7.00274403e-05, 6.44152359e-05, 6.22803995e-05, 6.07629684e-05,\n",
       "       5.69567496e-05, 5.50425744e-05, 5.47003459e-05, 5.22323659e-05,\n",
       "       5.17612777e-05, 5.06159140e-05, 4.96171009e-05, 4.91712159e-05,\n",
       "       4.78373282e-05, 4.77437334e-05, 4.63558440e-05, 4.51318417e-05,\n",
       "       4.47562246e-05, 4.36234416e-05, 4.32593767e-05, 4.27626204e-05,\n",
       "       4.24612522e-05, 4.06239858e-05, 3.84665382e-05, 3.45290174e-05,\n",
       "       2.79931058e-05, 2.78857885e-05, 2.58311989e-05, 2.45965834e-05,\n",
       "       2.39008747e-05, 2.35793461e-05, 2.17478459e-05, 2.05253915e-05,\n",
       "       2.04422082e-05, 1.92634673e-05, 1.86716612e-05, 1.86107063e-05,\n",
       "       1.79793484e-05, 1.75021372e-05, 1.69449615e-05, 1.53445313e-05,\n",
       "       1.43344551e-05, 1.30383026e-05, 1.29605013e-05, 1.25363124e-05,\n",
       "       1.09178562e-05, 1.04166348e-05, 4.75779662e-06])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score[\"Scores\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [df_score[df_score[\"Scores\"] > 1e-2]['Features'].values, df_score[df_score[\"Scores\"] > 1e-3]['Features'].values, df_score[df_score[\"Scores\"] > 1e-4]['Features'].values, df_score[df_score[\"Scores\"] > 1e-5]['Features'].values, df_score[df_score[\"Scores\"] > 1e-6]['Features'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>782.0</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>252.222222</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>87.777778</td>\n",
       "      <td>10339.061728</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>4315.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6555.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>697.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>594.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>1360.782222</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>420.090909</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1504.888889</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>569.437500</td>\n",
       "      <td>136.444444</td>\n",
       "      <td>43.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>615.733333</td>\n",
       "      <td>596.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.500000</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1746.285714</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>4722.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>654.428571</td>\n",
       "      <td>648.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>2686.204082</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3602.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>101.142857</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>-10.750000</td>\n",
       "      <td>7259.937500</td>\n",
       "      <td>88.222222</td>\n",
       "      <td>202.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1041.250000</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows Ã— 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2            3       4           5      6         7         8  \\\n",
       "0     0.0  10.0   950.000000  1074.0  274.986868  782.0 -0.319753 -1.432466   \n",
       "1     0.0  17.0   574.500000   582.0  104.913059  378.0  0.158313 -0.696295   \n",
       "2     3.0  16.0   593.600000   594.0    4.687572   18.0  0.396421 -0.312612   \n",
       "3     3.0  23.0   420.090909   420.0    3.591772   12.0 -0.021014 -0.856142   \n",
       "4     1.0   9.0  1068.750000  1075.0   25.118469   76.0 -0.276816 -1.271399   \n",
       "...   ...   ...          ...     ...         ...    ...       ...       ...   \n",
       "8511  3.0  16.0   615.733333   596.0   51.114860  152.0  2.153820  2.645687   \n",
       "8512  1.0   9.0  1091.500000  1093.0    5.894913   18.0 -0.311206 -1.184514   \n",
       "8513  2.0  15.0   654.428571   648.0  107.653355  458.0  0.475616  0.784000   \n",
       "8514  1.0   9.0  1075.000000  1083.0   24.535688   66.0 -0.263431 -1.567800   \n",
       "8515  1.0   9.0  1041.250000  1040.0    8.242421   22.0  0.214800 -1.575835   \n",
       "\n",
       "               9        10  ...       204         205        206        207  \\\n",
       "0     325.821586  1.000000  ...  1.000000  172.000000  10.000000   9.000000   \n",
       "1     336.569414  1.000000  ...  0.882353  -15.000000  15.000000   4.000000   \n",
       "2      94.909877  1.000000  ...  1.000000   -4.000000  16.000000  15.000000   \n",
       "3     254.059787  0.826087  ...  0.739130   -9.000000   6.000000   4.000000   \n",
       "4     461.130814  1.000000  ...  1.000000    2.000000   9.000000   8.000000   \n",
       "...          ...       ...  ...       ...         ...        ...        ...   \n",
       "8511  365.256750  1.000000  ...  0.003757    0.022262   0.003757   0.003757   \n",
       "8512  358.414529  1.000000  ...  0.888889   -3.000000   9.000000   8.000000   \n",
       "8513  180.045117  1.000000  ...  1.000000   -4.000000  15.000000  14.000000   \n",
       "8514  251.455499  1.000000  ...  1.000000   14.000000   9.000000   8.000000   \n",
       "8515  505.203302  1.000000  ...  1.000000    0.000000   9.000000   8.000000   \n",
       "\n",
       "             208           209        210           211         212  \\\n",
       "0     252.222222  10656.395062  87.777778  10339.061728  135.800000   \n",
       "1     158.000000   3944.000000  73.000000   6555.000000   -1.066667   \n",
       "2     122.400000   2058.773333  12.533333   1360.782222   95.500000   \n",
       "3      40.666667   1120.888889   5.333333   1504.888889   12.000000   \n",
       "4     122.000000    671.000000  19.750000    569.437500  136.444444   \n",
       "...          ...           ...        ...           ...         ...   \n",
       "8511    0.044242      0.044242   0.043021      0.043021    0.037385   \n",
       "8512   81.428571   1294.530612 -40.000000   1746.285714  155.333333   \n",
       "8513   77.142857   2213.551020  -1.714286   2686.204082  104.000000   \n",
       "8514  101.142857   4933.551020 -10.750000   7259.937500   88.222222   \n",
       "8515  102.000000    350.000000 -20.000000    588.000000  150.000000   \n",
       "\n",
       "              213  \n",
       "0     4315.560000  \n",
       "1      697.528889  \n",
       "2       68.750000  \n",
       "3     1464.000000  \n",
       "4       43.358025  \n",
       "...           ...  \n",
       "8511     0.037385  \n",
       "8512  4722.666667  \n",
       "8513  3602.666667  \n",
       "8514   202.172840  \n",
       "8515     0.000000  \n",
       "\n",
       "[8516 rows x 213 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_frequency.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([118, 183,  62, 197,  98, 138,   4, 154, 170,   3, 153,  78, 137,\n",
       "       184,  42, 198,  23,  24, 172, 156, 196, 186,  41, 117,   6,  40,\n",
       "        63, 200,  97, 185,  61, 139,  33, 171, 155, 182, 140,   5, 136,\n",
       "       147, 199, 169,  25, 119, 120, 100,  26,  79,  80,  22,  96, 111,\n",
       "        13,  64,  35,  99, 130,  37,  44, 148,  17,  18, 164, 160,  77,\n",
       "        43, 207, 204,  30,  36, 150,  19, 191, 144,   7,  31, 176,  16,\n",
       "       133,  76,  57, 193, 112,  34,   2, 168, 110, 127,  81, 131, 132,\n",
       "        55, 152, 187, 166, 162, 157,  32,  14, 173,  90, 116, 201, 146,\n",
       "       106, 151, 177, 149, 190, 104, 109,  93, 163,  39,  11, 113,  65,\n",
       "       126, 202, 188, 107, 161, 208, 121, 205,  15, 135, 180, 105,  49,\n",
       "       125,  21, 108,  54, 192,  60, 141,   9,  45,  27,  74, 128,  71,\n",
       "        51,  50,  12, 102, 129,  87,  82,  88, 212,  56,  46,  92, 101,\n",
       "       181,  28,  53, 134, 210,  85, 178, 159, 174, 142, 194,  38,  73,\n",
       "       143,  20,  66,  89,  70, 209,  86,  83, 158, 124,  69,   8, 211,\n",
       "       122, 175,  29,  59, 179,  91,  58, 189,  75, 213,  72,  95],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ranks[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ft = ranks[3]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbest_ft\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\testdatasets\\lib\\site-packages\\pandas\\core\\indexing.py:1147\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\testdatasets\\lib\\site-packages\\pandas\\core\\indexing.py:1652\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m-> 1652\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tuple_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1654\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\testdatasets\\lib\\site-packages\\pandas\\core\\indexing.py:940\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 940\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation based indexing can only have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] types\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    945\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\testdatasets\\lib\\site-packages\\pandas\\core\\indexing.py:1574\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;66;03m# check that the key does not exceed the maximum size of the index\u001b[39;00m\n\u001b[0;32m   1573\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arr) \u001b[38;5;129;01mand\u001b[39;00m (arr\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis):\n\u001b[1;32m-> 1574\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only index by location with a [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "df_train = df_train.iloc[:,best_ft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>710.769231</td>\n",
       "      <td>628.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3140.437500</td>\n",
       "      <td>127.600000</td>\n",
       "      <td>1041.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>968.666667</td>\n",
       "      <td>894.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>5249.000000</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>8081.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>8070.530612</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1078.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>757.500000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>7081.416667</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>264.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>413.909091</td>\n",
       "      <td>409.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>832.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>342.857143</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>205.142857</td>\n",
       "      <td>11207.836735</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2281.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>14282.775510</td>\n",
       "      <td>169.142857</td>\n",
       "      <td>46.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>361.489796</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>2186.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.285714</td>\n",
       "      <td>996.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>-45.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows Ã— 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2       3           4      5         6          7  \\\n",
       "0     0.0  14.0   710.769231   628.0  153.204817  556.0  0.996355   0.207174   \n",
       "1     0.0  10.0   968.666667   894.0  266.399867  932.0  0.979352   0.388359   \n",
       "2     0.0  11.0   797.000000   780.0  251.329664  794.0  0.260470  -1.002325   \n",
       "3     2.0  13.0   757.500000   755.0    8.986100   26.0  0.048579  -1.449012   \n",
       "4     0.0  23.0   413.909091   409.0   82.344017  426.0  3.023659  10.404884   \n",
       "...   ...   ...          ...     ...         ...    ...       ...        ...   \n",
       "2125  1.0   9.0  1071.250000  1062.0   36.509417  118.0  1.263183   0.543003   \n",
       "2126  1.0   8.0  1196.000000  1202.0   33.839959  102.0 -0.454057  -1.036905   \n",
       "2127  3.0  16.0   595.600000   590.0   23.734082   82.0  0.371174  -0.657132   \n",
       "2128  1.0   8.0  1080.285714   996.0  180.470587  448.0  0.587475  -1.363827   \n",
       "2129  3.0  25.0   391.250000   390.0    2.569857    8.0  0.605786  -0.869886   \n",
       "\n",
       "               8         9  ...       203        204   205   206         207  \\\n",
       "0     459.037295  1.000000  ...  0.928571 -10.000000  10.0   9.0  146.000000   \n",
       "1     398.464564  1.000000  ...  0.600000  64.000000   7.0   7.0  140.500000   \n",
       "2     340.802438  1.000000  ...  1.000000  26.000000   9.0   7.0  154.285714   \n",
       "3     412.324324  1.000000  ...  1.000000  -4.000000  12.0  12.0  108.500000   \n",
       "4     168.041577  0.956522  ...  0.083333   0.022262  11.0  12.0    0.044242   \n",
       "...          ...       ...  ...       ...        ...   ...   ...         ...   \n",
       "2125  364.303573  0.888889  ...  0.777778   0.000000   9.0   8.0  342.857143   \n",
       "2126  181.876516  1.000000  ...  1.000000 -26.000000   8.0   7.0  137.666667   \n",
       "2127  137.696567  1.000000  ...  1.000000  -8.000000  16.0  14.0  102.714286   \n",
       "2128  561.988537  1.000000  ...  1.000000  18.000000   8.0   5.0   62.400000   \n",
       "2129  654.123072  0.400000  ...  0.240000   4.000000   0.0   0.0    0.044242   \n",
       "\n",
       "               208         209           210         211          212  \n",
       "0       729.000000   78.250000   3140.437500  127.600000  1041.440000  \n",
       "1     15314.750000  -27.000000   5249.000000  112.285714  8081.632653  \n",
       "2      1944.489796   18.571429   8070.530612  131.111111  1078.320988  \n",
       "3      6122.750000   46.500000   7081.416667  121.833333   264.305556  \n",
       "4         0.044242  -50.000000      0.000000   45.818182   832.330579  \n",
       "...            ...         ...           ...         ...          ...  \n",
       "2125   2843.265306  205.142857  11207.836735   96.000000  2281.142857  \n",
       "2126    228.555556   87.714286  14282.775510  169.142857    46.693878  \n",
       "2127   1270.061224    7.285714    361.489796   90.400000  2186.240000  \n",
       "2128     51.840000  -45.200000      0.960000  101.000000  5002.000000  \n",
       "2129      0.044242    0.043021      0.043021    0.037385     0.037385  \n",
       "\n",
       "[2130 rows x 213 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_frequency.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.iloc[:,best_ft]\n",
    "x_test = df_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4258, 31)\n",
      "Vallidation: (4258, 31)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 5, max_features= 'sqrt', n_estimators= 1500)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME', learning_rate= 0.1, n_estimators= 1000)\n",
    "knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 100, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.1,max_depth= 5,min_child_weight= 1,n_estimators= 1000)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 5,max_features= 'sqrt',splitter= 'best')\n",
    "lgb_clf = LGBMClassifier(boosting = 'gbdt', data_sample_strategy= 'goss', estimators=50, learning_rate = 0.1, objective= 'multiclass')\n",
    "cb_clf = CatBoostClassifier(iterations = 300, learning_rate= 1)\n",
    "gb_clf = GradientBoostingClassifier(criterion='squared_error', learning_rate = 0.1, loss= 'log_loss', n_estimators=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3864815\ttotal: 160ms\tremaining: 47.9s\n",
      "1:\tlearn: 0.3031278\ttotal: 173ms\tremaining: 25.8s\n",
      "2:\tlearn: 0.2757458\ttotal: 183ms\tremaining: 18.1s\n",
      "3:\tlearn: 0.2639367\ttotal: 193ms\tremaining: 14.3s\n",
      "4:\tlearn: 0.2507312\ttotal: 217ms\tremaining: 12.8s\n",
      "5:\tlearn: 0.2462128\ttotal: 227ms\tremaining: 11.1s\n",
      "6:\tlearn: 0.2380394\ttotal: 238ms\tremaining: 9.94s\n",
      "7:\tlearn: 0.2282590\ttotal: 247ms\tremaining: 9s\n",
      "8:\tlearn: 0.2247326\ttotal: 257ms\tremaining: 8.29s\n",
      "9:\tlearn: 0.2205787\ttotal: 266ms\tremaining: 7.7s\n",
      "10:\tlearn: 0.2171169\ttotal: 276ms\tremaining: 7.25s\n",
      "11:\tlearn: 0.2093058\ttotal: 287ms\tremaining: 6.88s\n",
      "12:\tlearn: 0.2054064\ttotal: 297ms\tremaining: 6.55s\n",
      "13:\tlearn: 0.2025478\ttotal: 307ms\tremaining: 6.28s\n",
      "14:\tlearn: 0.1946238\ttotal: 317ms\tremaining: 6.03s\n",
      "15:\tlearn: 0.1932395\ttotal: 327ms\tremaining: 5.8s\n",
      "16:\tlearn: 0.1905312\ttotal: 337ms\tremaining: 5.6s\n",
      "17:\tlearn: 0.1874070\ttotal: 347ms\tremaining: 5.43s\n",
      "18:\tlearn: 0.1843102\ttotal: 356ms\tremaining: 5.27s\n",
      "19:\tlearn: 0.1807587\ttotal: 366ms\tremaining: 5.12s\n",
      "20:\tlearn: 0.1795995\ttotal: 375ms\tremaining: 4.98s\n",
      "21:\tlearn: 0.1745121\ttotal: 385ms\tremaining: 4.87s\n",
      "22:\tlearn: 0.1703601\ttotal: 396ms\tremaining: 4.77s\n",
      "23:\tlearn: 0.1653969\ttotal: 408ms\tremaining: 4.69s\n",
      "24:\tlearn: 0.1633953\ttotal: 417ms\tremaining: 4.59s\n",
      "25:\tlearn: 0.1598840\ttotal: 427ms\tremaining: 4.5s\n",
      "26:\tlearn: 0.1579373\ttotal: 437ms\tremaining: 4.41s\n",
      "27:\tlearn: 0.1545776\ttotal: 447ms\tremaining: 4.34s\n",
      "28:\tlearn: 0.1519882\ttotal: 457ms\tremaining: 4.27s\n",
      "29:\tlearn: 0.1498583\ttotal: 468ms\tremaining: 4.21s\n",
      "30:\tlearn: 0.1472773\ttotal: 482ms\tremaining: 4.18s\n",
      "31:\tlearn: 0.1453381\ttotal: 496ms\tremaining: 4.15s\n",
      "32:\tlearn: 0.1420936\ttotal: 510ms\tremaining: 4.13s\n",
      "33:\tlearn: 0.1386805\ttotal: 522ms\tremaining: 4.08s\n",
      "34:\tlearn: 0.1352894\ttotal: 536ms\tremaining: 4.06s\n",
      "35:\tlearn: 0.1343582\ttotal: 547ms\tremaining: 4.01s\n",
      "36:\tlearn: 0.1331265\ttotal: 559ms\tremaining: 3.98s\n",
      "37:\tlearn: 0.1308566\ttotal: 574ms\tremaining: 3.95s\n",
      "38:\tlearn: 0.1301001\ttotal: 585ms\tremaining: 3.92s\n",
      "39:\tlearn: 0.1272722\ttotal: 599ms\tremaining: 3.89s\n",
      "40:\tlearn: 0.1245573\ttotal: 614ms\tremaining: 3.88s\n",
      "41:\tlearn: 0.1222024\ttotal: 626ms\tremaining: 3.84s\n",
      "42:\tlearn: 0.1204022\ttotal: 639ms\tremaining: 3.82s\n",
      "43:\tlearn: 0.1197939\ttotal: 649ms\tremaining: 3.78s\n",
      "44:\tlearn: 0.1185874\ttotal: 665ms\tremaining: 3.77s\n",
      "45:\tlearn: 0.1170440\ttotal: 678ms\tremaining: 3.75s\n",
      "46:\tlearn: 0.1158471\ttotal: 689ms\tremaining: 3.71s\n",
      "47:\tlearn: 0.1148576\ttotal: 701ms\tremaining: 3.68s\n",
      "48:\tlearn: 0.1125420\ttotal: 714ms\tremaining: 3.66s\n",
      "49:\tlearn: 0.1117754\ttotal: 731ms\tremaining: 3.65s\n",
      "50:\tlearn: 0.1097498\ttotal: 743ms\tremaining: 3.63s\n",
      "51:\tlearn: 0.1091153\ttotal: 753ms\tremaining: 3.59s\n",
      "52:\tlearn: 0.1075460\ttotal: 765ms\tremaining: 3.57s\n",
      "53:\tlearn: 0.1046951\ttotal: 776ms\tremaining: 3.54s\n",
      "54:\tlearn: 0.1027250\ttotal: 786ms\tremaining: 3.5s\n",
      "55:\tlearn: 0.1020278\ttotal: 798ms\tremaining: 3.48s\n",
      "56:\tlearn: 0.1010033\ttotal: 810ms\tremaining: 3.45s\n",
      "57:\tlearn: 0.0998898\ttotal: 823ms\tremaining: 3.44s\n",
      "58:\tlearn: 0.0990421\ttotal: 835ms\tremaining: 3.41s\n",
      "59:\tlearn: 0.0972685\ttotal: 845ms\tremaining: 3.38s\n",
      "60:\tlearn: 0.0950811\ttotal: 857ms\tremaining: 3.36s\n",
      "61:\tlearn: 0.0942838\ttotal: 871ms\tremaining: 3.34s\n",
      "62:\tlearn: 0.0936777\ttotal: 884ms\tremaining: 3.33s\n",
      "63:\tlearn: 0.0917421\ttotal: 897ms\tremaining: 3.31s\n",
      "64:\tlearn: 0.0894149\ttotal: 914ms\tremaining: 3.3s\n",
      "65:\tlearn: 0.0884388\ttotal: 932ms\tremaining: 3.3s\n",
      "66:\tlearn: 0.0879666\ttotal: 944ms\tremaining: 3.28s\n",
      "67:\tlearn: 0.0872467\ttotal: 956ms\tremaining: 3.26s\n",
      "68:\tlearn: 0.0868351\ttotal: 969ms\tremaining: 3.25s\n",
      "69:\tlearn: 0.0859260\ttotal: 986ms\tremaining: 3.24s\n",
      "70:\tlearn: 0.0836104\ttotal: 1s\tremaining: 3.23s\n",
      "71:\tlearn: 0.0822143\ttotal: 1.01s\tremaining: 3.21s\n",
      "72:\tlearn: 0.0812369\ttotal: 1.03s\tremaining: 3.19s\n",
      "73:\tlearn: 0.0800797\ttotal: 1.04s\tremaining: 3.18s\n",
      "74:\tlearn: 0.0791979\ttotal: 1.05s\tremaining: 3.16s\n",
      "75:\tlearn: 0.0779401\ttotal: 1.06s\tremaining: 3.13s\n",
      "76:\tlearn: 0.0769826\ttotal: 1.07s\tremaining: 3.11s\n",
      "77:\tlearn: 0.0763136\ttotal: 1.08s\tremaining: 3.09s\n",
      "78:\tlearn: 0.0756518\ttotal: 1.1s\tremaining: 3.07s\n",
      "79:\tlearn: 0.0743253\ttotal: 1.11s\tremaining: 3.05s\n",
      "80:\tlearn: 0.0735041\ttotal: 1.12s\tremaining: 3.03s\n",
      "81:\tlearn: 0.0730693\ttotal: 1.13s\tremaining: 3.01s\n",
      "82:\tlearn: 0.0719254\ttotal: 1.15s\tremaining: 3s\n",
      "83:\tlearn: 0.0714713\ttotal: 1.16s\tremaining: 2.99s\n",
      "84:\tlearn: 0.0700426\ttotal: 1.17s\tremaining: 2.97s\n",
      "85:\tlearn: 0.0693566\ttotal: 1.19s\tremaining: 2.95s\n",
      "86:\tlearn: 0.0679764\ttotal: 1.2s\tremaining: 2.93s\n",
      "87:\tlearn: 0.0676061\ttotal: 1.21s\tremaining: 2.91s\n",
      "88:\tlearn: 0.0667279\ttotal: 1.22s\tremaining: 2.89s\n",
      "89:\tlearn: 0.0660274\ttotal: 1.23s\tremaining: 2.87s\n",
      "90:\tlearn: 0.0651975\ttotal: 1.24s\tremaining: 2.85s\n",
      "91:\tlearn: 0.0646827\ttotal: 1.25s\tremaining: 2.83s\n",
      "92:\tlearn: 0.0636311\ttotal: 1.26s\tremaining: 2.81s\n",
      "93:\tlearn: 0.0628186\ttotal: 1.27s\tremaining: 2.79s\n",
      "94:\tlearn: 0.0614907\ttotal: 1.28s\tremaining: 2.77s\n",
      "95:\tlearn: 0.0606203\ttotal: 1.29s\tremaining: 2.75s\n",
      "96:\tlearn: 0.0593134\ttotal: 1.31s\tremaining: 2.73s\n",
      "97:\tlearn: 0.0585294\ttotal: 1.32s\tremaining: 2.72s\n",
      "98:\tlearn: 0.0577851\ttotal: 1.33s\tremaining: 2.7s\n",
      "99:\tlearn: 0.0571560\ttotal: 1.34s\tremaining: 2.68s\n",
      "100:\tlearn: 0.0565696\ttotal: 1.35s\tremaining: 2.66s\n",
      "101:\tlearn: 0.0560099\ttotal: 1.36s\tremaining: 2.64s\n",
      "102:\tlearn: 0.0549375\ttotal: 1.37s\tremaining: 2.62s\n",
      "103:\tlearn: 0.0543168\ttotal: 1.38s\tremaining: 2.6s\n",
      "104:\tlearn: 0.0539762\ttotal: 1.39s\tremaining: 2.58s\n",
      "105:\tlearn: 0.0534363\ttotal: 1.4s\tremaining: 2.57s\n",
      "106:\tlearn: 0.0531462\ttotal: 1.42s\tremaining: 2.56s\n",
      "107:\tlearn: 0.0525907\ttotal: 1.43s\tremaining: 2.55s\n",
      "108:\tlearn: 0.0519109\ttotal: 1.45s\tremaining: 2.53s\n",
      "109:\tlearn: 0.0513974\ttotal: 1.46s\tremaining: 2.51s\n",
      "110:\tlearn: 0.0508632\ttotal: 1.47s\tremaining: 2.5s\n",
      "111:\tlearn: 0.0503714\ttotal: 1.48s\tremaining: 2.48s\n",
      "112:\tlearn: 0.0499744\ttotal: 1.49s\tremaining: 2.46s\n",
      "113:\tlearn: 0.0494667\ttotal: 1.5s\tremaining: 2.44s\n",
      "114:\tlearn: 0.0487575\ttotal: 1.51s\tremaining: 2.43s\n",
      "115:\tlearn: 0.0480229\ttotal: 1.52s\tremaining: 2.41s\n",
      "116:\tlearn: 0.0477099\ttotal: 1.53s\tremaining: 2.39s\n",
      "117:\tlearn: 0.0474474\ttotal: 1.54s\tremaining: 2.37s\n",
      "118:\tlearn: 0.0471411\ttotal: 1.55s\tremaining: 2.36s\n",
      "119:\tlearn: 0.0465198\ttotal: 1.56s\tremaining: 2.34s\n",
      "120:\tlearn: 0.0462396\ttotal: 1.57s\tremaining: 2.33s\n",
      "121:\tlearn: 0.0458282\ttotal: 1.58s\tremaining: 2.31s\n",
      "122:\tlearn: 0.0448403\ttotal: 1.6s\tremaining: 2.3s\n",
      "123:\tlearn: 0.0444769\ttotal: 1.62s\tremaining: 2.3s\n",
      "124:\tlearn: 0.0439089\ttotal: 1.63s\tremaining: 2.29s\n",
      "125:\tlearn: 0.0433212\ttotal: 1.65s\tremaining: 2.27s\n",
      "126:\tlearn: 0.0428713\ttotal: 1.66s\tremaining: 2.26s\n",
      "127:\tlearn: 0.0426070\ttotal: 1.67s\tremaining: 2.25s\n",
      "128:\tlearn: 0.0422097\ttotal: 1.69s\tremaining: 2.23s\n",
      "129:\tlearn: 0.0418208\ttotal: 1.7s\tremaining: 2.22s\n",
      "130:\tlearn: 0.0416278\ttotal: 1.71s\tremaining: 2.2s\n",
      "131:\tlearn: 0.0410889\ttotal: 1.72s\tremaining: 2.18s\n",
      "132:\tlearn: 0.0407148\ttotal: 1.73s\tremaining: 2.17s\n",
      "133:\tlearn: 0.0402843\ttotal: 1.74s\tremaining: 2.15s\n",
      "134:\tlearn: 0.0401269\ttotal: 1.75s\tremaining: 2.13s\n",
      "135:\tlearn: 0.0397019\ttotal: 1.75s\tremaining: 2.12s\n",
      "136:\tlearn: 0.0389984\ttotal: 1.76s\tremaining: 2.1s\n",
      "137:\tlearn: 0.0388085\ttotal: 1.77s\tremaining: 2.08s\n",
      "138:\tlearn: 0.0384978\ttotal: 1.78s\tremaining: 2.06s\n",
      "139:\tlearn: 0.0382177\ttotal: 1.79s\tremaining: 2.05s\n",
      "140:\tlearn: 0.0380289\ttotal: 1.8s\tremaining: 2.03s\n",
      "141:\tlearn: 0.0377187\ttotal: 1.81s\tremaining: 2.02s\n",
      "142:\tlearn: 0.0374321\ttotal: 1.82s\tremaining: 2s\n",
      "143:\tlearn: 0.0370435\ttotal: 1.83s\tremaining: 1.99s\n",
      "144:\tlearn: 0.0365981\ttotal: 1.84s\tremaining: 1.97s\n",
      "145:\tlearn: 0.0362773\ttotal: 1.85s\tremaining: 1.96s\n",
      "146:\tlearn: 0.0358971\ttotal: 1.86s\tremaining: 1.94s\n",
      "147:\tlearn: 0.0356322\ttotal: 1.87s\tremaining: 1.92s\n",
      "148:\tlearn: 0.0352179\ttotal: 1.88s\tremaining: 1.91s\n",
      "149:\tlearn: 0.0350146\ttotal: 1.9s\tremaining: 1.9s\n",
      "150:\tlearn: 0.0346914\ttotal: 1.9s\tremaining: 1.88s\n",
      "151:\tlearn: 0.0341829\ttotal: 1.92s\tremaining: 1.87s\n",
      "152:\tlearn: 0.0338050\ttotal: 1.93s\tremaining: 1.85s\n",
      "153:\tlearn: 0.0332298\ttotal: 1.94s\tremaining: 1.84s\n",
      "154:\tlearn: 0.0329886\ttotal: 1.95s\tremaining: 1.82s\n",
      "155:\tlearn: 0.0327010\ttotal: 1.96s\tremaining: 1.81s\n",
      "156:\tlearn: 0.0324260\ttotal: 1.97s\tremaining: 1.79s\n",
      "157:\tlearn: 0.0321785\ttotal: 1.98s\tremaining: 1.78s\n",
      "158:\tlearn: 0.0318444\ttotal: 1.99s\tremaining: 1.76s\n",
      "159:\tlearn: 0.0317273\ttotal: 1.99s\tremaining: 1.75s\n",
      "160:\tlearn: 0.0314333\ttotal: 2s\tremaining: 1.73s\n",
      "161:\tlearn: 0.0308995\ttotal: 2.01s\tremaining: 1.71s\n",
      "162:\tlearn: 0.0307577\ttotal: 2.02s\tremaining: 1.7s\n",
      "163:\tlearn: 0.0305826\ttotal: 2.03s\tremaining: 1.68s\n",
      "164:\tlearn: 0.0302089\ttotal: 2.04s\tremaining: 1.67s\n",
      "165:\tlearn: 0.0300098\ttotal: 2.05s\tremaining: 1.65s\n",
      "166:\tlearn: 0.0294502\ttotal: 2.06s\tremaining: 1.64s\n",
      "167:\tlearn: 0.0291963\ttotal: 2.06s\tremaining: 1.62s\n",
      "168:\tlearn: 0.0289963\ttotal: 2.07s\tremaining: 1.61s\n",
      "169:\tlearn: 0.0287837\ttotal: 2.08s\tremaining: 1.59s\n",
      "170:\tlearn: 0.0286378\ttotal: 2.09s\tremaining: 1.58s\n",
      "171:\tlearn: 0.0284738\ttotal: 2.1s\tremaining: 1.56s\n",
      "172:\tlearn: 0.0283488\ttotal: 2.11s\tremaining: 1.55s\n",
      "173:\tlearn: 0.0279513\ttotal: 2.12s\tremaining: 1.54s\n",
      "174:\tlearn: 0.0276844\ttotal: 2.13s\tremaining: 1.52s\n",
      "175:\tlearn: 0.0275430\ttotal: 2.14s\tremaining: 1.51s\n",
      "176:\tlearn: 0.0273682\ttotal: 2.15s\tremaining: 1.49s\n",
      "177:\tlearn: 0.0272579\ttotal: 2.16s\tremaining: 1.48s\n",
      "178:\tlearn: 0.0270169\ttotal: 2.17s\tremaining: 1.46s\n",
      "179:\tlearn: 0.0268786\ttotal: 2.17s\tremaining: 1.45s\n",
      "180:\tlearn: 0.0267863\ttotal: 2.18s\tremaining: 1.44s\n",
      "181:\tlearn: 0.0265330\ttotal: 2.19s\tremaining: 1.42s\n",
      "182:\tlearn: 0.0264104\ttotal: 2.2s\tremaining: 1.41s\n",
      "183:\tlearn: 0.0263088\ttotal: 2.21s\tremaining: 1.39s\n",
      "184:\tlearn: 0.0261219\ttotal: 2.22s\tremaining: 1.38s\n",
      "185:\tlearn: 0.0259204\ttotal: 2.23s\tremaining: 1.37s\n",
      "186:\tlearn: 0.0257639\ttotal: 2.24s\tremaining: 1.35s\n",
      "187:\tlearn: 0.0255660\ttotal: 2.25s\tremaining: 1.34s\n",
      "188:\tlearn: 0.0254088\ttotal: 2.26s\tremaining: 1.32s\n",
      "189:\tlearn: 0.0252115\ttotal: 2.27s\tremaining: 1.31s\n",
      "190:\tlearn: 0.0250786\ttotal: 2.28s\tremaining: 1.3s\n",
      "191:\tlearn: 0.0250175\ttotal: 2.29s\tremaining: 1.28s\n",
      "192:\tlearn: 0.0248848\ttotal: 2.29s\tremaining: 1.27s\n",
      "193:\tlearn: 0.0247305\ttotal: 2.3s\tremaining: 1.26s\n",
      "194:\tlearn: 0.0246279\ttotal: 2.31s\tremaining: 1.25s\n",
      "195:\tlearn: 0.0244943\ttotal: 2.32s\tremaining: 1.23s\n",
      "196:\tlearn: 0.0243005\ttotal: 2.33s\tremaining: 1.22s\n",
      "197:\tlearn: 0.0240336\ttotal: 2.34s\tremaining: 1.21s\n",
      "198:\tlearn: 0.0239243\ttotal: 2.35s\tremaining: 1.19s\n",
      "199:\tlearn: 0.0237239\ttotal: 2.36s\tremaining: 1.18s\n",
      "200:\tlearn: 0.0236114\ttotal: 2.37s\tremaining: 1.17s\n",
      "201:\tlearn: 0.0235321\ttotal: 2.38s\tremaining: 1.15s\n",
      "202:\tlearn: 0.0234566\ttotal: 2.39s\tremaining: 1.14s\n",
      "203:\tlearn: 0.0233032\ttotal: 2.4s\tremaining: 1.13s\n",
      "204:\tlearn: 0.0232354\ttotal: 2.41s\tremaining: 1.11s\n",
      "205:\tlearn: 0.0230490\ttotal: 2.42s\tremaining: 1.1s\n",
      "206:\tlearn: 0.0229586\ttotal: 2.43s\tremaining: 1.09s\n",
      "207:\tlearn: 0.0228258\ttotal: 2.44s\tremaining: 1.08s\n",
      "208:\tlearn: 0.0226550\ttotal: 2.44s\tremaining: 1.06s\n",
      "209:\tlearn: 0.0225198\ttotal: 2.45s\tremaining: 1.05s\n",
      "210:\tlearn: 0.0222728\ttotal: 2.46s\tremaining: 1.04s\n",
      "211:\tlearn: 0.0220915\ttotal: 2.48s\tremaining: 1.03s\n",
      "212:\tlearn: 0.0218755\ttotal: 2.49s\tremaining: 1.01s\n",
      "213:\tlearn: 0.0217754\ttotal: 2.5s\tremaining: 1s\n",
      "214:\tlearn: 0.0216907\ttotal: 2.5s\tremaining: 990ms\n",
      "215:\tlearn: 0.0215610\ttotal: 2.51s\tremaining: 978ms\n",
      "216:\tlearn: 0.0214308\ttotal: 2.52s\tremaining: 966ms\n",
      "217:\tlearn: 0.0213662\ttotal: 2.54s\tremaining: 954ms\n",
      "218:\tlearn: 0.0212523\ttotal: 2.54s\tremaining: 941ms\n",
      "219:\tlearn: 0.0210305\ttotal: 2.56s\tremaining: 929ms\n",
      "220:\tlearn: 0.0208651\ttotal: 2.56s\tremaining: 917ms\n",
      "221:\tlearn: 0.0207667\ttotal: 2.58s\tremaining: 905ms\n",
      "222:\tlearn: 0.0204328\ttotal: 2.58s\tremaining: 893ms\n",
      "223:\tlearn: 0.0201927\ttotal: 2.6s\tremaining: 881ms\n",
      "224:\tlearn: 0.0200128\ttotal: 2.6s\tremaining: 868ms\n",
      "225:\tlearn: 0.0198247\ttotal: 2.62s\tremaining: 856ms\n",
      "226:\tlearn: 0.0197022\ttotal: 2.63s\tremaining: 845ms\n",
      "227:\tlearn: 0.0195593\ttotal: 2.63s\tremaining: 832ms\n",
      "228:\tlearn: 0.0194982\ttotal: 2.65s\tremaining: 820ms\n",
      "229:\tlearn: 0.0193371\ttotal: 2.65s\tremaining: 808ms\n",
      "230:\tlearn: 0.0191117\ttotal: 2.67s\tremaining: 796ms\n",
      "231:\tlearn: 0.0190191\ttotal: 2.68s\tremaining: 784ms\n",
      "232:\tlearn: 0.0189021\ttotal: 2.69s\tremaining: 773ms\n",
      "233:\tlearn: 0.0188611\ttotal: 2.7s\tremaining: 761ms\n",
      "234:\tlearn: 0.0187498\ttotal: 2.71s\tremaining: 749ms\n",
      "235:\tlearn: 0.0187059\ttotal: 2.72s\tremaining: 737ms\n",
      "236:\tlearn: 0.0185091\ttotal: 2.73s\tremaining: 725ms\n",
      "237:\tlearn: 0.0184611\ttotal: 2.74s\tremaining: 714ms\n",
      "238:\tlearn: 0.0182828\ttotal: 2.75s\tremaining: 702ms\n",
      "239:\tlearn: 0.0181671\ttotal: 2.76s\tremaining: 690ms\n",
      "240:\tlearn: 0.0180116\ttotal: 2.77s\tremaining: 678ms\n",
      "241:\tlearn: 0.0179156\ttotal: 2.78s\tremaining: 666ms\n",
      "242:\tlearn: 0.0177856\ttotal: 2.79s\tremaining: 655ms\n",
      "243:\tlearn: 0.0177543\ttotal: 2.8s\tremaining: 643ms\n",
      "244:\tlearn: 0.0176321\ttotal: 2.81s\tremaining: 631ms\n",
      "245:\tlearn: 0.0174282\ttotal: 2.82s\tremaining: 620ms\n",
      "246:\tlearn: 0.0173442\ttotal: 2.83s\tremaining: 608ms\n",
      "247:\tlearn: 0.0172614\ttotal: 2.84s\tremaining: 596ms\n",
      "248:\tlearn: 0.0172159\ttotal: 2.85s\tremaining: 585ms\n",
      "249:\tlearn: 0.0171100\ttotal: 2.87s\tremaining: 573ms\n",
      "250:\tlearn: 0.0170472\ttotal: 2.88s\tremaining: 561ms\n",
      "251:\tlearn: 0.0169158\ttotal: 2.88s\tremaining: 550ms\n",
      "252:\tlearn: 0.0167823\ttotal: 2.89s\tremaining: 538ms\n",
      "253:\tlearn: 0.0166467\ttotal: 2.91s\tremaining: 527ms\n",
      "254:\tlearn: 0.0165648\ttotal: 2.92s\tremaining: 515ms\n",
      "255:\tlearn: 0.0164581\ttotal: 2.93s\tremaining: 503ms\n",
      "256:\tlearn: 0.0164352\ttotal: 2.94s\tremaining: 492ms\n",
      "257:\tlearn: 0.0163331\ttotal: 2.95s\tremaining: 480ms\n",
      "258:\tlearn: 0.0161729\ttotal: 2.96s\tremaining: 468ms\n",
      "259:\tlearn: 0.0160558\ttotal: 2.97s\tremaining: 457ms\n",
      "260:\tlearn: 0.0159486\ttotal: 2.98s\tremaining: 445ms\n",
      "261:\tlearn: 0.0158935\ttotal: 2.99s\tremaining: 434ms\n",
      "262:\tlearn: 0.0158125\ttotal: 3s\tremaining: 422ms\n",
      "263:\tlearn: 0.0157314\ttotal: 3.01s\tremaining: 411ms\n",
      "264:\tlearn: 0.0156561\ttotal: 3.02s\tremaining: 399ms\n",
      "265:\tlearn: 0.0155312\ttotal: 3.03s\tremaining: 388ms\n",
      "266:\tlearn: 0.0154509\ttotal: 3.04s\tremaining: 376ms\n",
      "267:\tlearn: 0.0153647\ttotal: 3.05s\tremaining: 365ms\n",
      "268:\tlearn: 0.0153059\ttotal: 3.06s\tremaining: 353ms\n",
      "269:\tlearn: 0.0152637\ttotal: 3.08s\tremaining: 342ms\n",
      "270:\tlearn: 0.0151539\ttotal: 3.1s\tremaining: 332ms\n",
      "271:\tlearn: 0.0150591\ttotal: 3.11s\tremaining: 320ms\n",
      "272:\tlearn: 0.0149442\ttotal: 3.14s\tremaining: 310ms\n",
      "273:\tlearn: 0.0148951\ttotal: 3.15s\tremaining: 299ms\n",
      "274:\tlearn: 0.0148484\ttotal: 3.17s\tremaining: 288ms\n",
      "275:\tlearn: 0.0147156\ttotal: 3.19s\tremaining: 277ms\n",
      "276:\tlearn: 0.0146676\ttotal: 3.2s\tremaining: 266ms\n",
      "277:\tlearn: 0.0145748\ttotal: 3.21s\tremaining: 254ms\n",
      "278:\tlearn: 0.0145441\ttotal: 3.22s\tremaining: 242ms\n",
      "279:\tlearn: 0.0145165\ttotal: 3.23s\tremaining: 231ms\n",
      "280:\tlearn: 0.0144228\ttotal: 3.24s\tremaining: 219ms\n",
      "281:\tlearn: 0.0143754\ttotal: 3.25s\tremaining: 208ms\n",
      "282:\tlearn: 0.0143082\ttotal: 3.26s\tremaining: 196ms\n",
      "283:\tlearn: 0.0142215\ttotal: 3.27s\tremaining: 184ms\n",
      "284:\tlearn: 0.0141808\ttotal: 3.28s\tremaining: 173ms\n",
      "285:\tlearn: 0.0140723\ttotal: 3.29s\tremaining: 161ms\n",
      "286:\tlearn: 0.0140435\ttotal: 3.3s\tremaining: 150ms\n",
      "287:\tlearn: 0.0139682\ttotal: 3.31s\tremaining: 138ms\n",
      "288:\tlearn: 0.0138796\ttotal: 3.32s\tremaining: 127ms\n",
      "289:\tlearn: 0.0137637\ttotal: 3.33s\tremaining: 115ms\n",
      "290:\tlearn: 0.0136900\ttotal: 3.35s\tremaining: 103ms\n",
      "291:\tlearn: 0.0136184\ttotal: 3.35s\tremaining: 91.9ms\n",
      "292:\tlearn: 0.0135731\ttotal: 3.36s\tremaining: 80.4ms\n",
      "293:\tlearn: 0.0134807\ttotal: 3.37s\tremaining: 68.9ms\n",
      "294:\tlearn: 0.0134287\ttotal: 3.38s\tremaining: 57.4ms\n",
      "295:\tlearn: 0.0133545\ttotal: 3.39s\tremaining: 45.9ms\n",
      "296:\tlearn: 0.0133350\ttotal: 3.4s\tremaining: 34.4ms\n",
      "297:\tlearn: 0.0132715\ttotal: 3.41s\tremaining: 22.9ms\n",
      "298:\tlearn: 0.0131651\ttotal: 3.42s\tremaining: 11.4ms\n",
      "299:\tlearn: 0.0131424\ttotal: 3.43s\tremaining: 0us\n",
      "[LightGBM] [Warning] Unknown parameter: estimators\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] Unknown parameter: estimators\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5642\n",
      "[LightGBM] [Info] Number of data points in the train set: 4258, number of used features: 31\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] Start training from score -1.565333\n",
      "[LightGBM] [Info] Start training from score -1.007324\n",
      "[LightGBM] [Info] Start training from score -1.565333\n",
      "[LightGBM] [Info] Start training from score -1.528926\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(boosting=&#x27;gbdt&#x27;, data_sample_strategy=&#x27;goss&#x27;, estimators=50,\n",
       "               objective=&#x27;multiclass&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(boosting=&#x27;gbdt&#x27;, data_sample_strategy=&#x27;goss&#x27;, estimators=50,\n",
       "               objective=&#x27;multiclass&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(boosting='gbdt', data_sample_strategy='goss', estimators=50,\n",
       "               objective='multiclass')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh con\n",
    "ab_clf.fit(x_train, y_train)\n",
    "cb_clf.fit(x_train, y_train)\n",
    "gb_clf.fit(x_train, y_train)\n",
    "# rf_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train,y_train)\n",
    "lgb_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: estimators\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] Unknown parameter: estimators\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n"
     ]
    }
   ],
   "source": [
    "# Dá»± Ä‘oÃ¡n trÃªn táº­p huáº¥n luyá»‡n Ä‘á»ƒ táº¡o Ä‘áº·c trÆ°ng má»›i cho mÃ´ hÃ¬nh blending\n",
    "X_train_meta = np.column_stack((\n",
    "    # rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    cb_clf.predict_proba(x_val),\n",
    "    gb_clf.predict_proba(x_val),\n",
    "    xgb_clf.predict_proba(x_val),\n",
    "    lgb_clf.predict_proba(x_val)\n",
    "))\n",
    "# Dá»± Ä‘oÃ¡n trÃªn táº­p kiá»ƒm tra Ä‘á»ƒ táº¡o Ä‘áº·c trÆ°ng má»›i cho mÃ´ hÃ¬nh blending\n",
    "X_test_meta = np.column_stack((\n",
    "    # rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    cb_clf.predict_proba(x_test),\n",
    "    gb_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    lgb_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4258, 20)\n",
      "X_test_meta:(2130, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     2.0\n",
       "4     0.0\n",
       "...   ...\n",
       "2125  1.0\n",
       "2126  1.0\n",
       "2127  3.0\n",
       "2128  1.0\n",
       "2129  3.0\n",
       "\n",
       "[2130 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.933, test=0.921) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.933, test=0.925) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.931, test=0.923) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.936, test=0.921) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.932, test=0.930) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.929, test=0.927) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.936, test=0.920) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.933, test=0.928) total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.930, test=0.928) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.936, test=0.923) total time=   1.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.934, test=0.927) total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.931, test=0.927) total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.936, test=0.920) total time=   1.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.933, test=0.928) total time=   1.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.931, test=0.928) total time=   1.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.938, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.930, test=0.926) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.933, test=0.931) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.934, test=0.919) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.932, test=0.930) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.931, test=0.928) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.936, test=0.923) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.934, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.930, test=0.930) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.936, test=0.922) total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.933, test=0.930) total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.931, test=0.927) total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.936, test=0.921) total time=   1.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.933, test=0.929) total time=   1.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.930, test=0.929) total time=   1.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.937, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.934, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.937, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.943, test=0.922) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.938, test=0.930) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.936, test=0.930) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.939, test=0.921) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.938, test=0.931) total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.936, test=0.932) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.942, test=0.920) total time=   1.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.938, test=0.930) total time=   1.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.936, test=0.929) total time=   1.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.942, test=0.920) total time=   2.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.940, test=0.929) total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.936, test=0.929) total time=   2.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.941, test=0.922) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.939, test=0.929) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.933, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.941, test=0.922) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.938, test=0.927) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.936, test=0.926) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.940, test=0.921) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.939, test=0.930) total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.936, test=0.928) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.943, test=0.923) total time=   1.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.939, test=0.930) total time=   1.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.936, test=0.930) total time=   1.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.942, test=0.920) total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.939, test=0.931) total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.937, test=0.929) total time=   2.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.948, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.942, test=0.927) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.944, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.953, test=0.919) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.944, test=0.931) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.945, test=0.930) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.949, test=0.920) total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.943, test=0.930) total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.948, test=0.932) total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.948, test=0.922) total time=   1.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.943, test=0.930) total time=   1.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.946, test=0.930) total time=   1.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.951, test=0.919) total time=   2.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.944, test=0.930) total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.946, test=0.929) total time=   2.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.947, test=0.920) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.939, test=0.926) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.943, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.947, test=0.920) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.942, test=0.929) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.945, test=0.932) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.947, test=0.923) total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.943, test=0.930) total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.945, test=0.930) total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.946, test=0.920) total time=   1.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.943, test=0.930) total time=   1.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.946, test=0.930) total time=   1.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.947, test=0.922) total time=   2.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.942, test=0.930) total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.945, test=0.930) total time=   2.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.956, test=0.922) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.951, test=0.925) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.952, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.957, test=0.920) total time=   0.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.951, test=0.932) total time=   0.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.954, test=0.929) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.955, test=0.920) total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.950, test=0.928) total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.956, test=0.930) total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.958, test=0.920) total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.950, test=0.930) total time=   1.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.956, test=0.930) total time=   1.6s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.957, test=0.921) total time=   2.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.950, test=0.928) total time=   2.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.955, test=0.930) total time=   2.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.954, test=0.919) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.948, test=0.925) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.954, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.955, test=0.922) total time=   0.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.951, test=0.929) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.957, test=0.930) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.956, test=0.917) total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.950, test=0.930) total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.956, test=0.929) total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.957, test=0.920) total time=   1.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.951, test=0.930) total time=   1.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.955, test=0.928) total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.958, test=0.920) total time=   2.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.952, test=0.929) total time=   2.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.955, test=0.930) total time=   3.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.936, test=0.920) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.931, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.931, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.935, test=0.921) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.931, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.930, test=0.928) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.935, test=0.923) total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.930, test=0.930) total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.931, test=0.928) total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.936, test=0.921) total time=   2.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.931, test=0.930) total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.930, test=0.929) total time=   2.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.937, test=0.921) total time=   3.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.931, test=0.930) total time=   3.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.931, test=0.929) total time=   3.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.933, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.932, test=0.929) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.928, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.936, test=0.918) total time=   0.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.931, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.931, test=0.930) total time=   0.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.936, test=0.920) total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.932, test=0.927) total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.931, test=0.930) total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.936, test=0.921) total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.933, test=0.930) total time=   1.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.930, test=0.930) total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.937, test=0.922) total time=   2.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.931, test=0.930) total time=   2.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.932, test=0.931) total time=   2.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.943, test=0.917) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.935, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.934, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.943, test=0.922) total time=   0.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.936, test=0.930) total time=   0.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.937, test=0.930) total time=   0.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.942, test=0.918) total time=   0.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.935, test=0.932) total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.934, test=0.932) total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.942, test=0.920) total time=   1.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.937, test=0.928) total time=   2.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.936, test=0.930) total time=   2.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.942, test=0.920) total time=   3.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.937, test=0.929) total time=   3.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.935, test=0.930) total time=   3.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.939, test=0.920) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.937, test=0.929) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.933, test=0.932) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.941, test=0.920) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.937, test=0.931) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.935, test=0.930) total time=   0.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.941, test=0.918) total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.936, test=0.931) total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.935, test=0.930) total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.943, test=0.920) total time=   1.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.938, test=0.930) total time=   2.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.937, test=0.930) total time=   1.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.942, test=0.921) total time=   3.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.936, test=0.929) total time=   3.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.936, test=0.928) total time=   3.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.949, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.941, test=0.929) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.944, test=0.932) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.951, test=0.921) total time=   0.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.944, test=0.931) total time=   0.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.944, test=0.928) total time=   0.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.951, test=0.916) total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.943, test=0.929) total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.944, test=0.930) total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.951, test=0.920) total time=   2.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.944, test=0.930) total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.947, test=0.930) total time=   2.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.951, test=0.919) total time=   3.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.944, test=0.929) total time=   3.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.945, test=0.932) total time=   3.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.950, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.940, test=0.923) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.947, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.952, test=0.917) total time=   0.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.943, test=0.932) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.944, test=0.926) total time=   0.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.953, test=0.921) total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.942, test=0.931) total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.947, test=0.929) total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.950, test=0.920) total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.944, test=0.930) total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.946, test=0.929) total time=   2.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.952, test=0.918) total time=   3.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.943, test=0.928) total time=   3.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.945, test=0.930) total time=   3.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.953, test=0.922) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.948, test=0.933) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.953, test=0.931) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.957, test=0.920) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.950, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.955, test=0.932) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.957, test=0.921) total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.953, test=0.929) total time=   1.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.954, test=0.930) total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.958, test=0.919) total time=   2.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.951, test=0.933) total time=   2.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.954, test=0.932) total time=   2.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.958, test=0.920) total time=   3.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.951, test=0.931) total time=   3.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.956, test=0.932) total time=   3.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.958, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.948, test=0.931) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.950, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.958, test=0.920) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.952, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.954, test=0.931) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.957, test=0.923) total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.950, test=0.929) total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.953, test=0.932) total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.958, test=0.920) total time=   2.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.950, test=0.932) total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.954, test=0.931) total time=   2.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.958, test=0.919) total time=   3.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.950, test=0.930) total time=   3.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.956, test=0.933) total time=   3.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.937, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.928, test=0.926) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.931, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.937, test=0.922) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.930, test=0.927) total time=   0.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.930, test=0.927) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.937, test=0.920) total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.931, test=0.930) total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.931, test=0.930) total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.935, test=0.921) total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.932, test=0.930) total time=   1.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.930, test=0.930) total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.935, test=0.921) total time=   2.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.932, test=0.930) total time=   2.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.931, test=0.930) total time=   2.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.936, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.931, test=0.927) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.927, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.937, test=0.920) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.930, test=0.928) total time=   0.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.931, test=0.928) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.936, test=0.920) total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.934, test=0.927) total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.932, test=0.929) total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.937, test=0.922) total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.933, test=0.930) total time=   1.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.930, test=0.928) total time=   1.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.938, test=0.920) total time=   2.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.932, test=0.930) total time=   1.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.931, test=0.930) total time=   2.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.938, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.935, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.934, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.942, test=0.917) total time=   0.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.936, test=0.928) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.934, test=0.929) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.940, test=0.918) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.936, test=0.928) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.935, test=0.929) total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.942, test=0.920) total time=   1.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.936, test=0.932) total time=   2.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.936, test=0.930) total time=   1.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.942, test=0.920) total time=   3.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.936, test=0.930) total time=   3.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.934, test=0.930) total time=   2.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.940, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.938, test=0.932) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.936, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.942, test=0.921) total time=   0.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.936, test=0.929) total time=   0.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.937, test=0.928) total time=   0.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.941, test=0.919) total time=   0.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.937, test=0.927) total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.934, test=0.932) total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.942, test=0.919) total time=   2.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.937, test=0.929) total time=   1.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.935, test=0.929) total time=   1.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.943, test=0.919) total time=   2.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.936, test=0.930) total time=   3.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.936, test=0.932) total time=   2.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.944, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.944, test=0.928) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.938, test=0.932) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.950, test=0.920) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.943, test=0.931) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.947, test=0.932) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.953, test=0.917) total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.944, test=0.929) total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.948, test=0.931) total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.949, test=0.919) total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.944, test=0.932) total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.947, test=0.930) total time=   2.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.951, test=0.920) total time=   3.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.944, test=0.932) total time=   3.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.946, test=0.932) total time=   3.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.950, test=0.921) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.942, test=0.928) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.943, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.950, test=0.919) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.946, test=0.927) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.946, test=0.930) total time=   0.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.952, test=0.922) total time=   0.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.943, test=0.930) total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.945, test=0.930) total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.951, test=0.921) total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.943, test=0.930) total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.945, test=0.932) total time=   2.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.950, test=0.922) total time=   3.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.943, test=0.931) total time=   3.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.944, test=0.932) total time=   3.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.959, test=0.913) total time=   0.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.948, test=0.926) total time=   0.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.950, test=0.932) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.958, test=0.918) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.951, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.955, test=0.931) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.955, test=0.918) total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.951, test=0.930) total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.955, test=0.932) total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.959, test=0.918) total time=   2.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.950, test=0.930) total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.955, test=0.932) total time=   2.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.959, test=0.922) total time=   3.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.951, test=0.931) total time=   3.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.955, test=0.932) total time=   3.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.956, test=0.915) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.949, test=0.927) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.950, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.957, test=0.918) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.948, test=0.931) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.954, test=0.928) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.959, test=0.917) total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.951, test=0.931) total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.955, test=0.932) total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.958, test=0.920) total time=   2.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.951, test=0.930) total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.955, test=0.930) total time=   2.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.958, test=0.920) total time=   3.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.950, test=0.930) total time=   3.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.955, test=0.932) total time=   3.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.935, test=0.914) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.933, test=0.931) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.932, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.937, test=0.920) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.932, test=0.927) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.931, test=0.928) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.936, test=0.919) total time=   0.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.933, test=0.929) total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.932, test=0.929) total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.937, test=0.919) total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.934, test=0.927) total time=   1.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.931, test=0.928) total time=   1.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.938, test=0.919) total time=   2.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.933, test=0.930) total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.931, test=0.927) total time=   2.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.937, test=0.922) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.934, test=0.926) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.930, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.935, test=0.921) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.931, test=0.930) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.931, test=0.927) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.937, test=0.919) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.932, test=0.929) total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.932, test=0.930) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.936, test=0.920) total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.933, test=0.931) total time=   1.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.930, test=0.927) total time=   1.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.936, test=0.919) total time=   2.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.933, test=0.930) total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.931, test=0.928) total time=   2.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.942, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.935, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.938, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.942, test=0.921) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.938, test=0.932) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.937, test=0.929) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.941, test=0.920) total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.938, test=0.927) total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.936, test=0.930) total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.942, test=0.921) total time=   1.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.938, test=0.930) total time=   1.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.937, test=0.930) total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.942, test=0.920) total time=   2.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.939, test=0.929) total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.937, test=0.929) total time=   1.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.940, test=0.916) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.935, test=0.931) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.938, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.941, test=0.922) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.938, test=0.928) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.936, test=0.930) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.941, test=0.923) total time=   0.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.939, test=0.930) total time=   0.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.936, test=0.929) total time=   0.4s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.941, test=0.921) total time=   0.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.939, test=0.932) total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.937, test=0.928) total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.942, test=0.922) total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.938, test=0.930) total time=   1.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.937, test=0.931) total time=   1.4s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.949, test=0.921) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.945, test=0.928) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.946, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.947, test=0.919) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.943, test=0.931) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.948, test=0.930) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.949, test=0.918) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.943, test=0.929) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.944, test=0.930) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.950, test=0.920) total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.943, test=0.932) total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.946, test=0.929) total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.949, test=0.922) total time=   1.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.943, test=0.931) total time=   1.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.946, test=0.931) total time=   1.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.947, test=0.915) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.943, test=0.927) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.940, test=0.934) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.950, test=0.922) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.943, test=0.932) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.943, test=0.931) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.950, test=0.918) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.943, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.945, test=0.927) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.947, test=0.921) total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.944, test=0.928) total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.944, test=0.929) total time=   1.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.949, test=0.921) total time=   1.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.944, test=0.930) total time=   1.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.945, test=0.930) total time=   1.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.953, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.950, test=0.929) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.953, test=0.931) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.957, test=0.920) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.949, test=0.929) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.958, test=0.930) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.956, test=0.922) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.950, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.957, test=0.932) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.958, test=0.920) total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.950, test=0.930) total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.955, test=0.931) total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.958, test=0.920) total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.950, test=0.929) total time=   1.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.957, test=0.931) total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.953, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.949, test=0.925) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.955, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.956, test=0.922) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.951, test=0.930) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.955, test=0.932) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.958, test=0.920) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.951, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.954, test=0.932) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.958, test=0.922) total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.950, test=0.930) total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.955, test=0.931) total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.957, test=0.921) total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.951, test=0.930) total time=   1.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.955, test=0.931) total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.937, test=0.914) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.932, test=0.931) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.929, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.938, test=0.916) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.931, test=0.931) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.929, test=0.932) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.934, test=0.922) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.932, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.930, test=0.929) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.936, test=0.920) total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.931, test=0.931) total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.930, test=0.926) total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.936, test=0.920) total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.932, test=0.930) total time=   1.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.930, test=0.929) total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.933, test=0.920) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.930, test=0.927) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.930, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.935, test=0.920) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.933, test=0.930) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.929, test=0.928) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.937, test=0.920) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.930, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.931, test=0.929) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.934, test=0.920) total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.932, test=0.929) total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.931, test=0.927) total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.937, test=0.923) total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.932, test=0.930) total time=   1.8s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.930, test=0.930) total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.939, test=0.920) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.932, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.933, test=0.932) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.945, test=0.920) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.937, test=0.930) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.934, test=0.928) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.942, test=0.919) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.937, test=0.929) total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.935, test=0.928) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.941, test=0.919) total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.937, test=0.930) total time=   1.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.935, test=0.931) total time=   2.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.940, test=0.919) total time=   3.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.938, test=0.930) total time=   3.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.935, test=0.929) total time=   3.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.945, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.934, test=0.927) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.933, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.941, test=0.919) total time=   0.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.937, test=0.929) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.936, test=0.930) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.944, test=0.920) total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.936, test=0.930) total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.937, test=0.930) total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.942, test=0.920) total time=   1.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.937, test=0.928) total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.937, test=0.930) total time=   1.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.943, test=0.920) total time=   1.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.938, test=0.930) total time=   1.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.936, test=0.929) total time=   1.9s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.949, test=0.917) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.939, test=0.935) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.946, test=0.933) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.950, test=0.920) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.943, test=0.930) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.946, test=0.932) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.950, test=0.919) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.944, test=0.930) total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.944, test=0.930) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.949, test=0.919) total time=   1.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.944, test=0.930) total time=   1.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.946, test=0.930) total time=   1.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.951, test=0.919) total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.944, test=0.931) total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.946, test=0.932) total time=   2.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.947, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.942, test=0.927) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.945, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.950, test=0.920) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.942, test=0.930) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.943, test=0.928) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.951, test=0.918) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.943, test=0.930) total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.945, test=0.932) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.951, test=0.919) total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.941, test=0.932) total time=   1.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.944, test=0.930) total time=   1.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.951, test=0.920) total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.943, test=0.931) total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.945, test=0.932) total time=   2.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.957, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.946, test=0.927) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.948, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.957, test=0.918) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.951, test=0.929) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.954, test=0.933) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.958, test=0.920) total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.951, test=0.930) total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.955, test=0.930) total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.958, test=0.920) total time=   1.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.951, test=0.932) total time=   1.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.955, test=0.934) total time=   1.4s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.958, test=0.919) total time=   2.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.949, test=0.930) total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.955, test=0.934) total time=   2.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.955, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.952, test=0.924) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.954, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.957, test=0.920) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.951, test=0.930) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.953, test=0.931) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.956, test=0.918) total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.950, test=0.930) total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.956, test=0.932) total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.958, test=0.921) total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.951, test=0.932) total time=   1.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.955, test=0.932) total time=   1.4s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.957, test=0.920) total time=   2.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.951, test=0.932) total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.956, test=0.930) total time=   2.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.934, test=0.921) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.929, test=0.925) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.931, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.937, test=0.921) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.930, test=0.929) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.931, test=0.927) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.936, test=0.922) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.931, test=0.930) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.931, test=0.930) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.936, test=0.922) total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.932, test=0.929) total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.930, test=0.929) total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.937, test=0.920) total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.932, test=0.928) total time=   1.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.931, test=0.928) total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.935, test=0.920) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.928, test=0.925) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.931, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.937, test=0.922) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.932, test=0.929) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.930, test=0.930) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.937, test=0.922) total time=   0.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.932, test=0.931) total time=   0.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.930, test=0.929) total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.936, test=0.921) total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.932, test=0.931) total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.930, test=0.929) total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.937, test=0.921) total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.931, test=0.928) total time=   1.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.931, test=0.928) total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.942, test=0.916) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.933, test=0.927) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.934, test=0.932) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.940, test=0.922) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.939, test=0.929) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.937, test=0.932) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.941, test=0.920) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.935, test=0.932) total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.936, test=0.931) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.942, test=0.920) total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.937, test=0.930) total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.935, test=0.929) total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.942, test=0.920) total time=   1.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.937, test=0.930) total time=   1.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.937, test=0.930) total time=   1.9s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.942, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.933, test=0.929) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.933, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.940, test=0.918) total time=   0.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.936, test=0.929) total time=   0.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.936, test=0.930) total time=   0.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.943, test=0.919) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.937, test=0.929) total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.934, test=0.930) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.944, test=0.919) total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.938, test=0.931) total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.934, test=0.929) total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.942, test=0.920) total time=   1.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.937, test=0.928) total time=   1.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.937, test=0.931) total time=   1.9s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.949, test=0.919) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.941, test=0.929) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=10;, score=(train=0.942, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.951, test=0.923) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.943, test=0.928) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=50;, score=(train=0.943, test=0.931) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.949, test=0.919) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.942, test=0.931) total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=100;, score=(train=0.944, test=0.930) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.950, test=0.920) total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.943, test=0.931) total time=   1.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=200;, score=(train=0.945, test=0.932) total time=   1.4s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.950, test=0.919) total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.944, test=0.930) total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=sqrt, n_estimators=300;, score=(train=0.945, test=0.933) total time=   2.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.948, test=0.920) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.942, test=0.931) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=10;, score=(train=0.942, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.950, test=0.921) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.942, test=0.930) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=50;, score=(train=0.944, test=0.932) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.950, test=0.920) total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.943, test=0.929) total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=100;, score=(train=0.943, test=0.930) total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.952, test=0.920) total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.943, test=0.929) total time=   1.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=200;, score=(train=0.945, test=0.932) total time=   1.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.950, test=0.920) total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.943, test=0.930) total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=6, max_features=log2, n_estimators=300;, score=(train=0.944, test=0.930) total time=   2.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.957, test=0.924) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.953, test=0.927) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=10;, score=(train=0.954, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.958, test=0.918) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.950, test=0.932) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=50;, score=(train=0.951, test=0.927) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.959, test=0.919) total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.951, test=0.930) total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=100;, score=(train=0.956, test=0.934) total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.959, test=0.919) total time=   1.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.950, test=0.932) total time=   1.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=200;, score=(train=0.955, test=0.932) total time=   1.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.959, test=0.920) total time=   2.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.951, test=0.931) total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=sqrt, n_estimators=300;, score=(train=0.956, test=0.932) total time=   2.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.957, test=0.915) total time=   0.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.953, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=10;, score=(train=0.953, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.958, test=0.918) total time=   0.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.949, test=0.931) total time=   0.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=50;, score=(train=0.954, test=0.928) total time=   0.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.957, test=0.919) total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.949, test=0.931) total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=100;, score=(train=0.955, test=0.930) total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.957, test=0.918) total time=   1.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.950, test=0.931) total time=   1.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=200;, score=(train=0.955, test=0.932) total time=   1.4s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.958, test=0.919) total time=   2.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.951, test=0.930) total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_depth=7, max_features=log2, n_estimators=300;, score=(train=0.955, test=0.931) total time=   2.2s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = RandomForestClassifier()\n",
    "params = {\n",
    "    'n_estimators': [10,50,100,200,300],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [4,5,6,7],\n",
    "    'max_features':['sqrt', 'log2'],\n",
    "    'class_weight':['balanced', 'balanced_subsample']\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced_subsample',\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 7,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9286069009783389"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>0.874157</td>\n",
       "      <td>0.843818</td>\n",
       "      <td>0.858720</td>\n",
       "      <td>0.957270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.984507</td>\n",
       "      <td>0.976864</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.978751</td>\n",
       "      <td>0.988905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.976526</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.985163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.935412</td>\n",
       "      <td>0.922064</td>\n",
       "      <td>0.982614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.925839</td>\n",
       "      <td>0.925924</td>\n",
       "      <td>0.925983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933803</td>\n",
       "      <td>0.933803</td>\n",
       "      <td>0.933803</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.934081</td>\n",
       "      <td>0.934555</td>\n",
       "      <td>0.933803</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.939906  0.874157   0.843818  0.858720     0.957270\n",
       "1            SB  0.984507  0.976864   0.980645  0.978751     0.988905\n",
       "2            SR  0.976526  0.943820   0.943820  0.943820     0.985163\n",
       "3          GSVT  0.966667  0.909091   0.935412  0.922064     0.982614\n",
       "4     macro avg       NaN  0.925839   0.925924  0.925983          NaN\n",
       "5     micro avg       NaN  0.933803   0.933803  0.933803          NaN\n",
       "6  weighted avg       NaN  0.934081   0.934555  0.933803          NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_evaluation_test.to_csv(\"../Result/Blending_RF_frequency_sf.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
