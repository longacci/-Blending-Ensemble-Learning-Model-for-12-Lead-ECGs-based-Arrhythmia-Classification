{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>782.0</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>252.222222</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>87.777778</td>\n",
       "      <td>10339.061728</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>4315.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6555.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>697.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>594.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>1360.782222</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>420.090909</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1504.888889</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>569.437500</td>\n",
       "      <td>136.444444</td>\n",
       "      <td>43.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>615.733333</td>\n",
       "      <td>596.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.500000</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1746.285714</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>4722.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>654.428571</td>\n",
       "      <td>648.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>2686.204082</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3602.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>101.142857</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>-10.750000</td>\n",
       "      <td>7259.937500</td>\n",
       "      <td>88.222222</td>\n",
       "      <td>202.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1041.250000</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2            3       4           5      6         7         8  \\\n",
       "0     0.0  10.0   950.000000  1074.0  274.986868  782.0 -0.319753 -1.432466   \n",
       "1     0.0  17.0   574.500000   582.0  104.913059  378.0  0.158313 -0.696295   \n",
       "2     3.0  16.0   593.600000   594.0    4.687572   18.0  0.396421 -0.312612   \n",
       "3     3.0  23.0   420.090909   420.0    3.591772   12.0 -0.021014 -0.856142   \n",
       "4     1.0   9.0  1068.750000  1075.0   25.118469   76.0 -0.276816 -1.271399   \n",
       "...   ...   ...          ...     ...         ...    ...       ...       ...   \n",
       "8511  3.0  16.0   615.733333   596.0   51.114860  152.0  2.153820  2.645687   \n",
       "8512  1.0   9.0  1091.500000  1093.0    5.894913   18.0 -0.311206 -1.184514   \n",
       "8513  2.0  15.0   654.428571   648.0  107.653355  458.0  0.475616  0.784000   \n",
       "8514  1.0   9.0  1075.000000  1083.0   24.535688   66.0 -0.263431 -1.567800   \n",
       "8515  1.0   9.0  1041.250000  1040.0    8.242421   22.0  0.214800 -1.575835   \n",
       "\n",
       "               9        10  ...       204         205        206        207  \\\n",
       "0     325.821586  1.000000  ...  1.000000  172.000000  10.000000   9.000000   \n",
       "1     336.569414  1.000000  ...  0.882353  -15.000000  15.000000   4.000000   \n",
       "2      94.909877  1.000000  ...  1.000000   -4.000000  16.000000  15.000000   \n",
       "3     254.059787  0.826087  ...  0.739130   -9.000000   6.000000   4.000000   \n",
       "4     461.130814  1.000000  ...  1.000000    2.000000   9.000000   8.000000   \n",
       "...          ...       ...  ...       ...         ...        ...        ...   \n",
       "8511  365.256750  1.000000  ...  0.003757    0.022262   0.003757   0.003757   \n",
       "8512  358.414529  1.000000  ...  0.888889   -3.000000   9.000000   8.000000   \n",
       "8513  180.045117  1.000000  ...  1.000000   -4.000000  15.000000  14.000000   \n",
       "8514  251.455499  1.000000  ...  1.000000   14.000000   9.000000   8.000000   \n",
       "8515  505.203302  1.000000  ...  1.000000    0.000000   9.000000   8.000000   \n",
       "\n",
       "             208           209        210           211         212  \\\n",
       "0     252.222222  10656.395062  87.777778  10339.061728  135.800000   \n",
       "1     158.000000   3944.000000  73.000000   6555.000000   -1.066667   \n",
       "2     122.400000   2058.773333  12.533333   1360.782222   95.500000   \n",
       "3      40.666667   1120.888889   5.333333   1504.888889   12.000000   \n",
       "4     122.000000    671.000000  19.750000    569.437500  136.444444   \n",
       "...          ...           ...        ...           ...         ...   \n",
       "8511    0.044242      0.044242   0.043021      0.043021    0.037385   \n",
       "8512   81.428571   1294.530612 -40.000000   1746.285714  155.333333   \n",
       "8513   77.142857   2213.551020  -1.714286   2686.204082  104.000000   \n",
       "8514  101.142857   4933.551020 -10.750000   7259.937500   88.222222   \n",
       "8515  102.000000    350.000000 -20.000000    588.000000  150.000000   \n",
       "\n",
       "              213  \n",
       "0     4315.560000  \n",
       "1      697.528889  \n",
       "2       68.750000  \n",
       "3     1464.000000  \n",
       "4       43.358025  \n",
       "...           ...  \n",
       "8511     0.037385  \n",
       "8512  4722.666667  \n",
       "8513  3602.666667  \n",
       "8514   202.172840  \n",
       "8515     0.000000  \n",
       "\n",
       "[8516 rows x 213 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_frequency.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.iloc[:,0].values\n",
    "x_train = df_train.iloc[:,1:].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>710.769231</td>\n",
       "      <td>628.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3140.437500</td>\n",
       "      <td>127.600000</td>\n",
       "      <td>1041.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>968.666667</td>\n",
       "      <td>894.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>5249.000000</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>8081.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>8070.530612</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1078.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>757.500000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>7081.416667</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>264.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>413.909091</td>\n",
       "      <td>409.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>832.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>342.857143</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>205.142857</td>\n",
       "      <td>11207.836735</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2281.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>14282.775510</td>\n",
       "      <td>169.142857</td>\n",
       "      <td>46.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>361.489796</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>2186.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.285714</td>\n",
       "      <td>996.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>-45.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2       3           4      5         6          7  \\\n",
       "0     0.0  14.0   710.769231   628.0  153.204817  556.0  0.996355   0.207174   \n",
       "1     0.0  10.0   968.666667   894.0  266.399867  932.0  0.979352   0.388359   \n",
       "2     0.0  11.0   797.000000   780.0  251.329664  794.0  0.260470  -1.002325   \n",
       "3     2.0  13.0   757.500000   755.0    8.986100   26.0  0.048579  -1.449012   \n",
       "4     0.0  23.0   413.909091   409.0   82.344017  426.0  3.023659  10.404884   \n",
       "...   ...   ...          ...     ...         ...    ...       ...        ...   \n",
       "2125  1.0   9.0  1071.250000  1062.0   36.509417  118.0  1.263183   0.543003   \n",
       "2126  1.0   8.0  1196.000000  1202.0   33.839959  102.0 -0.454057  -1.036905   \n",
       "2127  3.0  16.0   595.600000   590.0   23.734082   82.0  0.371174  -0.657132   \n",
       "2128  1.0   8.0  1080.285714   996.0  180.470587  448.0  0.587475  -1.363827   \n",
       "2129  3.0  25.0   391.250000   390.0    2.569857    8.0  0.605786  -0.869886   \n",
       "\n",
       "               8         9  ...       203        204   205   206         207  \\\n",
       "0     459.037295  1.000000  ...  0.928571 -10.000000  10.0   9.0  146.000000   \n",
       "1     398.464564  1.000000  ...  0.600000  64.000000   7.0   7.0  140.500000   \n",
       "2     340.802438  1.000000  ...  1.000000  26.000000   9.0   7.0  154.285714   \n",
       "3     412.324324  1.000000  ...  1.000000  -4.000000  12.0  12.0  108.500000   \n",
       "4     168.041577  0.956522  ...  0.083333   0.022262  11.0  12.0    0.044242   \n",
       "...          ...       ...  ...       ...        ...   ...   ...         ...   \n",
       "2125  364.303573  0.888889  ...  0.777778   0.000000   9.0   8.0  342.857143   \n",
       "2126  181.876516  1.000000  ...  1.000000 -26.000000   8.0   7.0  137.666667   \n",
       "2127  137.696567  1.000000  ...  1.000000  -8.000000  16.0  14.0  102.714286   \n",
       "2128  561.988537  1.000000  ...  1.000000  18.000000   8.0   5.0   62.400000   \n",
       "2129  654.123072  0.400000  ...  0.240000   4.000000   0.0   0.0    0.044242   \n",
       "\n",
       "               208         209           210         211          212  \n",
       "0       729.000000   78.250000   3140.437500  127.600000  1041.440000  \n",
       "1     15314.750000  -27.000000   5249.000000  112.285714  8081.632653  \n",
       "2      1944.489796   18.571429   8070.530612  131.111111  1078.320988  \n",
       "3      6122.750000   46.500000   7081.416667  121.833333   264.305556  \n",
       "4         0.044242  -50.000000      0.000000   45.818182   832.330579  \n",
       "...            ...         ...           ...         ...          ...  \n",
       "2125   2843.265306  205.142857  11207.836735   96.000000  2281.142857  \n",
       "2126    228.555556   87.714286  14282.775510  169.142857    46.693878  \n",
       "2127   1270.061224    7.285714    361.489796   90.400000  2186.240000  \n",
       "2128     51.840000  -45.200000      0.960000  101.000000  5002.000000  \n",
       "2129      0.044242    0.043021      0.043021    0.037385     0.037385  \n",
       "\n",
       "[2130 rows x 213 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_frequency.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test.iloc[:,0].values\n",
    "x_test = df_test.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)\n",
    "# x_test = apply_pca(x_test, len(x_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.950 total time=   0.3s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.940 total time=   0.2s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.947 total time=   0.2s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.948 total time=   0.2s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.931 total time=   0.2s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.946 total time=   0.2s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.942 total time=   0.3s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.935 total time=   0.2s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.919 total time=   0.2s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.940 total time=   0.2s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.954 total time=   0.1s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.940 total time=   0.1s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.953 total time=   0.1s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.948 total time=   0.1s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.932 total time=   0.1s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.945 total time=   0.1s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.938 total time=   0.1s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.935 total time=   0.1s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.920 total time=   0.1s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.946 total time=   0.1s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.930 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.921 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.900 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.911 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.902 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.899 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.934 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.917 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.918 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.910 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.908 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.918 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.924 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.906 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.899 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.910 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=0.867 total time=   8.3s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=0.853 total time=   8.3s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=0.874 total time=   8.1s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=0.853 total time=   8.5s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=0.857 total time=   8.3s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=0.872 total time=   8.3s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=0.875 total time=   8.1s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=0.859 total time=   8.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=0.858 total time=   8.4s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=0.866 total time=   8.1s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=0.884 total time=   5.2s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=0.871 total time=   5.1s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=0.881 total time=   5.6s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=0.857 total time=   5.4s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=0.869 total time=   5.2s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=0.877 total time=   5.3s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=0.877 total time=   5.6s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=0.859 total time=   5.6s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=0.870 total time=   5.4s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=0.860 total time=   5.5s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.952 total time=   0.2s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.940 total time=   0.2s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.950 total time=   0.2s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.945 total time=   0.2s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.935 total time=   0.2s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.942 total time=   0.2s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.940 total time=   0.2s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.932 total time=   0.2s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.924 total time=   0.2s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.942 total time=   0.2s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.953 total time=   0.1s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.941 total time=   0.1s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.950 total time=   0.1s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.946 total time=   0.1s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.935 total time=   0.1s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.944 total time=   0.1s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.940 total time=   0.1s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.933 total time=   0.1s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.924 total time=   0.1s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.942 total time=   0.1s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.910 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.924 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.906 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.914 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.924 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.913 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.910 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.932 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.914 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.912 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.911 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.917 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.926 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.913 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.912 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.915 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=0.881 total time=   8.5s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=0.865 total time=   8.5s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=0.887 total time=   8.4s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=0.859 total time=   8.6s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=0.872 total time=   8.3s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=0.877 total time=   9.2s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=0.884 total time=  13.1s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=0.860 total time=  13.8s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=0.866 total time=  14.1s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=0.868 total time=  14.4s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=0.887 total time=   7.9s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=0.870 total time=   7.9s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=0.888 total time=   8.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=0.866 total time=   7.7s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=0.873 total time=   8.1s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=0.883 total time=   7.9s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=0.887 total time=   7.8s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=0.863 total time=   7.8s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=0.867 total time=   7.9s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=0.871 total time=   7.8s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=0.957 total time=   0.4s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=0.940 total time=   0.4s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=0.946 total time=   0.4s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=0.944 total time=   0.4s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=0.935 total time=   0.4s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=0.941 total time=   0.4s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=0.944 total time=   0.4s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=0.937 total time=   0.4s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=0.926 total time=   0.4s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=0.941 total time=   0.4s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=0.954 total time=   0.2s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=0.945 total time=   0.2s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=0.950 total time=   0.2s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=0.947 total time=   0.2s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=0.937 total time=   0.2s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=0.945 total time=   0.3s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=0.944 total time=   0.2s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=0.937 total time=   0.2s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=0.925 total time=   0.2s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=0.946 total time=   0.2s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=0.930 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=0.907 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=0.913 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=0.905 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=0.908 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=0.911 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=0.910 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=0.908 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=0.900 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=0.905 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=0.932 total time=   0.0s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=0.917 total time=   0.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=0.924 total time=   0.0s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=0.913 total time=   0.0s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=0.915 total time=   0.0s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=0.928 total time=   0.0s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=0.915 total time=   0.0s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=0.910 total time=   0.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=0.914 total time=   0.0s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=0.886 total time=  14.2s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=0.858 total time=  14.0s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=0.878 total time=  14.4s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=0.853 total time=  14.2s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=0.858 total time=  13.9s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=0.880 total time=  14.1s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=0.885 total time=  14.2s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=0.872 total time=  14.2s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=0.865 total time=  14.2s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=0.871 total time=  14.2s\n",
      "[CV 1/10] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=0.890 total time=   7.8s\n",
      "[CV 2/10] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=0.872 total time=   8.1s\n",
      "[CV 3/10] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=0.897 total time=   7.9s\n",
      "[CV 4/10] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=0.859 total time=   8.2s\n",
      "[CV 5/10] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=0.873 total time=   8.0s\n",
      "[CV 6/10] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=0.887 total time=   7.9s\n",
      "[CV 7/10] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=0.888 total time=   8.1s\n",
      "[CV 8/10] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=0.868 total time=   8.1s\n",
      "[CV 9/10] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=0.863 total time=   8.0s\n",
      "[CV 10/10] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=0.866 total time=   8.0s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.950 total time=   2.8s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.940 total time=   2.8s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.947 total time=   3.0s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.948 total time=   2.8s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.931 total time=   2.8s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.946 total time=   3.0s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.942 total time=   2.8s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.935 total time=   2.8s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.919 total time=   2.9s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.940 total time=   2.8s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.954 total time=   2.7s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.940 total time=   2.7s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.953 total time=   2.6s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.948 total time=   2.8s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.932 total time=   2.7s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.945 total time=   2.7s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.938 total time=   2.6s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.935 total time=   2.6s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.920 total time=   2.7s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.946 total time=   2.8s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.930 total time=   2.8s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   2.6s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.921 total time=   2.8s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.900 total time=   2.8s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   2.8s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.911 total time=   2.8s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.912 total time=   2.9s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   2.8s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.902 total time=   2.7s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.899 total time=   2.8s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.934 total time=   2.8s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.917 total time=   2.7s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.918 total time=   2.8s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.910 total time=   2.8s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.908 total time=   2.8s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.918 total time=   2.6s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.924 total time=   2.8s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.906 total time=   2.8s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.899 total time=   2.8s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.910 total time=   2.7s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=0.867 total time=  50.6s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=0.853 total time=  50.9s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=0.874 total time=  50.2s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=0.853 total time=  49.2s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=0.857 total time=  30.7s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=0.872 total time=  51.2s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=0.875 total time=  51.0s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=0.859 total time=  51.7s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=0.858 total time=  51.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=0.866 total time=  51.4s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=0.884 total time=  50.0s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=0.871 total time=  51.5s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=0.881 total time=  51.0s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=0.857 total time=  51.5s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=0.869 total time=  50.8s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=0.877 total time=  50.5s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=0.877 total time=  51.4s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=0.859 total time=  51.8s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=0.870 total time=  51.8s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=0.860 total time=  51.4s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.952 total time=   2.8s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.940 total time=   2.8s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.950 total time=   2.9s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.945 total time=   2.8s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.935 total time=   2.9s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.942 total time=   2.8s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.940 total time=   2.9s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.932 total time=   2.9s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.924 total time=   2.8s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.942 total time=   2.9s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.953 total time=   2.8s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.941 total time=   2.8s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.950 total time=   2.8s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.946 total time=   2.8s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.935 total time=   2.8s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.944 total time=   2.7s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.940 total time=   2.8s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.933 total time=   2.9s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.924 total time=   2.8s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.942 total time=   2.8s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.933 total time=   2.9s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.910 total time=   2.9s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.924 total time=   2.9s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.906 total time=   2.9s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.912 total time=   2.9s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.914 total time=   2.9s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.924 total time=   3.0s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.913 total time=   2.8s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.910 total time=   2.9s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.912 total time=   2.9s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.932 total time=   2.8s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.914 total time=   2.9s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.925 total time=   2.8s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.912 total time=   2.9s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.911 total time=   2.8s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.917 total time=   2.7s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.926 total time=   2.9s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.913 total time=   2.8s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.912 total time=   2.9s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.915 total time=   2.9s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=0.881 total time=  51.1s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=0.865 total time=  51.9s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=0.887 total time=  52.0s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=0.859 total time=  51.1s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=0.872 total time=  50.5s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=0.877 total time=  50.7s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=0.884 total time=  51.0s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=0.860 total time=  50.7s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=0.866 total time=  50.2s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=0.868 total time=  50.2s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=0.887 total time=  33.2s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=0.870 total time=  45.5s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=0.888 total time=  53.6s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=0.866 total time=  54.7s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=0.873 total time=  53.4s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=0.883 total time=  54.2s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=0.887 total time=  51.7s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=0.863 total time=  50.2s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=0.867 total time=  50.5s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=0.871 total time=  47.9s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=0.957 total time=   2.4s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=0.940 total time=   2.4s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=0.946 total time=   2.3s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=0.944 total time=   2.6s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=0.935 total time=   2.5s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=0.941 total time=   2.5s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=0.944 total time=   2.4s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=0.937 total time=   2.5s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=0.926 total time=   2.4s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=0.941 total time=   2.4s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=0.954 total time=   2.3s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=0.945 total time=   2.5s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=0.950 total time=   2.4s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=0.947 total time=   2.4s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=0.937 total time=   2.5s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=0.945 total time=   2.5s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=0.944 total time=   2.4s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=0.937 total time=   2.4s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=0.925 total time=   2.4s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=0.946 total time=   2.4s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=0.930 total time=   2.5s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=0.907 total time=   2.4s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=0.913 total time=   2.5s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=0.905 total time=   2.4s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=0.908 total time=   2.5s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=0.911 total time=   2.5s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=0.910 total time=   2.7s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=0.908 total time=   2.7s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=0.900 total time=   3.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=0.905 total time=   2.8s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=0.932 total time=   2.2s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=0.917 total time=   2.1s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=0.924 total time=   2.0s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=0.913 total time=   1.9s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=0.914 total time=   2.1s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=0.915 total time=   2.2s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=0.928 total time=   2.0s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=0.915 total time=   2.0s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=0.910 total time=   2.2s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=0.914 total time=   2.0s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=0.886 total time=  28.4s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=0.858 total time=  28.2s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=0.878 total time=  27.4s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=0.853 total time=  27.3s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=0.858 total time=  26.3s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=0.880 total time=  27.4s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=0.885 total time=  28.4s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=0.872 total time=  27.7s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=0.865 total time=  27.7s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=0.871 total time=  26.5s\n",
      "[CV 1/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=0.890 total time=  27.2s\n",
      "[CV 2/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=0.872 total time=  28.1s\n",
      "[CV 3/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=0.897 total time=  26.5s\n",
      "[CV 4/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=0.859 total time=  28.5s\n",
      "[CV 5/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=0.873 total time=  26.6s\n",
      "[CV 6/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=0.887 total time=  26.9s\n",
      "[CV 7/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=0.888 total time=  27.5s\n",
      "[CV 8/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=0.868 total time=  27.4s\n",
      "[CV 9/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=0.863 total time=  26.3s\n",
      "[CV 10/10] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=0.866 total time=  25.6s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.950 total time=   1.7s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.940 total time=   1.7s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.947 total time=   1.7s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.948 total time=   1.7s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.931 total time=   1.6s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.946 total time=   1.7s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.942 total time=   1.7s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.935 total time=   1.7s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.919 total time=   1.6s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.940 total time=   1.8s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.954 total time=   1.8s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.940 total time=   1.9s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.953 total time=   1.8s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.948 total time=   1.9s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.932 total time=   1.8s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.945 total time=   1.9s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.938 total time=   1.5s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.935 total time=   1.6s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.920 total time=   1.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.946 total time=   1.6s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.930 total time=   1.7s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   1.8s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.921 total time=   1.7s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.900 total time=   1.9s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   2.1s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.911 total time=   1.9s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.912 total time=   1.9s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   2.0s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.902 total time=   1.9s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.899 total time=   1.9s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.934 total time=   1.9s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.917 total time=   1.9s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.918 total time=   2.0s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.910 total time=   1.9s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.908 total time=   2.0s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.918 total time=   2.0s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.924 total time=   2.0s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.906 total time=   1.9s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.899 total time=   2.0s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.910 total time=   1.9s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=0.867 total time=  18.3s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=0.853 total time=  21.0s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=0.874 total time=  30.6s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=0.853 total time=  39.3s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=0.857 total time=  34.4s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=0.872 total time=  33.5s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=0.875 total time=  33.2s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=0.859 total time=  32.9s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=0.858 total time=  32.5s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=0.866 total time=  31.3s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=0.884 total time=  32.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=0.871 total time=  32.8s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=0.881 total time=  33.7s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=0.857 total time=  35.9s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=0.869 total time=  34.9s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=0.877 total time=  32.9s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=0.877 total time=  33.1s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=0.859 total time=  33.5s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=0.870 total time=  32.7s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=0.860 total time=  31.7s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.952 total time=   2.8s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.940 total time=   2.7s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.950 total time=   2.8s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.945 total time=   2.7s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.935 total time=   2.8s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.942 total time=   2.8s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.940 total time=   2.9s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.932 total time=   2.8s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.924 total time=   3.1s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.942 total time=   2.6s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.953 total time=   2.8s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.941 total time=   2.9s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.950 total time=   3.1s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.946 total time=   3.0s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.935 total time=   2.9s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.944 total time=   3.0s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.940 total time=   2.7s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.933 total time=   2.6s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.924 total time=   2.7s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.942 total time=   2.6s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.933 total time=   2.7s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.910 total time=   2.9s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.924 total time=   2.8s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.906 total time=   3.0s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.912 total time=   2.9s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.914 total time=   2.8s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.924 total time=   2.9s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.913 total time=   2.8s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.910 total time=   2.8s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.912 total time=   2.7s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.932 total time=   2.9s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.914 total time=   3.2s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.925 total time=   3.2s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.912 total time=   2.9s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.911 total time=   2.9s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.917 total time=   2.8s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.926 total time=   2.7s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.913 total time=   2.8s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.912 total time=   2.7s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.915 total time=   2.6s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=0.881 total time=  33.3s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=0.865 total time=  33.4s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=0.887 total time=  33.0s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=0.859 total time=  35.9s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=0.872 total time=  34.8s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=0.877 total time=  34.1s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=0.884 total time=  33.0s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=0.860 total time=  33.3s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=0.866 total time=  27.7s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=0.868 total time=  24.5s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=0.887 total time=  33.2s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=0.870 total time=  35.6s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=0.888 total time=  30.7s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=0.866 total time=  20.9s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=0.873 total time=  22.9s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=0.883 total time=  20.8s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=0.887 total time=  21.8s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=0.863 total time=  22.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=0.867 total time=  20.9s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=0.871 total time=  19.8s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=0.957 total time=   2.4s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=0.940 total time=   2.1s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=0.946 total time=   2.1s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=0.944 total time=   2.2s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=0.935 total time=   2.3s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=0.941 total time=   2.1s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=0.944 total time=   2.2s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=0.937 total time=   2.2s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=0.926 total time=   2.1s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=0.941 total time=   2.1s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=0.954 total time=   1.9s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=0.945 total time=   2.1s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=0.950 total time=   2.2s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=0.947 total time=   2.2s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=0.937 total time=   2.0s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=0.945 total time=   1.9s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=0.944 total time=   1.8s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=0.937 total time=   2.0s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=0.925 total time=   1.7s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=0.946 total time=   1.7s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=0.930 total time=   2.0s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=0.907 total time=   2.0s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=0.913 total time=   2.5s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=0.905 total time=   2.5s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=0.908 total time=   2.5s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=0.911 total time=   2.0s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=0.910 total time=   1.9s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=0.908 total time=   1.9s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=0.900 total time=   1.9s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=0.905 total time=   2.0s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=0.932 total time=   2.2s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=0.917 total time=   2.7s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=0.924 total time=   2.1s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=0.913 total time=   2.1s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=0.914 total time=   2.0s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=0.915 total time=   1.9s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=0.928 total time=   2.2s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=0.915 total time=   2.3s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=0.910 total time=   2.0s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=0.914 total time=   2.0s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=0.886 total time=  20.8s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=0.858 total time=  19.8s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=0.878 total time=  18.7s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=0.853 total time=  20.4s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=0.858 total time=  19.9s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=0.880 total time=  20.0s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=0.885 total time=  19.7s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=0.872 total time=  18.4s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=0.865 total time=  19.3s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=0.871 total time=  17.8s\n",
      "[CV 1/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=0.890 total time=  19.6s\n",
      "[CV 2/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=0.872 total time=  20.1s\n",
      "[CV 3/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=0.897 total time=  20.2s\n",
      "[CV 4/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=0.859 total time=  21.0s\n",
      "[CV 5/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=0.873 total time=  20.3s\n",
      "[CV 6/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=0.887 total time=  20.2s\n",
      "[CV 7/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=0.888 total time=  20.0s\n",
      "[CV 8/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=0.868 total time=  19.1s\n",
      "[CV 9/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=0.863 total time=  19.3s\n",
      "[CV 10/10] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=0.866 total time=  18.6s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.950 total time=   0.2s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.940 total time=   0.2s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.947 total time=   0.2s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.948 total time=   0.2s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.931 total time=   0.2s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.946 total time=   0.2s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.942 total time=   0.2s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.935 total time=   0.3s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.919 total time=   0.3s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.940 total time=   0.3s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.954 total time=   0.2s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.940 total time=   0.2s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.953 total time=   0.1s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.948 total time=   0.1s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.932 total time=   0.1s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.945 total time=   0.2s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.938 total time=   0.2s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.935 total time=   0.1s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.920 total time=   0.1s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.946 total time=   0.1s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.930 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.921 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.900 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.911 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.904 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.902 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.899 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.934 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.917 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.918 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.910 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.908 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.918 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.924 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.906 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.899 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.910 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=0.867 total time=   8.6s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=0.853 total time=   8.7s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=0.874 total time=   9.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=0.853 total time=   8.7s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=0.857 total time=   9.5s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=0.872 total time=   9.3s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=0.875 total time=   9.2s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=0.859 total time=   8.9s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=0.858 total time=   8.9s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=0.866 total time=   9.2s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=0.884 total time=   5.5s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=0.871 total time=   5.5s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=0.881 total time=   5.6s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=0.857 total time=   5.5s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=0.869 total time=   5.3s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=0.877 total time=   5.4s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=0.877 total time=   5.5s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=0.859 total time=   5.9s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=0.870 total time=   6.1s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=0.860 total time=   5.9s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.952 total time=   0.2s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.940 total time=   0.2s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.950 total time=   0.2s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.945 total time=   0.2s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.935 total time=   0.2s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.942 total time=   0.3s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.940 total time=   0.2s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.932 total time=   0.2s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.924 total time=   0.2s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.942 total time=   0.2s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.953 total time=   0.1s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.941 total time=   0.4s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.950 total time=   0.2s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.946 total time=   0.3s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.935 total time=   0.1s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.944 total time=   0.1s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.940 total time=   0.1s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.933 total time=   0.1s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.924 total time=   0.1s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.942 total time=   0.1s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.933 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.910 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.924 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.906 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.914 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.924 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.913 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.910 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.912 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.932 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.914 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.925 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.912 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.911 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.917 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.926 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.913 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.912 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.915 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=0.881 total time=   9.3s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=0.865 total time=   9.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=0.887 total time=   9.2s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=0.859 total time=   8.9s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=0.872 total time=   8.8s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=0.877 total time=   8.7s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=0.884 total time=   9.1s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=0.860 total time=   9.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=0.866 total time=   8.9s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=0.868 total time=   8.6s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=0.887 total time=   5.5s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=0.870 total time=   5.6s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=0.888 total time=   5.6s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=0.866 total time=   5.8s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=0.873 total time=   5.5s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=0.883 total time=   5.4s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=0.887 total time=   5.8s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=0.863 total time=   5.7s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=0.867 total time=   5.5s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=0.871 total time=   5.5s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=0.957 total time=   0.2s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=0.940 total time=   0.2s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=0.946 total time=   0.2s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=0.944 total time=   0.2s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=0.935 total time=   0.2s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=0.941 total time=   0.2s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=0.944 total time=   0.2s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=0.937 total time=   0.2s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=0.926 total time=   0.2s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=0.941 total time=   0.2s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=0.954 total time=   0.1s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=0.945 total time=   0.1s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=0.950 total time=   0.1s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=0.947 total time=   0.1s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=0.937 total time=   0.1s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=0.945 total time=   0.1s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=0.944 total time=   0.2s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=0.937 total time=   0.2s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=0.925 total time=   0.1s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=0.946 total time=   0.1s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=0.930 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=0.907 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=0.913 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=0.905 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=0.908 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=0.911 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=0.910 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=0.908 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=0.900 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=0.905 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=0.932 total time=   0.0s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=0.917 total time=   0.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=0.924 total time=   0.0s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=0.913 total time=   0.0s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=0.915 total time=   0.0s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=0.928 total time=   0.0s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=0.915 total time=   0.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=0.910 total time=   0.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=0.914 total time=   0.0s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=0.886 total time=   8.9s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=0.858 total time=   9.0s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=0.878 total time=   9.3s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=0.853 total time=   9.1s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=0.858 total time=  14.2s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=0.880 total time=  14.4s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=0.885 total time=  14.8s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=0.872 total time=  14.6s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=0.865 total time=  14.3s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=0.871 total time=  14.3s\n",
      "[CV 1/10] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=0.890 total time=   8.2s\n",
      "[CV 2/10] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=0.872 total time=   8.2s\n",
      "[CV 3/10] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=0.897 total time=   8.2s\n",
      "[CV 4/10] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=0.859 total time=   8.2s\n",
      "[CV 5/10] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=0.873 total time=   8.3s\n",
      "[CV 6/10] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=0.887 total time=   8.2s\n",
      "[CV 7/10] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=0.888 total time=   7.7s\n",
      "[CV 8/10] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=0.868 total time=   8.0s\n",
      "[CV 9/10] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=0.863 total time=   8.0s\n",
      "[CV 10/10] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=0.866 total time=   7.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [4, 5, 6], &#x27;p&#x27;: [1, 2, 3],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [4, 5, 6], &#x27;p&#x27;: [1, 2, 3],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             verbose=5)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
       "                         'n_neighbors': [4, 5, 6], 'p': [1, 2, 3],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = KNeighborsClassifier()\n",
    "params = {\n",
    "    'n_neighbors': [4,5,6],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1,2,3]\n",
    "}\n",
    "GS =GridSearchCV(estimator= model, param_grid=params, cv=10, verbose=5)\n",
    "GS.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = GS.best_estimator_\n",
    "y_pred = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAGwCAYAAADrIxwOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABXvklEQVR4nO3deVxU9f4/8NewzbCvyoAioOCKFqK5da+WqJmWfe26XDW1cCm9JuVSSiV5E9JSybxpuUGZaWWa+SsXLC2zUnDJ3VJEUEZUkJ1Zz+8PcmwElHHOYRjm9Xw8zqPmcz7nM+8ZcHjP+/M558gEQRBAREREJCIHawdAREREjQ8TDCIiIhIdEwwiIiISHRMMIiIiEh0TDCIiIhIdEwwiIiISHRMMIiIiEp2TtQOwNQaDAVeuXIGnpydkMpm1wyEiIjMJgoCSkhIEBwfDwUGa79mVlZXQaDSijOXi4gKFQiHKWPWJCYaZrly5gpCQEGuHQUREFsrJyUHz5s1FH7eyshLhoR5Q5etFGU+pVCIrK8vmkgwmGGby9PQEAAS/PRcONvbDtlUR8ZnWDsH+ODhaOwK74uDCj+L6pBO0+FG9xfh5LjaNRgNVvh7ZmWHw8rSsQlJcYkBozEVoNBomGI3drWkRB4UCDq629cO2VU4yZ2uHYH9kTDDqkwN/x61C6mluD08ZPDwtew4DbHcqngkGERGRBPSCAXoL7/alFwziBGMFTDCIiIgkYIAAAyzLMCw93pp4mioRERGJjhUMIiIiCRhggKUTHJaPYD1MMIiIiCSgFwToBcumOCw93po4RUJERESiYwWDiIhIAva+yJMJBhERkQQMEKC34wSDUyREREQkOlYwiIiIJMApEiIiIhIdzyIhIiIiEhkrGERERBIw/LVZOoatYoJBREQkAb0IZ5FYerw1McEgIiKSgF6ACHdTFScWa+AaDCIiIhIdKxhEREQS4BoMIiIiEp0BMughs3gMW8UpEiIiIhIdKxhEREQSMAhVm6Vj2ComGERERBLQizBFYunx1sQpEiIiIhIdKxhEREQSsPcKBhMMIiIiCRgEGQyChWeRWHi8NXGKhIiIiETHCgYREZEEOEVCREREotPDAXoLJwr0IsViDZwiISIikoDw1xoMSzbBzDUYYWFhkMlk1bapU6f+FZOAxMREBAcHw9XVFX369MHJkydNxlCr1Zg2bRoCAgLg7u6OJ598Erm5uWa/fiYYREREjcShQ4eQl5dn3Hbv3g0AGDZsGABg0aJFWLJkCZYvX45Dhw5BqVSiX79+KCkpMY4RHx+PLVu2YOPGjdi/fz9KS0sxePBg6PXm1VOYYBAREUng1hoMSzdzNGnSBEql0rht374drVq1Qu/evSEIAlJSUpCQkIChQ4ciKioKaWlpKC8vx4YNGwAARUVFWLNmDRYvXozY2FhER0dj/fr1OH78ONLT082KhQkGERGRBPSCgygbABQXF5tsarX6ns+v0Wiwfv16PPfcc5DJZMjKyoJKpUL//v2NfeRyOXr37o0DBw4AADIzM6HVak36BAcHIyoqytinrphgEBERNXAhISHw9vY2bsnJyfc8ZuvWrbh58ybGjx8PAFCpVACAwMBAk36BgYHGfSqVCi4uLvD19a21T13xLBIiIiIJGCCDwcLv8QZU3e0sJycHXl5exna5XH7PY9esWYOBAwciODjYpF0mM512EQShWtud6tLnTqxgEBERSUDMNRheXl4m270SjOzsbKSnp2PChAnGNqVSCQDVKhH5+fnGqoZSqYRGo0FhYWGtfeqKCQYREVEjs27dOjRt2hSDBg0ytoWHh0OpVBrPLAGq1mns27cPPXv2BADExMTA2dnZpE9eXh5OnDhh7FNXnCIhIiKSwN8Xad7/GILZxxgMBqxbtw7jxo2Dk9PtP/MymQzx8fFISkpCZGQkIiMjkZSUBDc3N4waNQoA4O3tjbi4OMyYMQP+/v7w8/PDzJkz0bFjR8TGxpoVBxMMIiIiCVStwbDwZmf3cXx6ejouXbqE5557rtq+2bNno6KiAlOmTEFhYSG6deuGXbt2wdPT09hn6dKlcHJywvDhw1FRUYG+ffsiNTUVjo6OZsUhE4T7SI/sWHFxMby9vdE8ZT4cXBXWDscutH7+oLVDsD8O5n2QkGUcXJytHYJd0QkafF/5OYqKikwWTorl1t+Jzcdaw93Tsn9LZSV6PP3AOclilRIrGI2E744raLI1F4WPBuLa8FAAgMeRAnj/lA9Fdjkcy3TITugAdYh7zQMIApotPwf3k0W4/Hwkyh70rbkf3dWI/1xFr8eLEBKhhqbSAacy3LBmQRByzzMZlYqrux7jZl1Bz8eK4BOgxfkTblgxrznOHavld53qbPgLl9FrQCGat6yo+n0+7Im1C0NwOcv1b70EjJ5+GQNH5sPDW4ezRz3wv3lhuPSHm9XibigMItyL5NZZJLaIizwbAfnFUvj8lA91M1eTdpnagIpWnrj2f83vOYbPnqtShWdXOvUowzepAYgfHIk5I1vC0VFA0mcXIHe15VsWNWwvvZONzv8owaLpoXg+th0yf/TE25/9AX+lxtqh2byOD5Xgm08C8dLTHTB3bFs4OglY8PEZk9/nYZPzMPS5PHyQGIbpT0Wh8Jozkj4+A1d3/s6LeaEtW9SgIz9w4AAcHR3x2GOPmbRfvHixxpu5jBkzxmT/0aNHa+zv4uKCiIgIvPXWW7D1GSJZpR5Ba8/j6phw6N1MC1Il3QNQMKgZytt633UMl9xy+O5RQTU2XMpQ7ULC6JbY/bkfss8pcOGUKxa/1AKBzbWI7FRh7dAaJReFAQ8/fhOrFzTDid88ceWiAuuXBEOVI8fgZ65bOzyb9/qzbZG+uQku/eGGrDPuWDq7JQKbaRAZVfZXDwFPPavCxg+a4cBOP2Sfc8PiWa0gdzWgz5N8/w1wEGWzVQ16imTt2rWYNm0aVq9ejUuXLqFFixYm+9PT09GhQwfjY1dX1zuHqLG/Wq3G/v37MWHCBAQFBSEuLk6S+OtD040XURblg/J23vD79orZx8s0egSt/hP5I0Kh93aRIEL75u5V9S2u5CbXNEjB0VGAoxOgUZsuhFNXOqDDQ6VWiqrxcvP86/e5qOpPhzJEDb+mWhz+6faXGK3GAcd/80T7zqX47jPzrptAjUuDTTDKysrw+eef49ChQ1CpVEhNTcUbb7xh0sff39944ZC6+Hv/0NBQrF27FocPH75rgqFWq02u+V5cXGzmK5GO56EbUFwqx6U5He7duRZNvriEylaeXHMhCQGTEq/gxG/uyD579+SX7k9FmSNOZbhjVLwKl/5U4OY1Z/R5qgBto8twOeveVzokcwiYlJCNE4c8kX2uan2FbxMtAKDwuuki1ZvXndG0Gaeo9IIMejNvt17TGLaqwdZeNm3ahDZt2qBNmzYYM2YM1q1bJ+p0RkZGBg4fPoxu3brdtV9ycrLJ9d9DQkJEi8ESTgVqNPk8G3nPtYLgfH8/RvdjhXA7U4z8YS3u3ZnMNjXpMsLbVSB5Ct9fKS2aHgaZDPgs8wS2XziCp567hh+2+sKgt90P5oZoypsXEd62HAunt6q2r9pHs6yGNjuk/2uRp6WbrWqwFYw1a9YY11Q89thjKC0txZ49e0wu9NGzZ084ONx+83/66SdER0fXOuat/hqNBlqtFpMmTcLYsWPvGsecOXPw8ssvGx8XFxc3iCRDfqkcTiU6hCadMLbJDIDrnyXw2XsVfyzvCjjc/QPW7WwxnK+rEfFypkl78Id/oCLCE7kz2kkSuz2Y8lYuevQvxoz/a4XreZx6klJethyz/tUaclc93D0NKMh3xtwPLkCVw/ddLC/Mu4jufW9i1sh2uK66XRkqvFZVufBrokXhtdvvt4+/Fjev89Rbe9cgE4yzZ8/i4MGD+OqrrwAATk5OGDFiBNauXWuSYGzatAnt2t3+I3ivP/y3+mu1Whw/fhwvvvgifH198fbbb9d6jFwur9NNZepbeVsvXHw9yqRN+XEWNEoFCvoH3TO5AICCAUEo6tXEpC3svydwbVgLlHbilMn9ETB1wWX0fKwIs/4Vgas5De93p7FSVzhCXeEID28dYnqXYHVSM2uH1AgIeCExGz37F+CVUe1xNdf0dGtVjhwF+c6IfrgI509VnRbs5GxAx24lWLvQ+l/ErM0gOMBg4VkgBhsuBTXIBGPNmjXQ6XRo1uz2B4QgCHB2dja5AUtISAgiIiLqPO7f+7dr1w4XLlzA66+/jsTERCgUtnWdAkHhCE0z0/PMDS4O0Ls7GdsdynRwLlDD6WbVPKnz1UoAgM7LGXpvF+N2J62fHLoA/mG8H/9JuoxH/q8Qic+Go6LUwThHXVbiCE2l7ZY6G7KY3sWQyQTknFegWZgaE167jNwLcuza5G/t0Gze1PkX0efJG5g/qXXV73NA1bqKshInaNQOAGTYuk6JEVOu4MpFBS5fVGDElCtQVzhg77YA6wbfAIgxxaG34etgNLgEQ6fT4eOPP8bixYvRv39/k31PP/00Pv30UwwePFiU53J0dIROp4NGo7G5BKMuPI4VQvlxlvFx8OrzAIAbg4Jx44l7XxuDzPfE+BsAgHe/Om/S/m58CHZ/7meNkBo9d089nn31MgKCtCi56Yifv/PFuoXB0Ou4BsNSg8fkAwAWbTxt0r54Vkukb66qfn7xYRBcFAZMnX/ReKGthHFtUVHGM6fsXYNLMLZv347CwkLExcXB29v0+g3/+te/sGbNmvtOMG7cuAGVSgWdTofjx4/jvffewyOPPGJzl1+tzZ1rJop7NkFxzya19K7ZuZUPiRmS3RkQ/IC1Q7A7P273xY/bOaUnhYEt774IvooMn77XHJ++xy8tdzLA8rNADOKEYhUNLsFYs2YNYmNjqyUXQFUFIykpCQUFBfc19q31G46OjggKCsLjjz+OBQsWWBQvERFRTcS4UBYvtCWib775ptZ9nTt3Np6qerdTVsPCwkz23/mYiIiIpNXgEgwiIqLGQIx7idjyvUiYYBAREUnAABkMsHQNhu0uVmaCQUREJAF7r2DYbuRERETUYLGCQUREJAFxLrRlu3UAJhhEREQSMAgyGCy9DgbvpkpERER0GysYREREEjCIMEXCC20RERGRCXHupmq7CYbtRk5EREQNFisYREREEtBDBr2FF8qy9HhrYoJBREQkAU6REBEREYmMFQwiIiIJ6GH5FIdenFCsggkGERGRBOx9ioQJBhERkQR4szMiIiIikbGCQUREJAEBMhgsXIMh8DRVIiIi+jtOkRARERGJjBUMIiIiCdj77dqZYBAREUlAL8LdVC093ppsN3IiIiJqsFjBICIikoC9T5GwgkFERCQBAxxE2cx1+fJljBkzBv7+/nBzc8ODDz6IzMxM435BEJCYmIjg4GC4urqiT58+OHnypMkYarUa06ZNQ0BAANzd3fHkk08iNzfXrDiYYBARETUShYWF6NWrF5ydnfHdd9/h1KlTWLx4MXx8fIx9Fi1ahCVLlmD58uU4dOgQlEol+vXrh5KSEmOf+Ph4bNmyBRs3bsT+/ftRWlqKwYMHQ6+v+91ROEVCREQkAb0gg97CKQ5zj1+4cCFCQkKwbt06Y1tYWJjx/wVBQEpKChISEjB06FAAQFpaGgIDA7FhwwZMnjwZRUVFWLNmDT755BPExsYCANavX4+QkBCkp6djwIABdYqFFQwiIiIJ3FqDYekGAMXFxSabWq2u8Tm3bduGLl26YNiwYWjatCmio6OxatUq4/6srCyoVCr079/f2CaXy9G7d28cOHAAAJCZmQmtVmvSJzg4GFFRUcY+dcEEg4iISALCX3dTtWQT/rqSZ0hICLy9vY1bcnJyjc954cIFrFixApGRkdi5cyeef/55vPjii/j4448BACqVCgAQGBhoclxgYKBxn0qlgouLC3x9fWvtUxecIiEiImrgcnJy4OXlZXwsl8tr7GcwGNClSxckJSUBAKKjo3Hy5EmsWLECY8eONfaTyUynXgRBqNZ2p7r0+TtWMIiIiCSgh0yUDQC8vLxMttoSjKCgILRv396krV27drh06RIAQKlUAkC1SkR+fr6xqqFUKqHRaFBYWFhrn7pggkFERCQBgyDGOgzznrNXr144e/asSdu5c+cQGhoKAAgPD4dSqcTu3buN+zUaDfbt24eePXsCAGJiYuDs7GzSJy8vDydOnDD2qQtOkRARETUSL730Enr27ImkpCQMHz4cBw8exEcffYSPPvoIQNXUSHx8PJKSkhAZGYnIyEgkJSXBzc0No0aNAgB4e3sjLi4OM2bMgL+/P/z8/DBz5kx07NjReFZJXTDBICIiksCthZqWjmGOrl27YsuWLZgzZw7mz5+P8PBwpKSkYPTo0cY+s2fPRkVFBaZMmYLCwkJ069YNu3btgqenp7HP0qVL4eTkhOHDh6OiogJ9+/ZFamoqHB0d6xyLTBAEMwsw9q24uBje3t5onjIfDq4Ka4djF1o/f9DaIdgfh7p/iJDlHFycrR2CXdEJGnxf+TmKiopMFk6K5dbfiWd++DdcPFwsGktTqsEnj3wmWaxS4hoMIiIiEh2nSIiIiCRgjSt5NiRMMIiIiCRgjTUYDQkTjPsU8dJhOMk4b1ofdl45au0Q7M6A4AetHYJdMVTW/QZSZDmDoLV2CHaBCQYREZEEDLh9LxFLxrBVTDCIiIgkIEBmcYIgMMEgIiKiv/v73VAtGcNW2e7qESIiImqwWMEgIiKSAM8iISIiItFxioSIiIhIZKxgEBERScAgwlkkPE2ViIiITHCKhIiIiEhkrGAQERFJwN4rGEwwiIiIJGDvCQanSIiIiEh0rGAQERFJwN4rGEwwiIiIJCDA8tNMBXFCsQomGERERBKw9woG12AQERGR6FjBICIikoC9VzCYYBAREUnA3hMMTpEQERGR6FjBICIikoC9VzCYYBAREUlAEGQQLEwQLD3emjhFQkRERKJjBYOIiEgCBsgsvtCWpcdbExMMIiIiCdj7GgxOkRAREZHoWMEgIiKSgL0v8mSCQUREJAF7nyJhgkFERCQBe69gcA0GERERiY4VDCIiIgkIIkyR2HIFgwkGERGRBAQAgmD5GLaKUyREREQkOiYYREREErh1JU9LN3MkJiZCJpOZbEql0rhfEAQkJiYiODgYrq6u6NOnD06ePGkyhlqtxrRp0xAQEAB3d3c8+eSTyM3NNfv1M8EgIiKSwK2zSCzdzNWhQwfk5eUZt+PHjxv3LVq0CEuWLMHy5ctx6NAhKJVK9OvXDyUlJcY+8fHx2LJlCzZu3Ij9+/ejtLQUgwcPhl6vNysOrsEgIiJqRJycnEyqFrcIgoCUlBQkJCRg6NChAIC0tDQEBgZiw4YNmDx5MoqKirBmzRp88skniI2NBQCsX78eISEhSE9Px4ABA+ocBysYREREErh1oS1LNwAoLi422dRqda3P+8cffyA4OBjh4eEYOXIkLly4AADIysqCSqVC//79jX3lcjl69+6NAwcOAAAyMzOh1WpN+gQHByMqKsrYp66YYBAREUlAEMTZACAkJATe3t7GLTk5ucbn7NatGz7++GPs3LkTq1atgkqlQs+ePXHjxg2oVCoAQGBgoMkxgYGBxn0qlQouLi7w9fWttU9dcYqEiIiogcvJyYGXl5fxsVwur7HfwIEDjf/fsWNH9OjRA61atUJaWhq6d+8OAJDJTNd1CIJQre1OdelzJ1YwiIiIJCDmIk8vLy+TrbYE407u7u7o2LEj/vjjD+O6jDsrEfn5+caqhlKphEajQWFhYa196ooJBhERkQSsdRbJ36nVapw+fRpBQUEIDw+HUqnE7t27jfs1Gg327duHnj17AgBiYmLg7Oxs0icvLw8nTpww9qkrTpE0cmNezsMzM66atBXkO+Hf0VFWish2jX2oPa7mulRrf2LcNfwn+TIGBD9Y43ETXruMYVOuAQA0ahlWzQ/G3q2+UFfKEP1wKf6TnIsmwVopQ2/UBo+9jkFjbyAwRAMAyD6rwKdLA5Hxg9c9jiRLDB53HcNeuAa/plpkn1Ng5RvBOHHQw9phNSgGQQZZPd9NdebMmXjiiSfQokUL5Ofn46233kJxcTHGjRsHmUyG+Ph4JCUlITIyEpGRkUhKSoKbmxtGjRoFAPD29kZcXBxmzJgBf39/+Pn5YebMmejYsaPxrJK6alQJRn5+Pl5//XV89913uHr1Knx9ffHAAw8gMTERPXr0QFhYGLKzswEADg4OCAwMxMCBA/Huu+9WW9DSmFw8o8CrI1sZHxv0tntte2ta9t1Zk/fu4hkF5oyMwD+eKAIAfHb0hEn/Q997YemMEDw8qMjYtnJeM/y22wtzVlyEl68eH80PxhtjW2L5zrNwdKyf19HYXMtzxtqkIFy5WFUy7jesAInrLmJq/9bIPqewcnSNU+8nC/H8m1ewfG4znDzojkHP3MBbn2ZhYp82uHa5ehJO9Sc3Nxf//ve/cf36dTRp0gTdu3fHr7/+itDQUADA7NmzUVFRgSlTpqCwsBDdunXDrl274OnpaRxj6dKlcHJywvDhw1FRUYG+ffsiNTUVjmZ+SDWqBOPpp5+GVqtFWloaWrZsiatXr2LPnj0oKCgw9pk/fz4mTpwIvV6Pc+fOYdKkSXjxxRfxySefWDFyaen1QOE1Z2uHYfN8/E0vMrNpuTeCwtTo1KMUAODXVGey/5ed3nigVymCQqu+WZcVO2DnZ36YtewSOv+z6phX3s/GmC4dcOQnT3TpUwIy32+7vU0epy4MwuCxN9A2powJhkSGTrqOnZ/5YccGfwBViXNMnxIMHnsD65KDrBxdw/H3s0AsGcMcGzduvOt+mUyGxMREJCYm1tpHoVDg/fffx/vvv2/ek9+h0SQYN2/exP79+7F371707t0bABAaGoqHHnrIpJ+np6dxoUuzZs0wduzYe/5AbF2zcA02ZJ6AVuOAM0fcsO7tIKgu1W2BENVMq5Hh+82+GDo5HzUtrC685oSDe7wwMyXb2PbH727QaR0Q0/t2IuGv1CG0bSVOHXJngiECBwcB/3jiJuRuBpzOcLd2OI2Sk7MBkZ3KsWl5U5P2zH2eaN+lzEpRNUxVCYald1MVKRgraDQJhoeHBzw8PLB161Z07969TitsL1++jO3bt6Nbt2619lGr1SYXNCkuLhYl3vpy5og73pnuitwLcvg20eHfL6qw9Os/MOnRtigpbDQ//np3YIc3Sosd0X94QY37d3/uB1cPPR5+/Pb0SEG+E5xdDPD0Ma2E+AZoUXiNPwtLhLWtQMo3f8JFbkBFmQPmx4Xh0h+sXkjBy08PRyfg5nXT39mb15zge0cVj+xbozmLxMnJCampqUhLS4OPjw969eqFuXPn4vfffzfp98orr8DDwwOurq5o3rw5ZDIZlixZUuu4ycnJJhc3CQkJkfqliCrjBy/s/9YHF8+44shPnnh9bEsAVfPUdP92fuaHro8Uw19Z8wfqzo1+ePT/CuGiuPfXD0GQwcz7GdEdcs/LMaVfa0wfHIntHwdg5nuX0CKy0tphNWp3frOWyWDb9xaXQEM4i8SaGk2CAVStwbhy5Qq2bduGAQMGYO/evejcuTNSU1ONfWbNmoWjR4/i999/x549ewAAgwYNqvUmLnPmzEFRUZFxy8nJqY+XIhl1hSMunlGgWXjtl5mlu7ua64wjP3nisVE3atx//Dd35J5XVNvv11QHrcYBJTdNF0rdvOEE3wB+87OETuuAKxfl+ON3N6xLDkLWKVc8NeGatcNqlIoLHKHXAb5NTH9nvQN0rMTdQRBps1WNKsEAqhan9OvXD2+88QYOHDiA8ePHY968ecb9AQEBiIiIQGRkJB599FGkpKTgwIED+OGHH2ocTy6XV7vAiS1zdjEgJFKNgqtc9Hm/dm30h0+ADt1ia54u2/mZPyI7laNVB9Nv0JGdyuHkbMDhH2+v1r5x1QnZZxRo35Vz12JzdrHlj+aGS6d1wB+/u6HzP03XDHX+ZwlOcd0L/U2jTzfbt2+PrVu31rr/1mk3FRUV9RRR/Zr4+mX8utsb+Zed4ROgw6jpV+HmocfuL/ysHZpNMhiAXZv8EDusAI41/OspK3HAj994Y9K8K9X2uXsZMODfBfjozWB4+erg6aPHqv8GI6xtJaL/wQWe9+vZV/Nw6HtPXLviAlcPPfoMuYlOPUvx2uiW1g6t0frqowDMWpaDc7+74nSGOx4fcwNNm2nx/z72t3ZoDYoYUxy2PEXSaBKMGzduYNiwYXjuuefQqVMneHp6IiMjA4sWLcKQIUOM/UpKSqBSqSAIAnJycjB79mwEBASYfYUyWxEQpMWc/12El58eRTeccOawG+KfaI18nqt+X4786In8yy4YMLLmNSz7vvYFBBkeeaqwxv3PJ16Go6OABc+HQVPhgAcfLsGbaRd4DQwL+DTRYdb7l+DXVIfyEkdknVbgtdEtTSpFJK5923zh6avH6Jeuwq+pDtlnFXhtTDg/V+4kxhyHDRfiZIJgyyfB3KZWq5GYmIhdu3bh/Pnz0Gq1CAkJwbBhwzB37ly4urqaXGgLAJo0aYKuXbtiwYIFePDBB+v0PMXFxfD29kYf2VNwknGaoT7svHzE2iHYndquSkrUGOgELfbiaxQVFUky7X3r70TL1AQ4uFl2NpOhvBIXxi+QLFYpNZoKhlwuR3Jycq23sAWAixcv1l9AREREdqzRJBhEREQNiTWu5NmQMMEgIiKSgL0v8mx0p6kSERGR9bGCQUREJAVBVrVZOoaNYoJBREQkAXtfg8EpEiIiIhIdKxhERERSsPMLbTHBICIikoC9n0VSpwRj2bJldR7wxRdfvO9giIiIqHGoU4KxdOnSOg0mk8mYYBAREd1iw1MclqpTgpGVlSV1HERERI2KvU+R3PdZJBqNBmfPnoVOpxMzHiIiosZBEGmzUWYnGOXl5YiLi4Obmxs6dOiAS5cuAahae/H222+LHiARERHZHrMTjDlz5uDYsWPYu3cvFIrbt6GNjY3Fpk2bRA2OiIjIdslE2myT2aepbt26FZs2bUL37t0hk91+4e3bt8f58+dFDY6IiMhm2fl1MMyuYFy7dg1Nmzat1l5WVmaScBAREZH9MjvB6Nq1K/7f//t/xse3kopVq1ahR48e4kVGRERky+x8kafZUyTJycl47LHHcOrUKeh0Orz33ns4efIkfvnlF+zbt0+KGImIiGyPnd9N1ewKRs+ePfHzzz+jvLwcrVq1wq5duxAYGIhffvkFMTExUsRIRERENua+7kXSsWNHpKWliR0LERFRo2Hvt2u/rwRDr9djy5YtOH36NGQyGdq1a4chQ4bAyYn3TiMiIgJg92eRmJ0RnDhxAkOGDIFKpUKbNm0AAOfOnUOTJk2wbds2dOzYUfQgiYiIyLaYvQZjwoQJ6NChA3Jzc3H48GEcPnwYOTk56NSpEyZNmiRFjERERLbn1iJPSzcbZXYF49ixY8jIyICvr6+xzdfXFwsWLEDXrl1FDY6IiMhWyYSqzdIxbJXZFYw2bdrg6tWr1drz8/MREREhSlBEREQ2z86vg1GnBKO4uNi4JSUl4cUXX8SXX36J3Nxc5Obm4ssvv0R8fDwWLlwodbxERERkA+o0ReLj42NyGXBBEDB8+HBjm/DXeTRPPPEE9Hq9BGESERHZGDu/0FadEowffvhB6jiIiIgaF56mem+9e/eWOg4iIiISUXJyMubOnYvp06cjJSUFQNWMw5tvvomPPvoIhYWF6NatG/73v/+hQ4cOxuPUajVmzpyJzz77DBUVFejbty8++OADNG/e3KznN3uR5y3l5eU4c+YMfv/9d5ONiIiIYNVFnocOHcJHH32ETp06mbQvWrQIS5YswfLly3Ho0CEolUr069cPJSUlxj7x8fHYsmULNm7ciP3796O0tBSDBw82ewnEfd2uffDgwfD09ESHDh0QHR1tshERERGslmCUlpZi9OjRWLVqlcklJQRBQEpKChISEjB06FBERUUhLS0N5eXl2LBhAwCgqKgIa9asweLFixEbG4vo6GisX78ex48fR3p6ullxmJ1gxMfHo7CwEL/++itcXV2xY8cOpKWlITIyEtu2bTN3OCIiIrqHv5/NWVxcDLVaXWvfqVOnYtCgQYiNjTVpz8rKgkqlQv/+/Y1tcrkcvXv3xoEDBwAAmZmZ0Gq1Jn2Cg4MRFRVl7FNXZl9o6/vvv8fXX3+Nrl27wsHBAaGhoejXrx+8vLyQnJyMQYMGmTskERFR4yPiWSQhISEmzfPmzUNiYmK17hs3bsThw4dx6NChavtUKhUAIDAw0KQ9MDAQ2dnZxj4uLi4mlY9bfW4dX1dmJxhlZWVo2rQpAMDPzw/Xrl1D69at0bFjRxw+fNjc4YiIiBolMa/kmZOTAy8vL2O7XC6v1jcnJwfTp0/Hrl27oFAoah9TZpr0CIJQre1Odelzp/u6kufZs2cBAA8++CA+/PBDXL58GStXrkRQUJC5wxEREdE9eHl5mWw1JRiZmZnIz89HTEwMnJyc4OTkhH379mHZsmVwcnIyVi7urETk5+cb9ymVSmg0GhQWFtbap67uaw1GXl4egKoSzY4dO9CiRQssW7YMSUlJ5g5HRETUONXzIs++ffvi+PHjOHr0qHHr0qULRo8ejaNHj6Jly5ZQKpXYvXu38RiNRoN9+/ahZ8+eAICYmBg4Ozub9MnLy8OJEyeMferK7CmS0aNHG/8/OjoaFy9exJkzZ9CiRQsEBASYOxwRERGJwNPTE1FRUSZt7u7u8Pf3N7bHx8cjKSkJkZGRiIyMRFJSEtzc3DBq1CgAgLe3N+Li4jBjxgz4+/vDz88PM2fORMeOHastGr0XsxOMO7m5uaFz586WDkNERNSoyCDCGgxRIrlt9uzZqKiowJQpU4wX2tq1axc8PT2NfZYuXQonJycMHz7ceKGt1NRUODo6mhe7cOtGInfx8ssv13nAJUuWmBWArSkuLoa3tzf6yJ6Ck8zZ2uHYhZ2Xj1g7BLszIPhBa4dAJBmdoMVefI2ioiKThZNiufV3InThW3C4y2LLujBUViL7ldcki1VKdapgHDlStw94c1eY2jTBxu+ja0MGtuxu7RDszrmVne7diUTTekqmtUOwL4IBMNTH8/BmZ/fEm50RERGZyc5vdnbf9yIhIiIiqo3FizyJiIioBnZewWCCQUREJAExr+RpizhFQkRERKJjBYOIiEgKdj5Fcl8VjE8++QS9evVCcHCw8Q5sKSkp+Prrr0UNjoiIyGbV86XCGxqzE4wVK1bg5ZdfxuOPP46bN29Cr9cDAHx8fJCSkiJ2fERERGSDzE4w3n//faxatQoJCQkmlw3t0qULjh8/LmpwREREturWIk9LN1tl9hqMrKwsREdHV2uXy+UoKysTJSgiIiKbZ+dX8jS7ghEeHo6jR49Wa//uu+/Qvn17MWIiIiKyfXa+BsPsCsasWbMwdepUVFZWQhAEHDx4EJ999hmSk5OxevVqKWIkIiIiG2N2gvHss89Cp9Nh9uzZKC8vx6hRo9CsWTO89957GDlypBQxEhER2Rx7v9DWfV0HY+LEiZg4cSKuX78Og8GApk2bih0XERGRbbPz62BYdKGtgIAAseIgIiKiRsTsBCM8PBwyWe2rWi9cuGBRQERERI2CGKeZ2lMFIz4+3uSxVqvFkSNHsGPHDsyaNUusuIiIiGwbp0jMM3369Brb//e//yEjI8PigIiIiMj2iXY31YEDB2Lz5s1iDUdERGTbeB0McXz55Zfw8/MTazgiIiKbxtNUzRQdHW2yyFMQBKhUKly7dg0ffPCBqMERERGRbTI7wXjqqadMHjs4OKBJkybo06cP2rZtK1ZcREREZMPMSjB0Oh3CwsIwYMAAKJVKqWIiIiKyfXZ+FolZizydnJzwwgsvQK1WSxUPERFRo2Dvt2s3+yySbt264ciRI1LEQkRERI2E2WswpkyZghkzZiA3NxcxMTFwd3c32d+pUyfRgiMiIrJpNlyBsFSdE4znnnsOKSkpGDFiBADgxRdfNO6TyWQQBAEymQx6vV78KImIiGyNna/BqHOCkZaWhrfffhtZWVlSxkNERESNQJ0TDEGoSqNCQ0MlC4aIiKix4IW2zHC3u6gSERHR33CKpO5at259zySjoKDAooCIiIjI9pmVYLz55pvw9vaWKhYiIqJGg1MkZhg5ciSaNm0qVSxERESNh51PkdT5Qltcf0FERER1ZfZZJERERFQHdl7BqHOCYTAYpIyDiIioUbH3NRhm34uEiIiI6kAQaTPDihUr0KlTJ3h5ecHLyws9evTAd999dzskQUBiYiKCg4Ph6uqKPn364OTJkyZjqNVqTJs2DQEBAXB3d8eTTz6J3Nxcs18+EwwiIqJGonnz5nj77beRkZGBjIwMPProoxgyZIgxiVi0aBGWLFmC5cuX49ChQ1AqlejXrx9KSkqMY8THx2PLli3YuHEj9u/fj9LSUgwePNjsW4EwwSAiIpKCFSoYTzzxBB5//HG0bt0arVu3xoIFC+Dh4YFff/0VgiAgJSUFCQkJGDp0KKKiopCWloby8nJs2LABAFBUVIQ1a9Zg8eLFiI2NRXR0NNavX4/jx48jPT3drFiYYBAREUng1hoMSzcAKC4uNtnUavU9n1+v12Pjxo0oKytDjx49kJWVBZVKhf79+xv7yOVy9O7dGwcOHAAAZGZmQqvVmvQJDg5GVFSUsU9dmX27drItg8dex6CxNxAYogEAZJ9V4NOlgcj4wcvKkTUOUV2L8a9JeYiIKoN/oBbzJ0fil91+xv0+AVo8N/sSOv+jCO5eepw46IkVb4bhykWFFaO2Tb47rqDJ1lwUPhqIa8Or7onkcaQA3j/lQ5FdDscyHbITOkAd4l7zAIKAZsvPwf1kES4/H4myB33rMfrGxdVdj3GzrqDnY0XwCdDi/Ak3rJjXHOeO1fLek8VCQkJMHs+bNw+JiYk19j1+/Dh69OiByspKeHh4YMuWLWjfvr0xQQgMDDTpHxgYiOzsbACASqWCi4sLfH19q/VRqVRmxcwEo5G7lueMtUlBuHJRDgDoN6wAiesuYmr/1sg+xz9yllK4GXDhtBt2fdkEr6/44469At5YeQ46nQzzJ7dGWYkjhsapkPTJaUzu3wnqCkerxGyL5BdL4fNTPtTNXE3aZWoDKlp5oqSzH5TrL951DJ89VyWM0L689E42wtpUYtH0UBRcdcajQwvw9md/YOKj7XFD5WLt8BoOEU9TzcnJgZfX7S+Gcrm81kPatGmDo0eP4ubNm9i8eTPGjRuHffv2GfffeV0rQRDuea2ruvS5U6OaIsnPz8fkyZPRokULyOVyKJVKDBgwAL/88gsAICwsDDKZDDKZDK6urmjbti3eeeedRn2Nj992e+PQ9164fEGOyxfkSF0YhMoyB7SNKbN2aI1Cxj4ffLwkBAd2+lXb1yy8Eu06l2L562E497sHLme54n9vhMHVzYA+T9ywQrS2SVapR9Da87g6Jhx6N9PvRCXdA1AwqBnK2979FgYuueXw3aOCamy4lKHaBReFAQ8/fhOrFzTDid88ceWiAuuXBEOVI8fgZ65bO7wGRcwpkltnhdza7pZguLi4ICIiAl26dEFycjIeeOABvPfee1AqlQBQrRKRn59vrGoolUpoNBoUFhbW2qeuGlWC8fTTT+PYsWNIS0vDuXPnsG3bNvTp08fkBmzz589HXl4eTp8+jZkzZ2Lu3Ln46KOPrBh1/XFwENB7SCHkbgaczmApU2rOLlWfDFr17X9mBoMMOq0MHbqU1HYY3aHpxosoi/JBebv7uw+STKNH0Oo/kT8iFHpvfru2lKOjAEcnQKM2/TarrnRAh4dKrRQV3Y0gCFCr1QgPD4dSqcTu3buN+zQaDfbt24eePXsCAGJiYuDs7GzSJy8vDydOnDD2qatGM0Vy8+ZN7N+/H3v37kXv3r0BAKGhoXjooYdM+nl6ehqzuAkTJmDFihXYtWsXJk+eXOO4arXaZDFNcXGxRK9AOmFtK5DyzZ9wkRtQUeaA+XFhuPQHp0eklnNegau5Lhg/KwfvJ4SjssIB/xengl9TLfyaaq0dnk3wPHQDikvluDSnw32P0eSLS6hs5ck1FyKpKHPEqQx3jIpX4dKfCty85ow+TxWgbXQZLmfV/q3aLlnhSp5z587FwIEDERISgpKSEmzcuBF79+7Fjh07IJPJEB8fj6SkJERGRiIyMhJJSUlwc3PDqFGjAADe3t6Ii4vDjBkz4O/vDz8/P8ycORMdO3ZEbGysWbE0mgTDw8MDHh4e2Lp1K7p3737X8hFQldHt27cPp0+fRmRkZK39kpOT8eabb4odbr3KPS/HlH6t4e6lx8ODijDzvUuYNTSCSYbE9DoHvDWlNeLfvoAvjmZCrwOO/OyNQ3t5R+K6cCpQo8nn2cid3haC8/0VW92PFcLtTDGyE6JEjs6+LZoehpcXZ+OzzBPQ64A/T7jhh62+iIiqsHZoDYsVEoyrV6/imWeeQV5eHry9vdGpUyfs2LED/fr1AwDMnj0bFRUVmDJlCgoLC9GtWzfs2rULnp6exjGWLl0KJycnDB8+HBUVFejbty9SU1Ph6GjeujGZ0IgWIGzevBkTJ05ERUUFOnfujN69e2PkyJHo1KkTgKo1GHl5eXB2doZGo4FWq4VCocCePXtqLf3UVMEICQlBHwyBk8y5Xl6X2N7edB5XLrpg2Ssh9+7cADgobCMR+u7Cb9XOIrnFzVMHZ2cBRQXOWPrVCfxx3B0fzGu46wHOpHSydghwP1qIZiv/gPC33EJmAAQZABnwx/KugENVmd7puhotXztW7SySJp9nw+eHq4Cs+hgVEZ7IndGunl7N3bWekmntEO6L3FUPd08DCvKdMfeDC1C4G/DGuAhrh3VPOkGLvYavUFRUZLJwUizFxcXw9vZGuylJcJRb9vmlV1fi9AdzJYtVSo2mggFUrcEYNGgQfvrpJ/zyyy/YsWMHFi1ahNWrV2P8+PEAgFmzZmH8+PG4du0aEhIS8Oijj951Xkkul9+zGmKLbq0PoPpRXlL1Ty04rBKRHcvwyZLmVo6o4Stv64WLr5tWHpQfZ0GjVKCgf5AxubibggFBKOrVxKQt7L8ncG1YC5R24pSJpdQVjlBXOMLDW4eY3iVYndTM2iE1KH/lwhaPYasaVYIBAAqFAv369UO/fv3wxhtvYMKECZg3b54xwQgICEBERAQiIiKwefNmREREoHv37mbPLdmKZ1/Nw6HvPXHtigtcPfToM+QmOvUsxWujW1o7tEZB4aZHcGil8XFgiBot25WhpMgJ167I8fDAGygqcMa1Ky4Ia1OO59/Ixi+7fXF4v4/1grYRgsIRmmZuJm0GFwfo3Z2M7Q5lOjgXqOF0s2pNi/PVqp+FzssZem8X43YnrZ8cuoDG98WhvsT0LoZMJiDnvALNwtSY8Npl5F6QY9cmf2uH1rDwbqqNW/v27bF169Ya9/n6+mLatGmYOXMmjhw5YvY5vrbAp4kOs96/BL+mOpSXOCLrtAKvjW6Jwz963vtguqfIjmVY9Nlp4+PJr10CAOz+MgBLZreCX1MtJiVcgk+AFgXXnLHnqwB8tpzf8sTicawQyo+zjI+DV58HANwYFIwbT7BKJBV3Tz2effUyAoK0KLnpiJ+/88W6hcHQ6xrfZ6gl7P1uqo0mwbhx4waGDRuG5557Dp06dYKnpycyMjKwaNEiDBkypNbjpk6dioULF2Lz5s3417/+VY8R14+lM2xjnYWtOv6bFwa27Fbr/m1pSmxLU9ZjRI3bnWsmins2QXHPJrX0rtm5lQ/duxPd1Y/bffHjdk4x0d01mgTDw8MD3bp1w9KlS3H+/HlotVqEhIRg4sSJmDt3bq3HNWnSBM888wwSExMxdOhQODg0qkuDEBGRtXCKpHGQy+VITk5GcnJyrX0uXrxYY7u9XGiLiIjqmQ0nCJbi13UiIiISXaOpYBARETUkXORJRERE4rPzNRicIiEiIiLRsYJBREQkAU6REBERkfg4RUJEREQkLlYwiIiIJMApEiIiIhKfnU+RMMEgIiKSgp0nGFyDQURERKJjBYOIiEgCXINBRERE4uMUCREREZG4WMEgIiKSgEwQIBMsK0FYerw1McEgIiKSAqdIiIiIiMTFCgYREZEEeBYJERERiY9TJERERETiYgWDiIhIApwiISIiIvHZ+RQJEwwiIiIJ2HsFg2swiIiISHSsYBAREUmBUyREREQkBVue4rAUp0iIiIhIdKxgEBERSUEQqjZLx7BRTDCIiIgkwLNIiIiIiETGCgYREZEU7PwsElYwiIiIJCAziLOZIzk5GV27doWnpyeaNm2Kp556CmfPnjXpIwgCEhMTERwcDFdXV/Tp0wcnT5406aNWqzFt2jQEBATA3d0dTz75JHJzc82KhQkGERFRI7Fv3z5MnToVv/76K3bv3g2dTof+/fujrKzM2GfRokVYsmQJli9fjkOHDkGpVKJfv34oKSkx9omPj8eWLVuwceNG7N+/H6WlpRg8eDD0en2dY+EUCRERkRSsMEWyY8cOk8fr1q1D06ZNkZmZiX/+858QBAEpKSlISEjA0KFDAQBpaWkIDAzEhg0bMHnyZBQVFWHNmjX45JNPEBsbCwBYv349QkJCkJ6ejgEDBtQpFlYwiIiIJHDrLBJLNwAoLi422dRqdZ1iKCoqAgD4+fkBALKysqBSqdC/f39jH7lcjt69e+PAgQMAgMzMTGi1WpM+wcHBiIqKMvapCyYYREREUrh1HQxLNwAhISHw9vY2bsnJyXV4egEvv/wyHn74YURFRQEAVCoVACAwMNCkb2BgoHGfSqWCi4sLfH19a+1TF5wiISIiauBycnLg5eVlfCyXy+95zH/+8x/8/vvv2L9/f7V9MpnM5LEgCNXa7lSXPn/HCgYREZEExJwi8fLyMtnulWBMmzYN27Ztww8//IDmzZsb25VKJQBUq0Tk5+cbqxpKpRIajQaFhYW19qkLVjDuk4ObKxxkLtYOwy4YysutHYLdaf3CIWuHYFfOrY6xdgh2xVBRCUz9SvonssIiT0EQMG3aNGzZsgV79+5FeHi4yf7w8HAolUrs3r0b0dHRAACNRoN9+/Zh4cKFAICYmBg4Oztj9+7dGD58OAAgLy8PJ06cwKJFi+ocCxMMIiKiRmLq1KnYsGEDvv76a3h6ehorFd7e3nB1dYVMJkN8fDySkpIQGRmJyMhIJCUlwc3NDaNGjTL2jYuLw4wZM+Dv7w8/Pz/MnDkTHTt2NJ5VUhdMMIiIiCRgjXuRrFixAgDQp08fk/Z169Zh/PjxAIDZs2ejoqICU6ZMQWFhIbp164Zdu3bB09PT2H/p0qVwcnLC8OHDUVFRgb59+yI1NRWOjo51joUJBhERkRSscDdVoQ79ZTIZEhMTkZiYWGsfhUKB999/H++//75Zz/93XORJREREomMFg4iISAL2frt2JhhERERS4N1UiYiIiMTFCgYREZEEOEVCRERE4jMIVZulY9goJhhERERS4BoMIiIiInGxgkFERCQBGURYgyFKJNbBBIOIiEgKVriSZ0PCKRIiIiISHSsYREREEuBpqkRERCQ+nkVCREREJC5WMIiIiCQgEwTILFykaenx1sQEg4iISAqGvzZLx7BRnCIhIiIi0bGCQUREJAFOkRAREZH47PwsEiYYREREUuCVPImIiIjExQoGERGRBHglTyIiIhIfp0iIiIiIxMUKBhERkQRkhqrN0jFsFRMMIiIiKXCKhIiIiEhcrGAQERFJgRfaIiIiIrHZ+6XCOUVCREREomMFg4iISAp2vsiTCQYREZEUBACWnmZqu/kFEwwiIiIpcA0GERERkchYwSAiIpKCABHWYIgSiVUwwSAiIpKCnS/y5BQJERERiY4JRiMy/PnLeO+r37H56G/47LdDeH3FGTQLr6i1/7T/nsd3f/6Cp8bn1WOUjV9Ut1K8mZaFDYdPYueVY+jxWJG1Q2rU/JUazF6WjS9OHMfXfx7DB7vOIKJjubXDahR8/18eWsdloMlnl4xt/l9fRljCCUS8cBitph1Bs3fPQnGh1OQ4733X0HzRGbSaehit4zLgUK6r79AbBoNImxl+/PFHPPHEEwgODoZMJsPWrVtN9guCgMTERAQHB8PV1RV9+vTByZMnTfqo1WpMmzYNAQEBcHd3x5NPPonc3FzzAgETjEal40NF+Ga9Ei8N64i549rD0VHAgtRTkLvqq/XtEVuANg+U4rrK2QqRNm4KNwMunFTgfwnNrB1Ko+fhrcOSrX9Ar5PhtTEtMalPW3w0vxnKih2tHZrNk2eVwefHa1A3dzVp1wQqkD+6BbLnd0DOq22hC5Cj2ZI/4FiiNfaRaQwoi/JGwaCg+g67Qbl1FomlmznKysrwwAMPYPny5TXuX7RoEZYsWYLly5fj0KFDUCqV6NevH0pKSox94uPjsWXLFmzcuBH79+9HaWkpBg8eDL2++t+Su7F6gqFSqTB9+nRERERAoVAgMDAQDz/8MFauXIny8qpvIUeOHMHgwYPRtGlTKBQKhIWFYcSIEbh+/ToyMzMhk8mwf//+GscfMGAAnnzySchksrtu48ePr8dXLY3Xn2uP9K+a4tIfbsg6446lr0YgsJkGkVFlJv38A9WYkpiFRTMioddZ/Veg0cn4wQtpi4Lw83c+1g6l0Rs+JR/Xr7hg8cstcPaoO67mynF0vyfysuXWDs2mySr1CFp1AVfHhUHvbpqslXT3R3l7L2ibyKFp5oprI0LgWKGHS87taunNfoEofDwIlS3d6zt0uzdw4EC89dZbGDp0aLV9giAgJSUFCQkJGDp0KKKiopCWloby8nJs2LABAFBUVIQ1a9Zg8eLFiI2NRXR0NNavX4/jx48jPT3drFis+tflwoULiI6Oxq5du5CUlIQjR44gPT0dL730Er755hukp6cjPz8fsbGxCAgIwM6dO3H69GmsXbsWQUFBKC8vR0xMDB544AGsW7eu2vg5OTlIT09HXFwc8vLyjFtKSgq8vLxM2t577z0rvAPScvOsKkuW3Ly9llcmEzDz3T/x5apgXPrDzVqhEYmie/8inPvdDQkfZmHTsRP4386zGDjqhrXDsnlNP72Esk7eKG/vdfeOOgO8912D3tUR6hDXu/e1R7cWeVq6ASguLjbZ1Gq12eFkZWVBpVKhf//+xja5XI7evXvjwIEDAIDMzExotVqTPsHBwYiKijL2qSurnkUyZcoUODk5ISMjA+7utzPdjh074umnn4YgCPj6669RXFyM1atXw8mpKtzw8HA8+uijxv5xcXGYO3culi1bZjJOamoqmjRpgkGDBhmPBQBvb2/IZDIolcp6eJXWImDS3GycOOSJ7L8lEsMmX4FBL8PXaY35tZO9CGqhweBnruOrVU2wcVkg2kSX44X5udBqZEj/0s/a4dkkz98KoMgux6XX29Xax/3YTQR9eAEyjQF6b2fkzmgNgyenW6sR8SySkJAQk+Z58+YhMTHRrKFUKhUAIDAw0KQ9MDAQ2dnZxj4uLi7w9fWt1ufW8XVltQrGjRs3sGvXLkydOtUkKfi7W0mATqfDli1bINTygxo9ejS0Wi2++OILY5sgCEhNTcW4ceNMkgtzqdXqapmjLZiSmIXwNuVY+FKksS2iQymGjMvD4tkRAGTWC45IJDIH4M8Trlj3djDOn3TDt+sD8N0Gfwwae93aodkkpwINmmy8hLyJ4RCca//zUN7WE9nz2iNnTluURXkjeOV5OBZra+1PlsvJyUFRUZFxmzNnzn2PJZOZfv4LglCt7U516XMnqyUYf/75JwRBQJs2bUzaAwIC4OHhAQ8PD7zyyivo3r075s6di1GjRiEgIAADBw7EO++8g6tXrxqP8fPzw1NPPWUyTbJ3715cuHABzz33nEVxJicnw9vb27jdmUU2RC+8kYXufQvxypj2uK66PRcd1bUEPv5afPxjJraf+QXbz/yCwOZqTJhzEal7D1sxYqL7U5DvhOxzCpO2nD8VaBrMP3b3Q36xDE7FOoTOP4XIiRmInJgBt7Ol8NmTj8iJGYCh6kueIHeENlCBylYeuPpsGAQHGbx+YlJXjYhTJF5eXiabXG7+OqNbVfs7KxH5+fnGqoZSqYRGo0FhYWGtferK6iv87syIDh48iKNHj6JDhw7GOaYFCxZApVJh5cqVaN++PVauXIm2bdvi+PHjxuPi4uLw448/4s8//wQArF27Fr169aqWwJhrzpw5JlljTk6OReNJS8AL8y6gZ/8beHVMe1zNNf3g3bM1AFMGPYCpT9zerqucsXl1MBKerb0cStRQnTrkjpBWpnPRzVqqkX+Z5fr7Ud7OCxff7IDsebe3yjA3lHTzQ/a8DoBD7d9gHXSW3tWrEbLCaap3Ex4eDqVSid27dxvbNBoN9u3bh549ewIAYmJi4OzsbNInLy8PJ06cMPapK6utwYiIiIBMJsOZM2dM2lu2bAkAcHU1XTDk7++PYcOGYdiwYUhOTkZ0dDTeffddpKWlAQBiY2MRGhqK1NRUzJ49G1999VWtp+mYQy6X31emaA1T38xCnyeuY/7zbVBR5gjfAA0AoKzEERq1I0puOqPkpukHr17ngMJrLricxQVaYlG46REcrjE+VoZo0LJDBUpuOuLaZRcrRtb4fLWqKZZ+fQ4jp13Fj9/4oM2D5Xh89A2kzG5u7dBskuDqCM0dp6Ua5A7QezhB09wVMrUeftvzUPagD3TeznAs08Hnh2twKtCgpMvtNS+ORVo4FWnhnF+V/MlzK2BQOELr5wKDh/1cQNoaNzsrLS01ftEGqhZ2Hj16FH5+fmjRogXi4+ORlJSEyMhIREZGIikpCW5ubhg1ahSAqjWKcXFxmDFjBvz9/eHn54eZM2eiY8eOiI2NNSsWq/2k/f390a9fPyxfvhzTpk2rdR1GTVxcXNCqVSuUld0+/VImk+HZZ5/F6tWr0bx5czg4OGD48OFShN5gDR5dNW20aMMpk/bFs1sh/aum1gjJLrV+oALvbD5vfPz8m1cAALs2+WLxSy2sFVajdO6YG+ZPCMezr+ZhdLwKqhwXrJzXDD9s4QJPSTjI4KKqhPcH5+FQqoPB3QmV4e7IebUtNM1uJyY+e/Phv+32BfxCFp4FAKieDUPxwwH1HrY9ycjIwCOPPGJ8/PLLLwMAxo0bZ/wCXlFRgSlTpqCwsBDdunXDrl274OnpaTxm6dKlcHJywvDhw1FRUYG+ffsiNTUVjo7mXV9GJtS2crIenD9/Hr169YKvry8SExPRqVMnODg44NChQ5g5cyZGjx6NRx55BBs3bsTIkSPRunVrCIKAb775Bq+++irWrVuHZ555xjjepUuXEB4eDm9vbzz99NNYtWpVjc+bmpqK+Ph43Lx50+yYi4uL4e3tjUfdRsJJxm+j9cFQzqsy1jszF3ORZc6tjrF2CHbFUFGJ3KmJKCoqgpfXPU7FvQ+3/k7ERr4EJ0fLKuA6vRrpfyyVLFYpWbVW1apVKxw5cgRJSUmYM2cOcnNzIZfL0b59e8ycORNTpkyBSqWCm5sbZsyYgZycHMjlckRGRmL16tUmyQUAtGjRArGxsdi1a5fFizuJiIgsYhAAmYXf4Q22e7Mzq1YwbBErGPWPFQwrYAWjXrGCUb/qrYLRKl6cCsb5FFYwiIiI6C92frt2JhhERESSECHBgO0mGFa/DgYRERE1PqxgEBERSYFTJERERCQ6gwCLpzhs+CwSTpEQERGR6FjBICIikoJgqNosHcNGMcEgIiKSAtdgEBERkei4BoOIiIhIXKxgEBERSYFTJERERCQ6ASIkGKJEYhWcIiEiIiLRsYJBREQkBU6REBERkegMBgAWXsfCYLvXweAUCREREYmOFQwiIiIpcIqEiIiIRGfnCQanSIiIiEh0rGAQERFJwc4vFc4Eg4iISAKCYIBg4d1QLT3emphgEBERSUEQLK9AcA0GERER0W2sYBAREUlBEGENhg1XMJhgEBERScFgAGQWrqGw4TUYnCIhIiIi0bGCQUREJAVOkRAREZHYBIMBgoVTJLZ8miqnSIiIiEh0rGAQERFJgVMkREREJDqDAMjsN8HgFAkRERGJjhUMIiIiKQgCAEuvg2G7FQwmGERERBIQDAIEC6dIBCYYREREZEIwwPIKBk9TJSIiogbggw8+QHh4OBQKBWJiYvDTTz9ZJQ4mGERERBIQDIIomzk2bdqE+Ph4JCQk4MiRI/jHP/6BgQMH4tKlSxK9ytoxwSAiIpKCYBBnM8OSJUsQFxeHCRMmoF27dkhJSUFISAhWrFgh0YusHddgmOnWghudoLVyJPbDwPfaCmTWDsCuGCoqrR2CXbn1fku9gFIHrcXX2dKh6vOvuLjYpF0ul0Mul5u0aTQaZGZm4tVXXzVp79+/Pw4cOGBZIPeBCYaZSkpKAAA/Vmy2ciREErLdheu2aepWa0dgl0pKSuDt7S36uC4uLlAqldiv+laU8Tw8PBASEmLSNm/ePCQmJpq0Xb9+HXq9HoGBgSbtgYGBUKlUosRiDiYYZgoODkZOTg48PT0hk9nOt7zi4mKEhIQgJycHXl5e1g7HLvA9r198v+uXLb/fgiCgpKQEwcHBkoyvUCiQlZUFjUYjyniCIFT7e3Nn9eLv7uxb0/H1gQmGmRwcHNC8eXNrh3HfvLy8bO7DwNbxPa9ffL/rl62+31JULv5OoVBAoVBI+hx3CggIgKOjY7VqRX5+frWqRn3gIk8iIqJGwMXFBTExMdi9e7dJ++7du9GzZ896j4cVDCIiokbi5ZdfxjPPPIMuXbqgR48e+Oijj3Dp0iU8//zz9R4LEww7IZfLMW/evLvO25G4+J7XL77f9Yvvd8M0YsQI3LhxA/Pnz0deXh6ioqLw7bffIjQ0tN5jkQm2fKFzIiIiapC4BoOIiIhExwSDiIiIRMcEg4iIiETHBIOIiIhExwTDhh04cACOjo547LHHTNovXrwImUxWbRszZozJ/qNHj9bY38XFBREREXjrrbckv1a/rcvPz8fkyZPRokULyOVyKJVKDBgwAL/88gsAICwszPi+Ojo6Ijg4GHFxcSgsLLRy5LbLnPfc1dUVbdu2xTvvvMPf5RqoVCpMnz4dERERUCgUCAwMxMMPP4yVK1eivLwcAHDkyBEMHjwYTZs2hUKhQFhYGEaMGIHr168jMzMTMpkM+/fvr3H8AQMG4Mknn6zx8+jv2/jx4+vxVVN94WmqNmzt2rWYNm0aVq9ejUuXLqFFixYm+9PT09GhQwfjY1dX17uOd6u/Wq3G/v37MWHCBAQFBSEuLk6S+BuDp59+GlqtFmlpaWjZsiWuXr2KPXv2oKCgwNhn/vz5mDhxIvR6Pc6dO4dJkybhxRdfxCeffGLFyG2XOe95ZWUl0tPT8cILL8DLywuTJ0+2YuQNy4ULF9CrVy/4+PggKSkJHTt2hE6nw7lz57B27VoEBweje/fuiI2NxRNPPIGdO3fCx8cHWVlZ2LZtG8rLyxETE4MHHngA69atw8MPP2wyfk5ODtLT0/HVV1/ho48+MrZv2rQJb7zxBs6ePWtsu9dnE9kogWxSaWmp4OnpKZw5c0YYMWKE8Oabbxr3ZWVlCQCEI0eO1Hjsnftr6//oo48KU6ZMkegV2L7CwkIBgLB3795a+4SGhgpLly41aZs/f77Qvn17iaNrnO73Pe/cubMwdOhQiaOzLQMGDBCaN28ulJaW1rjfYDAIW7ZsEZycnAStVlvrOMuWLRM8PDyqjTN//nwhMDCw2rHr1q0TvL29LY6fGj5OkdioTZs2oU2bNmjTpg3GjBmDdevWiVoCzsjIwOHDh9GtWzfRxmxsPDw84OHhga1bt0KtVtfpmMuXL2P79u18X++Tue+5IAjYu3cvTp8+DWdn53qI0DbcuHEDu3btwtSpU+Hu7l5jH5lMBqVSCZ1Ohy1bttT6+TJ69GhotVp88cUXxjZBEJCamopx48bByYmFcrtl3fyG7lfPnj2FlJQUQRAEQavVCgEBAcLu3bsFQbhdkXB1dRXc3d2N2+HDh03231nBuNXf2dlZACBMmjTJKq/Nlnz55ZeCr6+voFAohJ49ewpz5swRjh07ZtwfGhoquLi4CO7u7oJCoRAACN26dRMKCwutF7SNM+c9v/W7rFAohJ9//tmKUTcsv/76qwBA+Oqrr0za/f39jZ8Xs2fPFgRBEObOnSs4OTkJfn5+wmOPPSYsWrRIUKlUJseNGDFC+Oc//2l8/P333wsAhDNnzlR7blYw7AcrGDbo7NmzOHjwIEaOHAkAcHJywogRI7B27VqTfps2bcLRo0eNW/v27e867q3+x44dw6ZNm/D111/j1Vdflex1NAZPP/00rly5gm3btmHAgAHYu3cvOnfujNTUVGOfWbNm4ejRo/j999+xZ88eAMCgQYOg1+utFLVtM+c937dvHx555BEkJCRY5WZPDd2dt/A+ePAgjh49alyLBQALFiyASqXCypUr0b59e6xcuRJt27bF8ePHjcfFxcXhxx9/xJ9//gmgan1Yr1690KZNm/p7MdTwWDvDIfPNmjVLACA4OjoaNwcHB0EulwsFBQWircFITk4WnJychIqKCmlfUCMTFxcntGjRQhCEmtcD/PLLLwIAY8WJLHe397ygoEDw8/Pj+/03169fF2QymZCcnFzj/t69ewvTp0+vcZ9arRbat28vjB071thmMBiE0NBQISEhQSgqKhLc3NyEtWvX1ng8Kxj2gxUMG6PT6fDxxx9j8eLFJtWJY8eOITQ0FJ9++qloz+Xo6AidTgeNRiPamPagffv2KCsrq3W/o6MjAKCioqK+Qmr07vae+/r6Ytq0aZg5cyZPVf2Lv78/+vXrh+XLl9/1d7UmLi4uaNWqlclxMpkMzz77LNLS0rBhwwY4ODhg+PDhYodNNoYJho3Zvn07CgsLERcXh6ioKJPtX//6F9asWXPfY9+4cQMqlQq5ubn47rvv8N577+GRRx6Bl5eXiK+g8bhx4wYeffRRrF+/Hr///juysrLwxRdfYNGiRRgyZIixX0lJCVQqFfLy8nDw4EHMmjULAQEBLNnfh7q+53eaOnUqzp49i82bN9djtA3bBx98AJ1Ohy5dumDTpk04ffo0zp49i/Xr1+PMmTNwdHTE9u3bMWbMGGzfvh3nzp3D2bNn8e677+Lbb7+t9n4/++yzuHLlCubOnYuRI0fWuniU7Ii1SyhknsGDBwuPP/54jfsyMzMFAMb/mjtFcmtzdHQUmjdvLkycOFHIz8+X6JXYvsrKSuHVV18VOnfuLHh7ewtubm5CmzZthNdee00oLy8XBKGqXP/397ZJkybC448/XuvPhu6uru/5ndNSgiAIEydOFDp06CDo9fp6jrrhunLlivCf//xHCA8PF5ydnQUPDw/hoYceEt555x2hrKxMOH/+vDBx4kShdevWgqurq+Dj4yN07dpVWLduXY3j9e/fXwAgHDhwoNbn5BSJ/eDt2omIiEh0nCIhIiIi0THBICIiItExwSAiIiLRMcEgIiIi0THBICIiItExwSAiIiLRMcEgIiIi0THBICIiItExwSCyQYmJiXjwwQeNj8ePH4+nnnqq3uO4ePEiZDIZjh49WmufsLAwpKSk1HnM1NRU+Pj4WBybTCbD1q1bLR6HiO4PEwwikYwfPx4ymQwymQzOzs5o2bIlZs6cafbNpO7He++9Z3K78rupS1JARGQpJ2sHQNSYPPbYY1i3bh20Wi1++uknTJgwAWVlZVixYkW1vlqtFs7OzqI8r7e3tyjjEBGJhRUMIhHJ5XIolUqEhIRg1KhRGD16tLFMf2taY+3atWjZsiXkcjkEQUBRUREmTZqEpk2bwsvLC48++iiOHTtmMu7bb7+NwMBAeHp6Ii4uDpWVlSb775wiMRgMWLhwISIiIiCXy9GiRQssWLAAABAeHg4AiI6OhkwmQ58+fYzHrVu3Du3atYNCoUDbtm3xwQcfmDzPwYMHER0dDYVCgS5duuDIkSNmv0dLlixBx44d4e7ujpCQEEyZMgWlpaXV+m3duhWtW7eGQqFAv379kJOTY7L/m2++QUxMDBQKBVq2bIk333wTOp3O7HiISBpMMIgk5OrqCq1Wa3z8559/4vPPP8fmzZuNUxSDBg2CSqXCt99+i8zMTHTu3Bl9+/ZFQUEBAODzzz/HvHnzsGDBAmRkZCAoKKjaH/47zZkzBwsXLsTrr7+OU6dOYcOGDQgMDARQlSQAQHp6OvLy8vDVV18BAFatWoWEhAQsWLAAp0+fRlJSEl5//XWkpaUBAMrKyjB48GC0adMGmZmZSExMxMyZM81+TxwcHLBs2TKcOHECaWlp+P777zF79myTPuXl5ViwYAHS0tLw888/o7i4GCNHjjTu37lzJ8aMGYMXX3wRp06dwocffojU1FRjEkVEDYCV7+ZK1GiMGzdOGDJkiPHxb7/9Jvj7+wvDhw8XBEEQ5s2bJzg7Owv5+fnGPnv27BG8vLyEyspKk7FatWolfPjhh4IgCEKPHj2E559/3mR/t27dhAceeKDG5y4uLhbkcrmwatWqGuPMysoSAFS7ZXxISIiwYcMGk7b//ve/Qo8ePQRBEIQPP/xQ8PPzE8rKyoz7V6xYUeNYf1fb7dNv+fzzzwV/f3/j43Xr1gkAhF9//dXYdvr0aQGA8NtvvwmCIAj/+Mc/hKSkJJNxPvnkEyEoKMj4GICwZcuWWp+XiKTFNRhEItq+fTs8PDyg0+mg1WoxZMgQvP/++8b9oaGhaNKkifFxZmYmSktL4e/vbzJORUUFzp8/DwA4ffo0nn/+eZP9PXr0wA8//FBjDKdPn4ZarUbfvn3rHPe1a9eQk5ODuLg4TJw40diu0+mM6ztOnz6NBx54AG5ubiZxmOuHH35AUlISTp06heLiYuh0OlRWVqKsrAzu7u4AACcnJ3Tp0sV4TNu2beHj44PTp0/joYceQmZmJg4dOmRSsdDr9aisrER5eblJjERkHUwwiET0yCOPYMWKFXB2dkZwcHC1RZy3/oDeYjAYEBQUhL1791Yb635P1XR1dTX7GIPBAKBqmqRbt24m+xwdHQEAgiDcVzx/l52djccffxzPP/88/vvf/8LPzw/79+9HXFycyVQSUHWa6Z1utRkMBrz55psYOnRotT4KhcLiOInIckwwiETk7u6OiIiIOvfv3LkzVCoVnJycEBYWVmOfdu3a4ddff8XYsWONbb/++mutY0ZGRsLV1RV79uzBhAkTqu13cXEBUPWN/5bAwEA0a9YMFy5cwOjRo2sct3379vjkk09QUVFhTGLuFkdNMjIyoNPpsHjxYjg4VC0B+/zzz6v10+l0yMjIwEMPPQQAOHv2LG7evIm2bdsCqHrfzp49a9Z7TUT1iwkGkRXFxsaiR48eeOqpp7Bw4UK0adMGV65cwbfffounnnoKXbp0wfTp0zFu3Dh06dIFDz/8MD799FOcPHkSLVu2rHFMhUKBV155BbNnz4aLiwt69eqFa9eu4eTJk4iLi0PTpk3h6uqKHTt2oHnz5lAoFPD29kZiYiJefPFFeHl5YeDAgVCr1cjIyEBhYSFefvlljBo1CgkJCYiLi8Nrr72Gixcv4t133zXr9bZq1Qo6nQ7vv/8+nnjiCfz8889YuXJltX7Ozs6YNm0ali1bBmdnZ/znP/9B9+7djQnHG2+8gcGDByMkJATDhg2Dg4MDfv/9dxw/fhxvvfWW+T8IIhIdzyIhsiKZTIZvv/0W//znP/Hcc8+hdevWGDlyJC5evGg862PEiBF444038MorryAmJgbZ2dl44YUX7jru66+/jhkzZuCNN95Au3btMGLECOTn5wOoWt+wbNkyfPjhhwgODsaQIUMAABMmTMDq1auRmpqKjh07onfv3khNTTWe1urh4YFvvvkGp06dQnR0NBISErBw4UKzXu+DDz6IJUuWYOHChYiKisKnn36K5OTkav3c3NzwyiuvYNSoUejRowdcXV2xceNG4/4BAwZg+/bt2L17N7p27Yru3btjyZIlCA0NNSseIpKOTBBjYpWIiIjob1jBICIiItExwSAiIiLRMcEgIiIi0THBICIiItExwSAiIiLRMcEgIiIi0THBICIiItExwSAiIiLRMcEgIiIi0THBICIiItExwSAiIiLR/X+KH6S1sD6Q7wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.970423</td>\n",
       "      <td>0.930337</td>\n",
       "      <td>0.928251</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.981009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.989717</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.980892</td>\n",
       "      <td>0.983728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.976995</td>\n",
       "      <td>0.930337</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.944128</td>\n",
       "      <td>0.989318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.932900</td>\n",
       "      <td>0.936957</td>\n",
       "      <td>0.934924</td>\n",
       "      <td>0.982614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947309</td>\n",
       "      <td>0.948941</td>\n",
       "      <td>0.945823</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.952582</td>\n",
       "      <td>0.952582</td>\n",
       "      <td>0.952582</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.952461</td>\n",
       "      <td>0.952485</td>\n",
       "      <td>0.952582</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC    Recall  Precision  F1-score  specificity\n",
       "0          AFIB  0.970423  0.930337   0.928251  0.929293     0.981009\n",
       "1            SB  0.985915  0.989717   0.972222  0.980892     0.983728\n",
       "2            SR  0.976995  0.930337   0.958333  0.944128     0.989318\n",
       "3          GSVT  0.971831  0.932900   0.936957  0.934924     0.982614\n",
       "4     macro avg       NaN  0.947309   0.948941  0.945823          NaN\n",
       "5     micro avg       NaN  0.952582   0.952582  0.952582          NaN\n",
       "6  weighted avg       NaN  0.952461   0.952485  0.952582          NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,y_pred)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"Recall\",\"Precision\",\"F1-score\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"../Result/KNN.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testdatasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
