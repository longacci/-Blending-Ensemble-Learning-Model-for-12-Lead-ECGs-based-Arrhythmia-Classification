{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>782.0</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>252.222222</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>87.777778</td>\n",
       "      <td>10339.061728</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>4315.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6555.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>697.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>594.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>1360.782222</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>420.090909</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1504.888889</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>569.437500</td>\n",
       "      <td>136.444444</td>\n",
       "      <td>43.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>615.733333</td>\n",
       "      <td>596.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.500000</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1746.285714</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>4722.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>654.428571</td>\n",
       "      <td>648.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>2686.204082</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3602.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>101.142857</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>-10.750000</td>\n",
       "      <td>7259.937500</td>\n",
       "      <td>88.222222</td>\n",
       "      <td>202.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1041.250000</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2            3       4           5      6         7         8  \\\n",
       "0     0.0  10.0   950.000000  1074.0  274.986868  782.0 -0.319753 -1.432466   \n",
       "1     0.0  17.0   574.500000   582.0  104.913059  378.0  0.158313 -0.696295   \n",
       "2     3.0  16.0   593.600000   594.0    4.687572   18.0  0.396421 -0.312612   \n",
       "3     3.0  23.0   420.090909   420.0    3.591772   12.0 -0.021014 -0.856142   \n",
       "4     1.0   9.0  1068.750000  1075.0   25.118469   76.0 -0.276816 -1.271399   \n",
       "...   ...   ...          ...     ...         ...    ...       ...       ...   \n",
       "8511  3.0  16.0   615.733333   596.0   51.114860  152.0  2.153820  2.645687   \n",
       "8512  1.0   9.0  1091.500000  1093.0    5.894913   18.0 -0.311206 -1.184514   \n",
       "8513  2.0  15.0   654.428571   648.0  107.653355  458.0  0.475616  0.784000   \n",
       "8514  1.0   9.0  1075.000000  1083.0   24.535688   66.0 -0.263431 -1.567800   \n",
       "8515  1.0   9.0  1041.250000  1040.0    8.242421   22.0  0.214800 -1.575835   \n",
       "\n",
       "               9        10  ...       204         205        206        207  \\\n",
       "0     325.821586  1.000000  ...  1.000000  172.000000  10.000000   9.000000   \n",
       "1     336.569414  1.000000  ...  0.882353  -15.000000  15.000000   4.000000   \n",
       "2      94.909877  1.000000  ...  1.000000   -4.000000  16.000000  15.000000   \n",
       "3     254.059787  0.826087  ...  0.739130   -9.000000   6.000000   4.000000   \n",
       "4     461.130814  1.000000  ...  1.000000    2.000000   9.000000   8.000000   \n",
       "...          ...       ...  ...       ...         ...        ...        ...   \n",
       "8511  365.256750  1.000000  ...  0.003757    0.022262   0.003757   0.003757   \n",
       "8512  358.414529  1.000000  ...  0.888889   -3.000000   9.000000   8.000000   \n",
       "8513  180.045117  1.000000  ...  1.000000   -4.000000  15.000000  14.000000   \n",
       "8514  251.455499  1.000000  ...  1.000000   14.000000   9.000000   8.000000   \n",
       "8515  505.203302  1.000000  ...  1.000000    0.000000   9.000000   8.000000   \n",
       "\n",
       "             208           209        210           211         212  \\\n",
       "0     252.222222  10656.395062  87.777778  10339.061728  135.800000   \n",
       "1     158.000000   3944.000000  73.000000   6555.000000   -1.066667   \n",
       "2     122.400000   2058.773333  12.533333   1360.782222   95.500000   \n",
       "3      40.666667   1120.888889   5.333333   1504.888889   12.000000   \n",
       "4     122.000000    671.000000  19.750000    569.437500  136.444444   \n",
       "...          ...           ...        ...           ...         ...   \n",
       "8511    0.044242      0.044242   0.043021      0.043021    0.037385   \n",
       "8512   81.428571   1294.530612 -40.000000   1746.285714  155.333333   \n",
       "8513   77.142857   2213.551020  -1.714286   2686.204082  104.000000   \n",
       "8514  101.142857   4933.551020 -10.750000   7259.937500   88.222222   \n",
       "8515  102.000000    350.000000 -20.000000    588.000000  150.000000   \n",
       "\n",
       "              213  \n",
       "0     4315.560000  \n",
       "1      697.528889  \n",
       "2       68.750000  \n",
       "3     1464.000000  \n",
       "4       43.358025  \n",
       "...           ...  \n",
       "8511     0.037385  \n",
       "8512  4722.666667  \n",
       "8513  3602.666667  \n",
       "8514   202.172840  \n",
       "8515     0.000000  \n",
       "\n",
       "[8516 rows x 213 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_frequency.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>710.769231</td>\n",
       "      <td>628.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3140.437500</td>\n",
       "      <td>127.600000</td>\n",
       "      <td>1041.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>968.666667</td>\n",
       "      <td>894.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>5249.000000</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>8081.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>8070.530612</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1078.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>757.500000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>7081.416667</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>264.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>413.909091</td>\n",
       "      <td>409.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>832.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>342.857143</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>205.142857</td>\n",
       "      <td>11207.836735</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2281.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>14282.775510</td>\n",
       "      <td>169.142857</td>\n",
       "      <td>46.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>361.489796</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>2186.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.285714</td>\n",
       "      <td>996.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>-45.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2       3           4      5         6          7  \\\n",
       "0     0.0  14.0   710.769231   628.0  153.204817  556.0  0.996355   0.207174   \n",
       "1     0.0  10.0   968.666667   894.0  266.399867  932.0  0.979352   0.388359   \n",
       "2     0.0  11.0   797.000000   780.0  251.329664  794.0  0.260470  -1.002325   \n",
       "3     2.0  13.0   757.500000   755.0    8.986100   26.0  0.048579  -1.449012   \n",
       "4     0.0  23.0   413.909091   409.0   82.344017  426.0  3.023659  10.404884   \n",
       "...   ...   ...          ...     ...         ...    ...       ...        ...   \n",
       "2125  1.0   9.0  1071.250000  1062.0   36.509417  118.0  1.263183   0.543003   \n",
       "2126  1.0   8.0  1196.000000  1202.0   33.839959  102.0 -0.454057  -1.036905   \n",
       "2127  3.0  16.0   595.600000   590.0   23.734082   82.0  0.371174  -0.657132   \n",
       "2128  1.0   8.0  1080.285714   996.0  180.470587  448.0  0.587475  -1.363827   \n",
       "2129  3.0  25.0   391.250000   390.0    2.569857    8.0  0.605786  -0.869886   \n",
       "\n",
       "               8         9  ...       203        204   205   206         207  \\\n",
       "0     459.037295  1.000000  ...  0.928571 -10.000000  10.0   9.0  146.000000   \n",
       "1     398.464564  1.000000  ...  0.600000  64.000000   7.0   7.0  140.500000   \n",
       "2     340.802438  1.000000  ...  1.000000  26.000000   9.0   7.0  154.285714   \n",
       "3     412.324324  1.000000  ...  1.000000  -4.000000  12.0  12.0  108.500000   \n",
       "4     168.041577  0.956522  ...  0.083333   0.022262  11.0  12.0    0.044242   \n",
       "...          ...       ...  ...       ...        ...   ...   ...         ...   \n",
       "2125  364.303573  0.888889  ...  0.777778   0.000000   9.0   8.0  342.857143   \n",
       "2126  181.876516  1.000000  ...  1.000000 -26.000000   8.0   7.0  137.666667   \n",
       "2127  137.696567  1.000000  ...  1.000000  -8.000000  16.0  14.0  102.714286   \n",
       "2128  561.988537  1.000000  ...  1.000000  18.000000   8.0   5.0   62.400000   \n",
       "2129  654.123072  0.400000  ...  0.240000   4.000000   0.0   0.0    0.044242   \n",
       "\n",
       "               208         209           210         211          212  \n",
       "0       729.000000   78.250000   3140.437500  127.600000  1041.440000  \n",
       "1     15314.750000  -27.000000   5249.000000  112.285714  8081.632653  \n",
       "2      1944.489796   18.571429   8070.530612  131.111111  1078.320988  \n",
       "3      6122.750000   46.500000   7081.416667  121.833333   264.305556  \n",
       "4         0.044242  -50.000000      0.000000   45.818182   832.330579  \n",
       "...            ...         ...           ...         ...          ...  \n",
       "2125   2843.265306  205.142857  11207.836735   96.000000  2281.142857  \n",
       "2126    228.555556   87.714286  14282.775510  169.142857    46.693878  \n",
       "2127   1270.061224    7.285714    361.489796   90.400000  2186.240000  \n",
       "2128     51.840000  -45.200000      0.960000  101.000000  5002.000000  \n",
       "2129      0.044242    0.043021      0.043021    0.037385     0.037385  \n",
       "\n",
       "[2130 rows x 213 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_frequency.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 0.9)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4258, 51)\n",
      "Vallidation: (4258, 51)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 5, max_features= 'sqrt', n_estimators= 1000)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 50)\n",
    "knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 100, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.1,max_depth= 5,min_child_weight= 1,n_estimators= 1000)\n",
    "# dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 5,max_features= 'sqrt',splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "svc_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "# dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    knn_clf.predict_proba(x_val),\n",
    "    svc_clf.predict_proba(x_val),\n",
    "    xgb_clf.predict_proba(x_val),\n",
    "    # dt_clf.predict_proba(x_val)\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    knn_clf.predict_proba(x_test),\n",
    "    svc_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    # dt_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4258, 20)\n",
      "X_test_meta:(2130, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.936, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.932, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.925, test=0.901) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.908, test=0.907) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.866, test=0.882) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.898, test=0.898) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, splitter=best;, score=(train=0.926, test=0.911) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, splitter=best;, score=(train=0.920, test=0.918) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, splitter=best;, score=(train=0.934, test=0.915) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, splitter=random;, score=(train=0.812, test=0.802) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, splitter=random;, score=(train=0.842, test=0.862) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, splitter=random;, score=(train=0.885, test=0.876) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.941, test=0.933) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.933, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.946, test=0.922) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.922, test=0.924) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.924, test=0.925) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.907, test=0.897) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=(train=0.934, test=0.925) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=(train=0.934, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=(train=0.938, test=0.909) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=(train=0.927, test=0.920) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=(train=0.927, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=(train=0.933, test=0.911) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.950, test=0.927) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.939, test=0.929) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.946, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.928, test=0.925) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.926, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.940, test=0.914) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=(train=0.947, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=(train=0.946, test=0.933) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=(train=0.949, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=(train=0.921, test=0.913) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=(train=0.929, test=0.933) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=(train=0.937, test=0.921) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.928, test=0.924) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.925, test=0.939) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.924, test=0.908) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.929, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.927, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.875, test=0.860) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=best;, score=(train=0.913, test=0.905) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=best;, score=(train=0.917, test=0.919) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=best;, score=(train=0.911, test=0.899) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=random;, score=(train=0.855, test=0.849) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=random;, score=(train=0.886, test=0.884) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=random;, score=(train=0.907, test=0.888) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.932, test=0.928) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.931, test=0.938) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.937, test=0.914) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.922, test=0.917) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.918, test=0.924) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.939, test=0.917) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=(train=0.938, test=0.929) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=(train=0.932, test=0.935) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=(train=0.936, test=0.921) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=(train=0.905, test=0.901) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=(train=0.913, test=0.918) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=(train=0.931, test=0.919) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.942, test=0.929) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.942, test=0.935) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.945, test=0.916) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.931, test=0.927) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.915, test=0.915) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.943, test=0.923) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=(train=0.947, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=(train=0.931, test=0.926) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=(train=0.946, test=0.923) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=(train=0.884, test=0.893) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=(train=0.926, test=0.927) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=(train=0.940, test=0.923) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.924, test=0.916) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.913, test=0.917) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.931, test=0.908) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.903, test=0.914) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.901, test=0.908) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.894, test=0.879) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=best;, score=(train=0.900, test=0.901) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=best;, score=(train=0.925, test=0.932) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=best;, score=(train=0.932, test=0.913) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=random;, score=(train=0.924, test=0.927) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=random;, score=(train=0.909, test=0.913) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=random;, score=(train=0.914, test=0.902) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.936, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.925, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.946, test=0.921) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.913, test=0.907) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.925, test=0.935) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.935, test=0.914) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=best;, score=(train=0.929, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=best;, score=(train=0.929, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=best;, score=(train=0.942, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=random;, score=(train=0.920, test=0.916) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=random;, score=(train=0.908, test=0.904) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=random;, score=(train=0.923, test=0.907) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.935, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.939, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.950, test=0.922) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.929, test=0.919) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.933, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.940, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=best;, score=(train=0.936, test=0.922) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=best;, score=(train=0.944, test=0.940) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=best;, score=(train=0.943, test=0.907) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=random;, score=(train=0.928, test=0.920) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=random;, score=(train=0.906, test=0.913) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=random;, score=(train=0.937, test=0.909) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:542: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.92343828 0.89548813 0.91427988 0.84665208\n",
      "        nan        nan 0.92836902 0.91521636 0.92367286 0.92249948\n",
      "        nan        nan 0.9271958  0.9271963  0.92461298 0.92250097\n",
      "        nan        nan 0.92390793 0.91239499 0.90746889 0.87365549\n",
      "        nan        nan 0.92672582 0.91921144 0.92837001 0.91240294\n",
      "        nan        nan 0.92672566 0.9215582  0.92390826 0.91451892\n",
      "        nan        nan 0.91357383 0.90041952 0.91498691 0.91380626\n",
      "        nan        nan 0.92789937 0.91874394 0.92414433 0.90911059\n",
      "        nan        nan 0.9271968  0.92649307 0.9229688  0.91404265]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.93095408 0.89091328 0.92672604 0.84616788\n",
      "        nan        nan 0.94023026 0.91756747 0.93506326 0.92883958\n",
      "        nan        nan 0.94492779 0.93165768 0.94751057 0.92883892\n",
      "        nan        nan 0.92543479 0.9102887  0.91357438 0.88257072\n",
      "        nan        nan 0.93353669 0.92625593 0.93518121 0.91627395\n",
      "        nan        nan 0.94304828 0.92966192 0.94128764 0.91697594\n",
      "        nan        nan 0.92249895 0.8993663  0.91885636 0.91557163\n",
      "        nan        nan 0.93553315 0.92414144 0.93318412 0.91686275\n",
      "        nan        nan 0.94128627 0.93400597 0.94105157 0.92379106]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = DecisionTreeClassifier()\n",
    "params = {\n",
    "    'criterion':['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [3,4,5],\n",
    "    'splitter':['best', 'random'],\n",
    "    'max_features':['auto', 'sqrt', 'log2']\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'log2',\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9283700086353215"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.956338</td>\n",
       "      <td>0.840449</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.889417</td>\n",
       "      <td>0.986944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.982629</td>\n",
       "      <td>0.984576</td>\n",
       "      <td>0.968394</td>\n",
       "      <td>0.976418</td>\n",
       "      <td>0.981509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.967359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.959624</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.893305</td>\n",
       "      <td>0.908511</td>\n",
       "      <td>0.969424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.918861</td>\n",
       "      <td>0.921966</td>\n",
       "      <td>0.917654</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928169</td>\n",
       "      <td>0.928169</td>\n",
       "      <td>0.928169</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.927777</td>\n",
       "      <td>0.928996</td>\n",
       "      <td>0.928169</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.956338  0.840449   0.944444  0.889417     0.986944\n",
       "1            SB  0.982629  0.984576   0.968394  0.976418     0.981509\n",
       "2            SR  0.957746  0.921348   0.881720  0.901099     0.967359\n",
       "3          GSVT  0.959624  0.924242   0.893305  0.908511     0.969424\n",
       "4     macro avg       NaN  0.918861   0.921966  0.917654          NaN\n",
       "5     micro avg       NaN  0.928169   0.928169  0.928169          NaN\n",
       "6  weighted avg       NaN  0.927777   0.928996  0.928169          NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"./Result/Blending_DT_PCA.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
