{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>782.0</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>252.222222</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>87.777778</td>\n",
       "      <td>10339.061728</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>4315.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6555.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>697.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>594.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>1360.782222</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>420.090909</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1504.888889</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>569.437500</td>\n",
       "      <td>136.444444</td>\n",
       "      <td>43.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>615.733333</td>\n",
       "      <td>596.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.500000</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1746.285714</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>4722.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>654.428571</td>\n",
       "      <td>648.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>2686.204082</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3602.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>101.142857</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>-10.750000</td>\n",
       "      <td>7259.937500</td>\n",
       "      <td>88.222222</td>\n",
       "      <td>202.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1041.250000</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2            3       4           5      6         7         8  \\\n",
       "0     0.0  10.0   950.000000  1074.0  274.986868  782.0 -0.319753 -1.432466   \n",
       "1     0.0  17.0   574.500000   582.0  104.913059  378.0  0.158313 -0.696295   \n",
       "2     3.0  16.0   593.600000   594.0    4.687572   18.0  0.396421 -0.312612   \n",
       "3     3.0  23.0   420.090909   420.0    3.591772   12.0 -0.021014 -0.856142   \n",
       "4     1.0   9.0  1068.750000  1075.0   25.118469   76.0 -0.276816 -1.271399   \n",
       "...   ...   ...          ...     ...         ...    ...       ...       ...   \n",
       "8511  3.0  16.0   615.733333   596.0   51.114860  152.0  2.153820  2.645687   \n",
       "8512  1.0   9.0  1091.500000  1093.0    5.894913   18.0 -0.311206 -1.184514   \n",
       "8513  2.0  15.0   654.428571   648.0  107.653355  458.0  0.475616  0.784000   \n",
       "8514  1.0   9.0  1075.000000  1083.0   24.535688   66.0 -0.263431 -1.567800   \n",
       "8515  1.0   9.0  1041.250000  1040.0    8.242421   22.0  0.214800 -1.575835   \n",
       "\n",
       "               9        10  ...       204         205        206        207  \\\n",
       "0     325.821586  1.000000  ...  1.000000  172.000000  10.000000   9.000000   \n",
       "1     336.569414  1.000000  ...  0.882353  -15.000000  15.000000   4.000000   \n",
       "2      94.909877  1.000000  ...  1.000000   -4.000000  16.000000  15.000000   \n",
       "3     254.059787  0.826087  ...  0.739130   -9.000000   6.000000   4.000000   \n",
       "4     461.130814  1.000000  ...  1.000000    2.000000   9.000000   8.000000   \n",
       "...          ...       ...  ...       ...         ...        ...        ...   \n",
       "8511  365.256750  1.000000  ...  0.003757    0.022262   0.003757   0.003757   \n",
       "8512  358.414529  1.000000  ...  0.888889   -3.000000   9.000000   8.000000   \n",
       "8513  180.045117  1.000000  ...  1.000000   -4.000000  15.000000  14.000000   \n",
       "8514  251.455499  1.000000  ...  1.000000   14.000000   9.000000   8.000000   \n",
       "8515  505.203302  1.000000  ...  1.000000    0.000000   9.000000   8.000000   \n",
       "\n",
       "             208           209        210           211         212  \\\n",
       "0     252.222222  10656.395062  87.777778  10339.061728  135.800000   \n",
       "1     158.000000   3944.000000  73.000000   6555.000000   -1.066667   \n",
       "2     122.400000   2058.773333  12.533333   1360.782222   95.500000   \n",
       "3      40.666667   1120.888889   5.333333   1504.888889   12.000000   \n",
       "4     122.000000    671.000000  19.750000    569.437500  136.444444   \n",
       "...          ...           ...        ...           ...         ...   \n",
       "8511    0.044242      0.044242   0.043021      0.043021    0.037385   \n",
       "8512   81.428571   1294.530612 -40.000000   1746.285714  155.333333   \n",
       "8513   77.142857   2213.551020  -1.714286   2686.204082  104.000000   \n",
       "8514  101.142857   4933.551020 -10.750000   7259.937500   88.222222   \n",
       "8515  102.000000    350.000000 -20.000000    588.000000  150.000000   \n",
       "\n",
       "              213  \n",
       "0     4315.560000  \n",
       "1      697.528889  \n",
       "2       68.750000  \n",
       "3     1464.000000  \n",
       "4       43.358025  \n",
       "...           ...  \n",
       "8511     0.037385  \n",
       "8512  4722.666667  \n",
       "8513  3602.666667  \n",
       "8514   202.172840  \n",
       "8515     0.000000  \n",
       "\n",
       "[8516 rows x 213 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_frequency.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>710.769231</td>\n",
       "      <td>628.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3140.437500</td>\n",
       "      <td>127.600000</td>\n",
       "      <td>1041.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>968.666667</td>\n",
       "      <td>894.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>5249.000000</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>8081.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>8070.530612</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1078.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>757.500000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>7081.416667</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>264.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>413.909091</td>\n",
       "      <td>409.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>832.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>342.857143</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>205.142857</td>\n",
       "      <td>11207.836735</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2281.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>14282.775510</td>\n",
       "      <td>169.142857</td>\n",
       "      <td>46.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>361.489796</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>2186.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.285714</td>\n",
       "      <td>996.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>-45.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2       3           4      5         6          7  \\\n",
       "0     0.0  14.0   710.769231   628.0  153.204817  556.0  0.996355   0.207174   \n",
       "1     0.0  10.0   968.666667   894.0  266.399867  932.0  0.979352   0.388359   \n",
       "2     0.0  11.0   797.000000   780.0  251.329664  794.0  0.260470  -1.002325   \n",
       "3     2.0  13.0   757.500000   755.0    8.986100   26.0  0.048579  -1.449012   \n",
       "4     0.0  23.0   413.909091   409.0   82.344017  426.0  3.023659  10.404884   \n",
       "...   ...   ...          ...     ...         ...    ...       ...        ...   \n",
       "2125  1.0   9.0  1071.250000  1062.0   36.509417  118.0  1.263183   0.543003   \n",
       "2126  1.0   8.0  1196.000000  1202.0   33.839959  102.0 -0.454057  -1.036905   \n",
       "2127  3.0  16.0   595.600000   590.0   23.734082   82.0  0.371174  -0.657132   \n",
       "2128  1.0   8.0  1080.285714   996.0  180.470587  448.0  0.587475  -1.363827   \n",
       "2129  3.0  25.0   391.250000   390.0    2.569857    8.0  0.605786  -0.869886   \n",
       "\n",
       "               8         9  ...       203        204   205   206         207  \\\n",
       "0     459.037295  1.000000  ...  0.928571 -10.000000  10.0   9.0  146.000000   \n",
       "1     398.464564  1.000000  ...  0.600000  64.000000   7.0   7.0  140.500000   \n",
       "2     340.802438  1.000000  ...  1.000000  26.000000   9.0   7.0  154.285714   \n",
       "3     412.324324  1.000000  ...  1.000000  -4.000000  12.0  12.0  108.500000   \n",
       "4     168.041577  0.956522  ...  0.083333   0.022262  11.0  12.0    0.044242   \n",
       "...          ...       ...  ...       ...        ...   ...   ...         ...   \n",
       "2125  364.303573  0.888889  ...  0.777778   0.000000   9.0   8.0  342.857143   \n",
       "2126  181.876516  1.000000  ...  1.000000 -26.000000   8.0   7.0  137.666667   \n",
       "2127  137.696567  1.000000  ...  1.000000  -8.000000  16.0  14.0  102.714286   \n",
       "2128  561.988537  1.000000  ...  1.000000  18.000000   8.0   5.0   62.400000   \n",
       "2129  654.123072  0.400000  ...  0.240000   4.000000   0.0   0.0    0.044242   \n",
       "\n",
       "               208         209           210         211          212  \n",
       "0       729.000000   78.250000   3140.437500  127.600000  1041.440000  \n",
       "1     15314.750000  -27.000000   5249.000000  112.285714  8081.632653  \n",
       "2      1944.489796   18.571429   8070.530612  131.111111  1078.320988  \n",
       "3      6122.750000   46.500000   7081.416667  121.833333   264.305556  \n",
       "4         0.044242  -50.000000      0.000000   45.818182   832.330579  \n",
       "...            ...         ...           ...         ...          ...  \n",
       "2125   2843.265306  205.142857  11207.836735   96.000000  2281.142857  \n",
       "2126    228.555556   87.714286  14282.775510  169.142857    46.693878  \n",
       "2127   1270.061224    7.285714    361.489796   90.400000  2186.240000  \n",
       "2128     51.840000  -45.200000      0.960000  101.000000  5002.000000  \n",
       "2129      0.044242    0.043021      0.043021    0.037385     0.037385  \n",
       "\n",
       "[2130 rows x 213 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_frequency.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 0.9)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4258, 51)\n",
      "Vallidation: (4258, 51)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 5, max_features= 'sqrt', n_estimators= 1000)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 50)\n",
    "# knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 100, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.1,max_depth= 5,min_child_weight= 1,n_estimators= 1000)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 5,max_features= 'sqrt',splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features='sqrt')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "# knn_clf.fit(x_train, y_train)\n",
    "svc_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    # knn_clf.predict_proba(x_val),\n",
    "    svc_clf.predict_proba(x_val),\n",
    "    xgb_clf.predict_proba(x_val),\n",
    "    dt_clf.predict_proba(x_val)\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    # knn_clf.predict_proba(x_test),\n",
    "    svc_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    dt_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4258, 20)\n",
      "X_test_meta:(2130, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=(train=0.951, test=0.926) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=(train=0.944, test=0.940) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=(train=0.949, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=(train=0.950, test=0.922) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=(train=0.945, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=(train=0.950, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=(train=0.948, test=0.921) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=(train=0.945, test=0.935) total time=   0.2s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=(train=0.951, test=0.924) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.923) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.936) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=(train=0.948, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=(train=0.950, test=0.926) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.933) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=(train=0.950, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=(train=0.952, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.923) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=(train=0.948, test=0.933) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=(train=0.953, test=0.923) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.929) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.942) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=(train=0.944, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=(train=0.939, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=(train=0.950, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=(train=0.945, test=0.929) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=(train=0.940, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=(train=0.949, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=(train=0.944, test=0.930) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=(train=0.943, test=0.945) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=(train=0.948, test=0.925) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.930) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.941) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.3s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.951, test=0.926) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.944, test=0.940) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.949, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.950, test=0.922) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.945, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.950, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.948, test=0.921) total time=   0.5s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.945, test=0.935) total time=   0.5s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.951, test=0.924) total time=   0.4s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.923) total time=   0.4s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.936) total time=   0.4s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.4s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.948, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.950, test=0.926) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.933) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.950, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.952, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.923) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.948, test=0.933) total time=   0.4s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.4s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.953, test=0.923) total time=   0.4s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.929) total time=   0.4s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.942) total time=   0.4s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.4s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.944, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.939, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.950, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.945, test=0.929) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.940, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.949, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.944, test=0.930) total time=   0.5s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.943, test=0.945) total time=   0.5s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.948, test=0.925) total time=   0.4s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.930) total time=   0.4s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.941) total time=   0.4s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.4s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.951, test=0.926) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.944, test=0.940) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.949, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.950, test=0.922) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.945, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.950, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.948, test=0.921) total time=   0.1s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.945, test=0.935) total time=   0.2s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.951, test=0.924) total time=   0.1s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.923) total time=   0.1s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.936) total time=   0.1s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.1s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.948, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.950, test=0.926) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.933) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.950, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.952, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.923) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.948, test=0.933) total time=   0.2s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.1s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.953, test=0.923) total time=   0.1s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.929) total time=   0.1s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.942) total time=   0.1s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.1s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.944, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.939, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.950, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.945, test=0.929) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.940, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.949, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.944, test=0.930) total time=   0.2s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.943, test=0.945) total time=   0.2s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.948, test=0.925) total time=   0.2s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.930) total time=   0.1s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.941) total time=   0.1s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.1s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=(train=0.951, test=0.926) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=(train=0.944, test=0.940) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=(train=0.949, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=(train=0.950, test=0.922) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=(train=0.945, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=(train=0.950, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=(train=0.948, test=0.921) total time=   0.3s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=(train=0.945, test=0.935) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=(train=0.951, test=0.924) total time=   0.3s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.923) total time=   0.3s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.936) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.4s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=(train=0.948, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=(train=0.950, test=0.926) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.933) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=(train=0.950, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=(train=0.952, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.923) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=(train=0.948, test=0.933) total time=   0.3s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=(train=0.943, test=0.946) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=(train=0.953, test=0.923) total time=   0.3s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.929) total time=   0.4s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.942) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.3s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=(train=0.944, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=(train=0.939, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=(train=0.950, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=(train=0.945, test=0.929) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=(train=0.940, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=(train=0.949, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.925) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=(train=0.944, test=0.930) total time=   0.3s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=(train=0.943, test=0.945) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=(train=0.948, test=0.925) total time=   0.3s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.930) total time=   0.3s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.941) total time=   0.3s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.922) total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = KNeighborsClassifier()\n",
    "params = {\n",
    "    'n_neighbors': [4,5,6],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1,2,3]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363550341277168"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAGwCAYAAADrIxwOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABYNElEQVR4nO3deVxU9foH8M+BgRn2VRhQRBRcQVM0XLq54ZaWXsvlp5UW2qJppGapmeRNSEulsrRygTLTyrTylimWlllXRc1dSxFBGVBEdmY9vz/I0REwxjnDMPB5v17nde+c8z2HZ6Zx5pnnuxxBFEURRERERBJysHUARERE1PAwwSAiIiLJMcEgIiIiyTHBICIiIskxwSAiIiLJMcEgIiIiyTHBICIiIsnJbB2AvTEYDLh8+TI8PDwgCIKtwyEiIjOJooji4mIEBwfDwcE6v7MrKiqg0WgkuZazszMUCoUk16pLTDDMdPnyZYSEhNg6DCIislBWVhaaNWsm+XUrKioQFuoOVZ5ekusplUpkZGTYXZLBBMNMHh4eAIDgN+bCwc7+Y9ur8Ph0W4fQ+Dg42jqCRsXBzcXWITQqOlGLn0s+N36eS02j0UCVp0dmegt4elhWISkqNiA0+gI0Gg0TjIbuRreIg0IBBxf7+o9tr2SCk61DaHwEJhh1yUFwtnUIjZK1u7ndPQS4e1j2Nwyw3654JhhERERWoBcN0Ft4ty+9aJAmGBtggkFERGQFBogwwLIMw9LzbYnTVImIiEhyrGAQERFZgQEGWNrBYfkVbIcJBhERkRXoRRF60bIuDkvPtyV2kRAREZHkWMEgIiKygsY+yJMJBhERkRUYIELfiBMMdpEQERGR5FjBICIisgJ2kRAREZHkOIuEiIiISGKsYBAREVmB4e/N0mvYKyYYREREVqCXYBaJpefbEhMMIiIiK9CLkOBuqtLEYgscg0FERESSYwWDiIjICjgGg4iIiCRngAA9BIuvYa/YRUJERESSYwWDiIjICgxi5WbpNewVEwwiIiIr0EvQRWLp+bbELhIiIiKSHCsYREREVtDYKxhMMIiIiKzAIAowiBbOIrHwfFtiFwkRERFJjgkGERGRFdzoIrF0M0eLFi0gCEKVberUqQAAURSRkJCA4OBguLi4oE+fPjhx4oTJNdRqNaZNmwZ/f3+4ubnhoYceQnZ2ttnPnwkGERGRFejhIMlmjgMHDiAnJ8e47dy5EwAwatQoAMCSJUuwbNkyrFixAgcOHIBSqcSAAQNQXFxsvEZ8fDy2bNmCjRs3Yu/evSgpKcGwYcOg1+vNioUJBhERkRWIf4/BsGQTzRyD0aRJEyiVSuO2bds2tGrVCr1794YoikhOTsa8efMwcuRIREZGIjU1FWVlZdiwYQMAoLCwEGvWrMHSpUsRGxuLzp07Y/369Th27BjS0tLMioUJBhERUT1XVFRksqnV6n88R6PRYP369XjyySchCAIyMjKgUqkwcOBAYxu5XI7evXtj3759AID09HRotVqTNsHBwYiMjDS2qS0mGERERFYg5RiMkJAQeHl5GbekpKR//Ptbt27F9evXMXHiRACASqUCAAQGBpq0CwwMNB5TqVRwdnaGj49PjW1qi9NUiYiIrEAvOkAvWvY7Xv/3UuFZWVnw9PQ07pfL5f947po1azBkyBAEBweb7BcE024XURSr7LtdbdrcjhUMIiKies7T09Nk+6cEIzMzE2lpaZg0aZJxn1KpBIAqlYi8vDxjVUOpVEKj0aCgoKDGNrXFBIOIiMgKDBBggIOF290ttLVu3ToEBARg6NChxn1hYWFQKpXGmSVA5TiNPXv2oGfPngCA6OhoODk5mbTJycnB8ePHjW1qi10kREREVmCrpcINBgPWrVuHCRMmQCa7+TUvCALi4+ORmJiIiIgIREREIDExEa6urhg3bhwAwMvLC3FxcZg5cyb8/Pzg6+uLWbNmISoqCrGxsWbFwQSDiIioAUlLS8PFixfx5JNPVjk2e/ZslJeXY8qUKSgoKEBMTAx27NgBDw8PY5vly5dDJpNh9OjRKC8vR//+/ZGSkgJHR0ez4hBEUbTju83XvaKiInh5eaFZ8kI4uChsHU6j0PqZ/bYOofFxMO+DhCzj4OZq6xAaFZ2owY/Fn6KwsNBk4KRUbnxPbPkjAm4elv1bKi3W49+d/rRarNbECgYREZEVVI7BsPBmZ3Z8N1UO8iQiIiLJsYLRQPhsv4wmW7NR0C8QV0aHAgDcD1+D1y95UGSWwbFUh8x5HaAOcTM5z+uXPHjsz4c8qxSOFQb8tawLDK58W1giMqYEo6ZcQURUGfyUOiQ82QK/bfeydVgNlp9Sg7i5l9CtbxGcFQZcOq/Aslmh+OsYux0sNfqpLPQamI9mLcuhqXDAycMeWPtWC1zKuPnafn9mb7Xnrl7SApvXNKurUOslw13cS6TqNex3FAO/SRoA+YUSeP+SB3VTF5P9gtqA8lYeKO7iC+X6C9WeK2gMKO3ghdIOXmiy1fy75VFVClcDzp9QYMdGH7y6JtPW4TRo7l46LNtyFkf3ueOVx8Jx/aoMQaFqlBZxDIkUou4txLefBuHsMXc4OoqY8EImFq05gaeHdoG6vPI1HtfrXpNzut5fgPhFf+LXH/xtEXK9Is1CW/abYNTrLpJ9+/bB0dERgwcPNtl/4cKFam9H++ijj5ocP3LkSLXtnZ2dER4ejtdffx32PsZVqNAjaO055D4aBv1tlYfi7v64NrQpytrW/Ov5en8lCgYHoyLM3dqhNhoHf/JE6pIg/Pq9t61DafBGT8nF1ctOWDqzBc4ccUNuthxHfvVETuY/r3JI/2z+pEikbQnExb/ckHHGHcvntEZgUzUiOpQY2xRcdTbZuvfPx9H/eUGVzUHwlq+BUbnZq3pdwVi7di2mTZuG1atX4+LFi2jevLnJ8bS0NHTo0MH42MXF5fZLVNterVZj7969mDRpEoKCghAXF2eV+OtCwMYLKI30Rlk7L/h+d9nW4RDVqe4DCpG+xxPzVp1Hx+4luKpywraPm+D7Dfz1bA2uHjoAQHFh9V8d3n4a3Nu7AEtfjqjLsKieqrcJRmlpKT7//HMcOHAAKpUKKSkpePXVV03a+Pn5GZc+rY1b24eGhmLt2rU4dOjQHRMMtVptcte6oqIiM5+J9XgcyIfiYhkuzunwz42JGqCg5moMe+wKvvooABvfVaLNPaV4dmEWtGoBaZv9bB1eAyPiqTkZOH7QE5l/ulXbIvbfeSgvdcSvO5jgAYBeFKA383br1V3DXtXb2sumTZvQpk0btGnTBo8++ijWrVsnaXfGwYMHcejQIcTExNyxXVJSkskd7EJCQiSLwRKya2o0+TwTOU+2guhUb/8zElmV4AD8ddwV6xY3xbkTrvju08rqxdDHr9o6tAZnyqvnEda6FItntKmxzcCHc/HTt02g1fAzCQD0fw/ytHSzV/U28jVr1hjHVAwePBglJSXYtWuXSZuePXvC3d3duB0+fPiO17zR3tnZGd26dcPo0aPx+OOP3/GcOXPmoLCw0LhlZWVZ9sQkIr9YBlmxDqGJxxExZT8ipuyH65/F8P4pFxFT9gMG+x5bQlQb1/KckPmnaV9/1p8KBDTV2CiihunZV86he798vDQhCldzqx/f0iG6ECEty7H9C/NuiEUNV73sIjlz5gz279+Pr776CgAgk8kwZswYrF271mQt9E2bNqFdu3bGx/9UXbjRXqvV4tixY5g+fTp8fHzwxhtv1HiOXC6v1W1x61pZW09cmB9psk/5cQY0SgWuDQwCHOy3rEZUWycPuiGkZYXJvqYt1cjLdrZRRA2NiGfnn0fPAfl46bEo5N5h4OagR3Jx9rg7Ms5wwPgNBtEBBgtnkRjseCJCvUww1qxZA51Oh6ZNmxr3iaIIJycnk1vIhoSEIDw8vNbXvbV9u3btcP78ecyfPx8JCQlQKOxrxLOocISmqek8f4OzA/RuMuN+h1IdnK6pIbuuBQA45VZ+EOs8naD3qvwAdizUQFakhdOVymPyS+UwKByg9ZXD4FYv3x71nsJVj+Cwm7+glSEatOxQjuLrjrhyiV98UvrqowAs33oGY59T4edt3mhzTxkeGH8VyS81/+eT6R9NXXAOfYZdwcIp7VFe6ggf/8r3dWmxIzTqm1OBXd10+Nfgq/hocZitQq2XpOji0HMdDOnodDp8/PHHWLp0KQYOHGhy7OGHH8ann36KYcOGSfK3HB0dodPpoNFo7C7BqA33Pwqg/DjD+Dh49TkAQP7QYOQ/WLkAjvfPefD7783ZJyFLTwEAVI+HoahnkzqMtuFo3akcb24+Z3z8zGuVr++OTT5Y+gK/+KR09g83LJzUCk/MuYTx8TlQZTljVUIz/LTF19ahNQjDxqkAAEvWHzPZv/TlCKRtudkV0nvoVUAAdm/jZwbdVO8SjG3btqGgoABxcXHw8jJdv+GRRx7BmjVr7jrByM/Ph0qlgk6nw7Fjx/D222+jb9++dncDmZpkz2xn8rioZ5N/TBLyH2xmTDZIGkd/c8eg4E62DqPR+N8uL/xvF1dKtYYhbe6rVbvvP1fi+89rP6OvsTDA8lkgBmlCsYl6l2CsWbMGsbGxVZILoLKCkZiYiGvXrt3VtW+M33B0dERQUBAeeOABLFq0yKJ4iYiIqiPFQllcaEtC3377bY3HunTpYpyqeqcpqy1atDA5fvtjIiIisq56l2AQERE1BNLci4QVDCIiIrqFAQIMsHQMhv0uOcAEg4iIyAoaewXDfiMnIiKieosVDCIiIiuQZqEt+60DMMEgIiKyAoMowGDpOhi8myoRERHRTaxgEBERWYFBgi4SLrRFREREJqS5m6r9Jhj2GzkRERHVW6xgEBERWYEeAvQWLpRl6fm2xASDiIjICthFQkRERCQxVjCIiIisQA/Luzj00oRiE0wwiIiIrKCxd5EwwSAiIrIC3uyMiIiISGKsYBAREVmBCAEGC8dgiJymSkRERLdiFwkRERGRxFjBICIisoLGfrt2JhhERERWoJfgbqqWnm9L9hs5ERER1VtMMIiIiKzgRheJpZu5Ll26hEcffRR+fn5wdXXFPffcg/T0dONxURSRkJCA4OBguLi4oE+fPjhx4oTJNdRqNaZNmwZ/f3+4ubnhoYceQnZ2tllxMMEgIiKyAgMcJNnMUVBQgF69esHJyQnff/89Tp48iaVLl8Lb29vYZsmSJVi2bBlWrFiBAwcOQKlUYsCAASguLja2iY+Px5YtW7Bx40bs3bsXJSUlGDZsGPT62i9ezjEYRERE9VxRUZHJY7lcDrlcXqXd4sWLERISgnXr1hn3tWjRwvj/RVFEcnIy5s2bh5EjRwIAUlNTERgYiA0bNuDpp59GYWEh1qxZg08++QSxsbEAgPXr1yMkJARpaWkYNGhQrWJmBYOIiMgK9KIgyQYAISEh8PLyMm5JSUnV/s1vvvkGXbt2xahRoxAQEIDOnTvjo48+Mh7PyMiASqXCwIEDjfvkcjl69+6Nffv2AQDS09Oh1WpN2gQHByMyMtLYpjZYwSAiIrICKaepZmVlwdPT07i/uuoFAJw/fx4rV67EjBkzMHfuXOzfvx/Tp0+HXC7H448/DpVKBQAIDAw0OS8wMBCZmZkAAJVKBWdnZ/j4+FRpc+P82mCCQUREZAWiBHdTFf8+39PT0yTBqInBYEDXrl2RmJgIAOjcuTNOnDiBlStX4vHHHze2EwTTxEcUxSr7qsbyz21uxS4SIiKiBiIoKAjt27c32deuXTtcvHgRAKBUKgGgSiUiLy/PWNVQKpXQaDQoKCiosU1tMMEgIiKyAj0ESTZz9OrVC2fOnDHZd/bsWYSGhgIAwsLCoFQqsXPnTuNxjUaDPXv2oGfPngCA6OhoODk5mbTJycnB8ePHjW1qg10kREREVmAQLV/q2yCa1/6FF15Az549kZiYiNGjR2P//v348MMP8eGHHwKo7BqJj49HYmIiIiIiEBERgcTERLi6umLcuHEAAC8vL8TFxWHmzJnw8/ODr68vZs2ahaioKOOsktpggkFERNRAdOvWDVu2bMGcOXOwcOFChIWFITk5GePHjze2mT17NsrLyzFlyhQUFBQgJiYGO3bsgIeHh7HN8uXLIZPJMHr0aJSXl6N///5ISUmBo6NjrWMRRFE0Mz9q3IqKiuDl5YVmyQvh4KKwdTiNQutn9ts6hMbHofYfImQ5BzdXW4fQqOhEDX4s/hSFhYW1GjhprhvfExN+Ggtnd2eLrqUp0SC170arxWpNrGAQERFZgQECDGaOoajuGvaKgzyJiIhIcqxgEBERWcGtK3Facg17xQSDiIjICgwSLLRl6fm2xATjLoXPOAKZ4GTrMBqFHy4fsXUIjc6gZtG2DqFRMdxyF0uyPoOotXUIjQITDCIiIiswQIJ7kdjxIE8mGERERFYgSjCLRGSCQURERLeS8m6q9sh+R48QERFRvcUKBhERkRVwFgkRERFJjl0kRERERBJjBYOIiMgKGvu9SJhgEBERWQG7SIiIiIgkxgoGERGRFTT2CgYTDCIiIito7AkGu0iIiIhIcqxgEBERWUFjr2AwwSAiIrICEZZPMxWlCcUmmGAQERFZQWOvYHAMBhEREUmOFQwiIiIraOwVDCYYREREVtDYEwx2kRAREZHkWMEgIiKygsZewWCCQUREZAWiKEC0MEGw9HxbYhcJERERSY4VDCIiIiswQLB4oS1Lz7clJhhERERW0NjHYLCLhIiIiCTHCgYREZEVNPZBnkwwiIiIrKCxd5EwwSAiIrKCxl7B4BgMIiIikhwrGERERFYgStBFYs8VDCYYREREViACEEXLr2Gv2EVCRETUQCQkJEAQBJNNqVQaj4uiiISEBAQHB8PFxQV9+vTBiRMnTK6hVqsxbdo0+Pv7w83NDQ899BCys7PNjoUJBhERkRXcWMnT0s1cHTp0QE5OjnE7duyY8diSJUuwbNkyrFixAgcOHIBSqcSAAQNQXFxsbBMfH48tW7Zg48aN2Lt3L0pKSjBs2DDo9Xqz4mAXCRERkRVIOYukqKjIZL9cLodcLq/2HJlMZlK1uHktEcnJyZg3bx5GjhwJAEhNTUVgYCA2bNiAp59+GoWFhVizZg0++eQTxMbGAgDWr1+PkJAQpKWlYdCgQbWOnRUMIiKiei4kJAReXl7GLSkpqca2f/75J4KDgxEWFoaxY8fi/PnzAICMjAyoVCoMHDjQ2FYul6N3797Yt28fACA9PR1ardakTXBwMCIjI41taosVDCIiIiswiAIEiRbaysrKgqenp3F/TdWLmJgYfPzxx2jdujVyc3Px+uuvo2fPnjhx4gRUKhUAIDAw0OScwMBAZGZmAgBUKhWcnZ3h4+NTpc2N82uLCQYREZEViKIEs0j+Pt/T09MkwajJkCFDjP8/KioKPXr0QKtWrZCamoru3bsDAATBNOkRRbHKvqpx/HOb27GLhIiIqIFyc3NDVFQU/vzzT+O4jNsrEXl5ecaqhlKphEajQUFBQY1taosJBhERkRXcGORp6WYJtVqNU6dOISgoCGFhYVAqldi5c6fxuEajwZ49e9CzZ08AQHR0NJycnEza5OTk4Pjx48Y2tcUuEiIiIiuwxb1IZs2ahQcffBDNmzdHXl4eXn/9dRQVFWHChAkQBAHx8fFITExEREQEIiIikJiYCFdXV4wbNw4A4OXlhbi4OMycORN+fn7w9fXFrFmzEBUVZZxVUltMMBoBP6UGcXMvoVvfIjgrDLh0XoFls0Lx1zFXW4dmVx6/tz1ys52r7H9wwhU8l3QJAHDxTznWvB6Mo7+7QzQAoW0qMG/VBQQ00xrbnzzoipTFQTh9yBUyJ6BVh3K8vv4c5C72vGaf7fD9bRvDJlzFqGevwDdAi8yzCqx6NRjH97vbOqx6RcpBnrWVnZ2N//u//8PVq1fRpEkTdO/eHb///jtCQ0MBALNnz0Z5eTmmTJmCgoICxMTEYMeOHfDw8DBeY/ny5ZDJZBg9ejTKy8vRv39/pKSkwNHR0axYBFG0dAhK/ZGXl4f58+fj+++/R25uLnx8fNCpUyckJCSgR48eaNGihXGkrIODAwIDAzFkyBC89dZbVUbM1qSoqAheXl7o4zASMsHJmk9HEu5eOry3/TSO7nPHtk+a4PpVGYJC1cjNliMns/pRyPXND9nptg4BAHA93xEG/c1/7BdOKzBnbDiWfPkXOvUsweULzpg+tDUGj81HnxHX4eapx8U/FWhzTxm8/XUAKpOLeeNbYexzuYgZWAQnJwPOn3RBzIAiOMvrzz/FQc2ibR1CrTSE9zcAwGDeAka21vuhArz4ThZWzG2KE/vdMPSxfAwedw2T+7TBlUtVk/D6RidqsRtfo7CwsFYDJ81143uizYaX4ehq2ftQX6bGmXFvWC1Wa2pQFYyHH34YWq0WqampaNmyJXJzc7Fr1y5cu3bN2GbhwoWYPHky9Ho9zp49i6eeegrTp0/HJ598YsPIrWf0lFxcveyEpTNbGPflZtvRB2894u1n+iWwaYUXglqo0bFHCQAg5Y0g3NuvCJPm5xjbBIVqTM75IKEpRsRdwZhpecZ9TVuatqHa4/vbNkY+dRU/fOaL7Rv8AACrFjRFdJ9iDHs8H+uSgmwcXf0h5SwSe9RgEozr169j79692L17N3r37g0ACA0Nxb333mvSzsPDwziStmnTpnj88cexcePGOo+3rnQfUIj0PZ6Yt+o8OnYvwVWVE7Z93ATfb/C3dWh2TasR8ONmH4x8Og+CABgMwP5dnhg1JQ9z/68l/jruAmVzDcY+l4eeQwoBANevynD6kBv6/bsA8Q9GICfTGSHhakx8KQeRMaU2fkb2ie/vuidzMiCiYxk2rQgw2Z++xwPtu/J9fKvKBMPSMRgSBWMDDWYWibu7O9zd3bF161ao1epanXPp0iVs27YNMTExNbZRq9UoKioy2exJUHM1hj12BZcz5Jg7Phz//cQfzy7MQuzD+bYOza7t2+6FkiJHDBxdWR27flWG8lJHbFoRgK59i5H02Xn0GlyIhZNa4OhvbgCAnMzK0vEny5QYMj4fiz49j/CoMrw8phUuna//ZeX6iO/vuufpq4ejrPI9f6vrV2TwCdDZKCqqjxpMgiGTyZCSkoLU1FR4e3ujV69emDt3Lo4ePWrS7qWXXoK7uztcXFzQrFkzCIKAZcuW1XjdpKQkk+VZQ0JCrP1UJCU4AH8dd8W6xU1x7oQrvvu08tfd0Mev2jo0u/bDZ77o1rcIfsrKD1TRULm/x6AijHzqClpFlmPMtDzExBbhvx9X/po2/N3mgUfzMWjsNYRHleOZ1y6jWSs1ftjoZ4unYff4/rad239ZCwLs+97iVlAfpqnaUoNJMIDKMRiXL1/GN998g0GDBmH37t3o0qULUlJSjG1efPFFHDlyBEePHsWuXbsAAEOHDq3xLnFz5sxBYWGhccvKyqqLpyKZa3lOyPxTYbIv608FApqy3/9u5WY74fAvHhg87uav5MpfdSJCW1eYtA2JqEDepcrBwH6BlclIlTbhN9uQefj+rntF1xyh1wE+TUyrFV7+OhRcaTC97pIQJdrsVYNKMABAoVBgwIABePXVV7Fv3z5MnDgRCxYsMB739/dHeHg4IiIi0K9fPyQnJ2Pfvn346aefqr2eXC43LtFa26Va65OTB90Q0tL0C61pSzXyqpluSbWzY6MfvP11iIm92V3m5CyidacyZJ8zHWB46bzcOEU1MEQDP6Xmjm3IPHx/1z2d1gF/HnVFl/uLTfZ3ub8YJw+62Sgqqo8aXIJxu/bt26O0tOaBRzfm9ZaXl9dVSHXqq48C0LZLKcY+p0Jwiwr0HXEND4y/im9Sm9g6NLtkMAA7NvkidtQ1ON72Y23UlDzs+cYb333qi0sZzvh6rT9+3+mFBydUlusFAXjk2SvYuqYJftnmhUsZzkhdokTWOQUG/x/HDNwNvr9t46sP/TF43DUMHJuPkPAKPJ1wCQFNtfjvx+zqu1Vj7yJpMPWs/Px8jBo1Ck8++SQ6duwIDw8PHDx4EEuWLMHw4cON7YqLi6FSqSCKIrKysjB79mz4+/ubvQSqvTj7hxsWTmqFJ+Zcwvj4HKiynLEqoRl+2uJr69Ds0uGfPZB3yRmDxl6rcqzXkEJMfyMbG1cEYuX8ZmjWUo35H2WYzBAZOfkKtBUCVi1oiuLrjmjZvgJJn51DcAuW9O8G39+2secbH3j46DH+hVz4BuiQeUaBVx4NQ54drIFRp6To47DjPpIGs9CWWq1GQkICduzYgXPnzkGr1SIkJASjRo3C3Llz4eLiYrLQFgA0adIE3bp1w6JFi3DPPffU6u/Y20JbDUF9WWirMbGXhbYaDDtbaMve1dVCWy1T5sHBVfHPJ9yBoawC5ycu4kJbtiSXy5GUlISkpKQa21y4cKHuAiIiImrEGkyCQUREVJ9wJU8iIiKSnC3uplqfNPhZJERERFT3WMEgIiKyBlGo3Cy9hp1igkFERGQFjX0MBrtIiIiISHKsYBAREVlDI19oiwkGERGRFTT2WSS1SjDeeeedWl9w+vTpdx0MERERNQy1SjCWL19eq4sJgsAEg4iI6AY77uKwVK0SjIyMDGvHQURE1KA09i6Su55FotFocObMGeh0OinjISIiahhEiTY7ZXaCUVZWhri4OLi6uqJDhw64ePEigMqxF2+88YbkARIREZH9MTvBmDNnDv744w/s3r0bCsXN29DGxsZi06ZNkgZHRERkvwSJNvtk9jTVrVu3YtOmTejevTsE4eYTb9++Pc6dOydpcERERHarka+DYXYF48qVKwgICKiyv7S01CThICIiosbL7ASjW7du+O9//2t8fCOp+Oijj9CjRw/pIiMiIrJnjXyQp9ldJElJSRg8eDBOnjwJnU6Ht99+GydOnMBvv/2GPXv2WCNGIiIi+9PI76ZqdgWjZ8+e+PXXX1FWVoZWrVphx44dCAwMxG+//Ybo6GhrxEhERER25q7uRRIVFYXU1FSpYyEiImowGvvt2u8qwdDr9diyZQtOnToFQRDQrl07DB8+HDIZ751GREQEoNHPIjE7Izh+/DiGDx8OlUqFNm3aAADOnj2LJk2a4JtvvkFUVJTkQRIREZF9MXsMxqRJk9ChQwdkZ2fj0KFDOHToELKystCxY0c89dRT1oiRiIjI/twY5GnpZqfMrmD88ccfOHjwIHx8fIz7fHx8sGjRInTr1k3S4IiIiOyVIFZull7DXpldwWjTpg1yc3Or7M/Ly0N4eLgkQREREdm9Rr4ORq0SjKKiIuOWmJiI6dOn48svv0R2djays7Px5ZdfIj4+HosXL7Z2vERERGQHatVF4u3tbbIMuCiKGD16tHGf+Pc8mgcffBB6vd4KYRIREdmZRr7QVq0SjJ9++snacRARETUsNp6mmpSUhLlz5+L5559HcnJy5eVEEa+99ho+/PBDFBQUICYmBu+99x46dOhgPE+tVmPWrFn47LPPUF5ejv79++P9999Hs2bNzPr7tUowevfubdZFiYiIyHYOHDiADz/8EB07djTZv2TJEixbtgwpKSlo3bo1Xn/9dQwYMABnzpyBh4cHACA+Ph7ffvstNm7cCD8/P8ycORPDhg1Deno6HB0dax2D2YM8bygrK8Pp06dx9OhRk42IiIhgs0GeJSUlGD9+PD766COTGZ+iKCI5ORnz5s3DyJEjERkZidTUVJSVlWHDhg0AgMLCQqxZswZLly5FbGwsOnfujPXr1+PYsWNIS0szK467ul37sGHD4OHhgQ4dOqBz584mGxEREUHSBOPWyRZFRUVQq9U1/tmpU6di6NChiI2NNdmfkZEBlUqFgQMHGvfJ5XL07t0b+/btAwCkp6dDq9WatAkODkZkZKSxTW2ZnWDEx8ejoKAAv//+O1xcXLB9+3akpqYiIiIC33zzjbmXIyIion8QEhICLy8v45aUlFRtu40bN+LQoUPVHlepVACAwMBAk/2BgYHGYyqVCs7OziaVj9vb1JbZC239+OOP+Prrr9GtWzc4ODggNDQUAwYMgKenJ5KSkjB06FBzL0lERNTwSDiLJCsrC56ensbdcrm8StOsrCw8//zz2LFjBxQKRY2XvHVWKFDZdXL7viph1KLN7cyuYJSWliIgIAAA4OvriytXrgCovMPqoUOHzL0cERFRg3RjJU9LNwDw9PQ02apLMNLT05GXl4fo6GjIZDLIZDLs2bMH77zzDmQymbFycXslIi8vz3hMqVRCo9GgoKCgxja1dVcreZ45cwYAcM899+CDDz7ApUuXsGrVKgQFBZl7OSIiIpJA//79cezYMRw5csS4de3aFePHj8eRI0fQsmVLKJVK7Ny503iORqPBnj170LNnTwBAdHQ0nJycTNrk5OTg+PHjxja1ZXYXSXx8PHJycgAACxYswKBBg/Dpp5/C2dkZKSkp5l6OiIioYarjdTA8PDwQGRlpss/NzQ1+fn7G/fHx8UhMTERERAQiIiKQmJgIV1dXjBs3DgDg5eWFuLg4zJw5E35+fvD19cWsWbMQFRVVZdDoPzE7wRg/frzx/3fu3BkXLlzA6dOn0bx5c/j7+5t7OSIiIqojs2fPRnl5OaZMmWJcaGvHjh3GNTAAYPny5ZDJZBg9erRxoa2UlBSz1sAAAEG8sc431UpRURG8vLzQx2EkZIKTrcNpFH7ITrd1CI3OoGbRtg6hcTHwFgt1SSdqsRtfo7Cw0GTgpFRufE+ELn4dDncYbFkbhooKZL70itVitaZaVTBmzJhR6wsuW7bsroMhIiKihqFWCcbhw4drdTFzp7DYNYMeEO56IVQyw5CIXrYOodE5+16Hf25EkmkzjTPw6pIgioCuDv4Qb3b2z3izMyIiIjPZ+GZntsaf4ERERCQ5s2eREBERUS008goGEwwiIiIruHUlTkuuYa/YRUJERESSYwWDiIjIGhp5F8ldVTA++eQT9OrVC8HBwcjMzAQAJCcn4+uvv5Y0OCIiIrslSrTZKbMTjJUrV2LGjBl44IEHcP36dej1lSvQeXt7Izk5Wer4iIiIyA6ZnWC8++67+OijjzBv3jyTdcm7du2KY8eOSRocERGRvZLydu32yOwxGBkZGejcuXOV/XK5HKWlpZIERUREZPca+UqeZlcwwsLCcOTIkSr7v//+e7Rv316KmIiIiOxfIx+DYXYF48UXX8TUqVNRUVEBURSxf/9+fPbZZ0hKSsLq1autESMRERHZGbMTjCeeeAI6nQ6zZ89GWVkZxo0bh6ZNm+Ltt9/G2LFjrREjERGR3WnsC23d1ToYkydPxuTJk3H16lUYDAYEBARIHRcREZF9a+TrYFi00Ja/v79UcRAREVEDYnaCERYWBkGoeVTr+fPnLQqIiIioQZBimmljqmDEx8ebPNZqtTh8+DC2b9+OF198Uaq4iIiI7Bu7SMzz/PPPV7v/vffew8GDBy0OiIiIiOyfZHdTHTJkCDZv3izV5YiIiOwb18GQxpdffglfX1+pLkdERGTXOE3VTJ07dzYZ5CmKIlQqFa5cuYL3339f0uCIiIjIPpmdYIwYMcLksYODA5o0aYI+ffqgbdu2UsVFREREdsysBEOn06FFixYYNGgQlEqltWIiIiKyf418FolZgzxlMhmeffZZqNVqa8VDRETUIDT227WbPYskJiYGhw8ftkYsRERE1ECYPQZjypQpmDlzJrKzsxEdHQ03NzeT4x07dpQsOCIiIrtmxxUIS9U6wXjyySeRnJyMMWPGAACmT59uPCYIAkRRhCAI0Ov10kdJRERkbxr5GIxaJxipqal44403kJGRYc14iIiIqAGodYIhipVpVGhoqNWCISIiaii40JYZ7nQXVSIiIroFu0hqr3Xr1v+YZFy7ds2igIiIiMj+mZVgvPbaa/Dy8rJWLERERA0Gu0jMMHbsWAQEBFgrFiIiooajkXeR1HqhLY6/ICIiotoyexYJERER1QIrGLVjMBjYPUJERFRLtrgXycqVK9GxY0d4enrC09MTPXr0wPfff288LooiEhISEBwcDBcXF/Tp0wcnTpwwuYZarca0adPg7+8PNzc3PPTQQ8jOzjb7+Zt9LxIiIiKqBVGizQzNmjXDG2+8gYMHD+LgwYPo168fhg8fbkwilixZgmXLlmHFihU4cOAAlEolBgwYgOLiYuM14uPjsWXLFmzcuBF79+5FSUkJhg0bZvZK3UwwiIiIGogHH3wQDzzwAFq3bo3WrVtj0aJFcHd3x++//w5RFJGcnIx58+Zh5MiRiIyMRGpqKsrKyrBhwwYAQGFhIdasWYOlS5ciNjYWnTt3xvr163Hs2DGkpaWZFQsTDCIiImuQsIJRVFRksqnV6n/883q9Hhs3bkRpaSl69OiBjIwMqFQqDBw40NhGLpejd+/e2LdvHwAgPT0dWq3WpE1wcDAiIyONbWqLCQYREZEVSDkGIyQkBF5eXsYtKSmpxr977NgxuLu7Qy6X45lnnsGWLVvQvn17qFQqAEBgYKBJ+8DAQOMxlUoFZ2dn+Pj41Nimtsy+XTvZlzHP5aLXA4UICVdDU+GAkwddsWZRELLPKWwdWoMw+uls9BqYj2Yty6FRO+DkIU+sfTMUlzJcqm0/7T/n8MDYXHywqAW2pgTXcbT2zWf7ZTT5OhsFfQNxZfTf90QSRfj99xK89l6BQ5kOFS3ckTc2FJpgV+N5Tlcq0GRzFhTniiHoDChr7428MaHQezrZ6JnYl8h7i/HIM7mIiCqDX6AWr01qhd92eN/SQsSjL+RgyLircPfS4cxhN7w3vzkyz1b/b4DuTlZWFjw9PY2P5XJ5jW3btGmDI0eO4Pr169i8eTMmTJiAPXv2GI/fvuzEjbuh30lt2tyOFYwGrmOPUnyb4o/4YRGYM7YlHB1FJH52HnIX8wbrUPWi7i3Ct58G4YVRHTF3Ygc4ykQsWnei2te3R2w+2nQqxlWVsw0itW/yCyXw3psHdVPTLy2fHTnw3qVC3phQXHypA3SeTmj2zhkIFZWvv6DWo+k7ZyAKQHZ8W2TNag9Bb0DT988CBjue/1eHFK4GZJx0wfvzQ6o9PurZXPx7Ui7enx+C6cPa4doVJyR++idc3PgZI2UXyY1ZITe2OyUYzs7OCA8PR9euXZGUlIROnTrh7bffhlKpBIAqlYi8vDxjVUOpVEKj0aCgoKDGNrXVoBKMvLw8PP3002jevDnkcjmUSiUGDRqE3377DQDQokULCIIAQRDg4uKCtm3b4s0332zQa3zMG98SOz/3ReZZBc6fdMHSF5ojsJkWER3LbR1agzA/rj3SvgrAxb9ckXHaDctfDkdgUw0iIktM2vkFqjFlQQaWzGgNvY6L1plDqNAjaN055I4Pg971lqKrKMLnx1xcGxyMks6+0DR1Re6ElhA0BngeyAcAuJwrgVO+GrmPt4SmqSs0TV2heqwlFJmlcD1TZKNnZF8O7vZC6ltN8et2n2qOivh3XC42rgjCr9t9kHnWBUtntIBcYUDfEbwvlS2mqVZHFEWo1WqEhYVBqVRi586dxmMajQZ79uxBz549AQDR0dFwcnIyaZOTk4Pjx48b29RWg+oiefjhh6HVapGamoqWLVsiNzcXu3btMrkB28KFCzF58mRUVFQgLS0Nzz77LDw9PfH000/bMPK64+ZZ+aui+LqjjSNpmFzddQCA4us3/2kJgohZb/6JL1cH4+JfrjWdSjUI2HgBpZHeKGvnBd/vLxv3O11VQ1akRVn7m/dHEp0cUB7hAcW5YhT+KwCCzgAIgCgTTNqIAuByrhhl7XhvJUsom2vgG6DDoZ9vlu61Ggcc+5872kWX4LtPm9gwusZp7ty5GDJkCEJCQlBcXIyNGzdi9+7d2L59OwRBQHx8PBITExEREYGIiAgkJibC1dUV48aNAwB4eXkhLi4OM2fOhJ+fH3x9fTFr1ixERUUhNjbWrFgaTIJx/fp17N27F7t370bv3r0BAKGhobj33ntN2nl4eBjLRJMmTcLKlSuxY8eOGhMMtVptMlq3qMief/WIeCrhMo7/zw2ZZ9g/Kj0RT829gOMHPJD5p5tx76inLsGgF/B1apANY7NPHgfyocgqw8WXO1Q55likBQDoPEzHUug8neCUX/lvtiLMHQZnR/hvycLVEc0AEWiyJQuCCDgWaq3/BBo4nyaVr2HBVdOvkoKrTghsqrFFSPWLDVbyzM3NxWOPPYacnBx4eXmhY8eO2L59OwYMGAAAmD17NsrLyzFlyhQUFBQgJiYGO3bsgIeHh/Eay5cvh0wmw+jRo1FeXo7+/fsjJSUFjo7m/TBtMAmGu7s73N3dsXXrVnTv3v2O/VNAZcloz549OHXqFCIiImpsl5SUhNdee03qcG1iauIlhLUrx8wR4bYOpUGasiADYW3KMOv/Io37wjuUYPiEHEwb0QkAu0bMIbumRpMvMpE9vS1Epzv05t72sgoigL8Ho+k9nJAzORwBn12A9+5cQACKu/qhIsQVcOB/D8mIpq+lIAANuOe59myQYKxZs+aOxwVBQEJCAhISEmpso1Ao8O677+Ldd98174/fpsEkGDKZDCkpKZg8eTJWrVqFLl26oHfv3hg7diw6duxobPfSSy/hlVdegUajgVarhUKhwPTp02u87pw5czBjxgzj46KiIoSEVD/YqT6b8no2egwswsx/t8LVHA4ylNqz88+je/9reHFcJK6qbia3kd2K4O2nxcd7Dhr3OcqASS9fwIgJOZjYN9oW4doF+cUyyIp1CE06btwnGACXv4rhvScXFxIq/13LirTQe918TzsWa6HzuPnRVtbeCxf+0wkOJVrAQYDBVYaWLx2G1u/OP0LonxVcqawe+TTR4lrezUqSt5+2SlWDGp8G9Q54+OGHMXToUPzyyy/47bffsH37dixZsgSrV6/GxIkTAQAvvvgiJk6ciCtXrmDevHno16/fHQeuyOXyf6yG1G8ipi66hJ6DC/HiI+HIzbLn51IfiXj21Qz0HHANLz3aAbnZptN/d21tgsO/mvbzv772FH78ugl2bOa9fe6krK0nLrwSabJP+UkGNIEKXBsYBK2/HDpPJ7ieKoI65O8uKZ0BLn8W4+q/q/4IMLhXfgG6nC6CY7EWJR29rf0UGjzVRWdcy5Oh87+KcO5E5fgimZMBUTElWPtGUxtHZ3sCLK9b2nOdrUElGEBlaWfAgAEYMGAAXn31VUyaNAkLFiwwJhj+/v4IDw9HeHg4Nm/ejPDwcHTv3t3swSv24rnES+j77wIkPBGG8hIHY59pabEjNBUNahKRTUxNOI8+D17FwmfborzUET7+lf3OpcWO0KgdUXzdCcXXTccI6HUCCq461bhWBlUSFY7QNDUdFGtwdoDeTWbcX9AvEL7bL0MbIIemiQK+2y9DdHZAUTc/4zme+65Ao3SB3kMGxfkSBHyRiYJ+SmiVfP1rQ+GqR3CLm+PQlCFqtGxfhuLrMly57IwtawIxdqoKlzPkuJShwNjncqCucMBPW31tGHU9YYMukvqkwSUYt2vfvj22bt1a7TEfHx9MmzYNs2bNwuHDh81eRMQePDixcrreW1+dM9n/VnwIdn7ODwBLDRufCwBY8qnp3QiXvhSOtK9YobC2goFBcNAaEPBZZuVCW2HuyJ7WBqLi5mA059wK+H+dDcdSHbR+zsgfHIzr/ZU2jNq+tO5YhiWfnzU+fnpB5V01d37hh6UzW+CLlYGQKwx4btFFuHvqcfqIG+aOj0B5KWeqSTHNVIppqrbSYBKM/Px8jBo1Ck8++SQ6duwIDw8PHDx4EEuWLMHw4cNrPG/q1KlYvHgxNm/ejEceeaQOI64bg4I72TqEBm1IhHnzwgFw3IUFsme0M90hCMgf1gz5w5rVeM7Vf4dU22VCtXP0dw8Mbn6n96yA9cuDsX45V6YlUw0mwXB3d0dMTAyWL1+Oc+fOQavVIiQkBJMnT8bcuXNrPK9JkyZ47LHHkJCQgJEjR8LBgd0GREQkAXaRNAxyuRxJSUl3vAHMhQsXqt3/4YcfWikqIiJq1Ow4QbAUf64TERGR5BpMBYOIiKg+4SBPIiIikl4jH4PBLhIiIiKSHCsYREREVsAuEiIiIpIeu0iIiIiIpMUKBhERkRWwi4SIiIik18i7SJhgEBERWUMjTzA4BoOIiIgkxwoGERGRFXAMBhEREUmPXSRERERE0mIFg4iIyAoEUYQgWlaCsPR8W2KCQUREZA3sIiEiIiKSFisYREREVsBZJERERCQ9dpEQERERSYsVDCIiIitgFwkRERFJr5F3kTDBICIisoLGXsHgGAwiIiKSHCsYRERE1sAuEiIiIrIGe+7isBS7SIiIiEhyrGAQERFZgyhWbpZew04xwSAiIrICziIhIiIikhgrGERERNbQyGeRsIJBRERkBYJBms0cSUlJ6NatGzw8PBAQEIARI0bgzJkzJm1EUURCQgKCg4Ph4uKCPn364MSJEyZt1Go1pk2bBn9/f7i5ueGhhx5Cdna2WbEwwSAiImog9uzZg6lTp+L333/Hzp07odPpMHDgQJSWlhrbLFmyBMuWLcOKFStw4MABKJVKDBgwAMXFxcY28fHx2LJlCzZu3Ii9e/eipKQEw4YNg16vr3Us7CIhIiKyBgm7SIqKikx2y+VyyOXyKs23b99u8njdunUICAhAeno67r//foiiiOTkZMybNw8jR44EAKSmpiIwMBAbNmzA008/jcLCQqxZswaffPIJYmNjAQDr169HSEgI0tLSMGjQoFqFzgoGERGRFdyYRWLpBgAhISHw8vIybklJSbWKobCwEADg6+sLAMjIyIBKpcLAgQONbeRyOXr37o19+/YBANLT06HVak3aBAcHIzIy0timNljBICIisgYJ18HIysqCp6encXd11Yuqp4qYMWMG7rvvPkRGRgIAVCoVACAwMNCkbWBgIDIzM41tnJ2d4ePjU6XNjfNrgwkGERFRPefp6WmSYNTGc889h6NHj2Lv3r1VjgmCYPJYFMUq+25Xmza3YhcJERGRFUjZRWKuadOm4ZtvvsFPP/2EZs2aGfcrlUoAqFKJyMvLM1Y1lEolNBoNCgoKamxTG6xg3CVHb084Cs62DqNR0F8vtHUIjU7rqem2DqFRObOqi61DaFQM5RXA9M3W/0M2WAdDFEVMmzYNW7Zswe7duxEWFmZyPCwsDEqlEjt37kTnzp0BABqNBnv27MHixYsBANHR0XBycsLOnTsxevRoAEBOTg6OHz+OJUuW1DoWJhhEREQNxNSpU7FhwwZ8/fXX8PDwMFYqvLy84OLiAkEQEB8fj8TERERERCAiIgKJiYlwdXXFuHHjjG3j4uIwc+ZM+Pn5wdfXF7NmzUJUVJRxVkltMMEgIiKyAlvci2TlypUAgD59+pjsX7duHSZOnAgAmD17NsrLyzFlyhQUFBQgJiYGO3bsgIeHh7H98uXLIZPJMHr0aJSXl6N///5ISUmBo6NjrWNhgkFERGQNNribqliL9oIgICEhAQkJCTW2USgUePfdd/Huu++a9fdvxUGeREREJDlWMIiIiKygsd+unQkGERGRNfBuqkRERETSYgWDiIjICthFQkRERNIziJWbpdewU0wwiIiIrIFjMIiIiIikxQoGERGRFQiQYAyGJJHYBhMMIiIia7DBSp71CbtIiIiISHKsYBAREVkBp6kSERGR9DiLhIiIiEharGAQERFZgSCKECwcpGnp+bbEBIOIiMgaDH9vll7DTrGLhIiIiCTHCgYREZEVsIuEiIiIpNfIZ5EwwSAiIrIGruRJREREJC1WMIiIiKyAK3kSERGR9NhFQkRERCQtVjCIiIisQDBUbpZew14xwSAiIrIGdpEQERERSYsVDCIiImvgQltEREQktca+VDi7SIiIiEhyrGAQERFZQyMf5MkEg4iIyBpEAJZOM7Xf/IIJBhERkTVwDAYRERGRxFjBICIisgYREozBkCQSm2CCQUREZA2NfJAnu0iIiIhIckwwGpAHxlzGe1vS8eX+X/Hl/l+xdMNhdP3XtWrbPpdwFt+d/BnDH8uu4ygbvsiYEryWmoENh07gh8t/oMfgQluH1GA5OIqY8OJlpO47jm/+OoyUX49jfHwOBMF+f/XVJz7fX0brpw6gyaaLxn3uh66hafIZtHrhMFo/dQDyrLIq5znlVSD4/T/RcsZhtJqejqAP/oJjkbYuQ68fDBJtZvj555/x4IMPIjg4GIIgYOvWrSbHRVFEQkICgoOD4eLigj59+uDEiRMmbdRqNaZNmwZ/f3+4ubnhoYceQna2+d8VTDAakKu5cqxbHobnR3XG86M644//eWP+ihNoHl5q0q5H/6to07EYV3OdbRRpw6ZwNeD8CQXem9fU1qE0eGOmqDD0sSt475UQTO7THqsTm+KRZ3Ix/Mkrtg7N7skvlMD75ytQN3Mx2S+oDSgPd8eVkc2qPU9Q69E0+SxEAcie0QZZs9tB0IlouuJPwNC4Er8bs0gs3cxRWlqKTp06YcWKFdUeX7JkCZYtW4YVK1bgwIEDUCqVGDBgAIqLi41t4uPjsWXLFmzcuBF79+5FSUkJhg0bBr1eb1YsNk8wVCoVnn/+eYSHh0OhUCAwMBD33XcfVq1ahbKyysz48OHDGDZsGAICAqBQKNCiRQuMGTMGV69eRXp6OgRBwN69e6u9/qBBg/DQQw9BEIQ7bhMnTqzDZ20d+3f74eDPvriU6YpLma74+O0wVJQ5om3HImMbvwA1np33F96c3RZ6nWDDaBuugz95InVJEH793tvWoTR47aJL8dsOb+z/0Qu52XLs/a8PDv3siYiOVX9VU+0JFXoErT6P3MdaQO9qOlSvuIc/rg1rirJ2ntWe6/JXCZzy1cid2BKaZq7QNHOFamIYFBdK4Xq6qNpz6J8VFRWZbGq1utp2Q4YMweuvv46RI0dWOSaKIpKTkzFv3jyMHDkSkZGRSE1NRVlZGTZs2AAAKCwsxJo1a7B06VLExsaic+fOWL9+PY4dO4a0tDSzYrZpgnH+/Hl07twZO3bsQGJiIg4fPoy0tDS88MIL+Pbbb5GWloa8vDzExsbC398fP/zwA06dOoW1a9ciKCgIZWVliI6ORqdOnbBu3boq18/KykJaWhri4uKQk5Nj3JKTk+Hp6Wmy7+2337bBK2A9Dg4i7h+SB4WLHqf+qPwgEAQRs944jc1rQ3DxLzcbR0hkueMH3HFPr2I0DasAALRsV4YO3Upw4Mfqv/yodgI+y0RplDfK2nuZfa6gEwEBEGU3f8CITg4Qhcrko1G5McjT0g1ASEgIvLy8jFtSUpLZ4WRkZEClUmHgwIHGfXK5HL1798a+ffsAAOnp6dBqtSZtgoODERkZaWxTWzadRTJlyhTIZDIcPHgQbm43v/CioqLw8MMPQxRFfP311ygqKsLq1ashk1WGGxYWhn79+hnbx8XFYe7cuXjnnXdMrpOSkoImTZpg6NChxnMBwMvLC4IgQKlU1sGzrFstIkqx9LPDcHY2oLzMEf+Z3gFZ5ypfk1GTsqDXC/h6fbCNoySSxufvBcLNQ4/Ve07CoAccHIGUxcHY/bWvrUOzWx7786HILMPFee3v6vyKlm4wODvC/6tsXB1R2U3YZHM2BBFwLGxk4zAknEWSlZUFT8+bibNcLjf7UiqVCgAQGBhosj8wMBCZmZnGNs7OzvDx8anS5sb5tWWzCkZ+fj527NiBqVOnmiQFt7qRBOh0OmzZsgViDf+hxo8fD61Wiy+++MK4TxRFpKSkYMKECSbJhbnUanWV0lR9ln3BBc+NjMaM/+uM7zYFY2biGYS0KkV4+2I89NglLJvbBgC7Rqhh6P1QAfqPvIY3nmuBqUPa4a0XQvHIM7mIfSTf1qHZJdk1NZpsuoicuJYQne7u60Hv4YScp1vB7Y/rCJ9+COHPH4JDuR4VzV3rQae8/fL09DTZ7ibBuEEQTL8DRFGssu92tWlzO5tVMP766y+Ioog2bdqY7Pf390dFRWW5c+rUqVi8eDHmzp2LcePG4ZlnnsG9996Lfv364fHHHzdmYb6+vhgxYgTWrVtnHEuxe/dunD9/Hk8++aRFcSYlJeG1116z6Bp1Sad1QM7FykFZf57wQERkMYY/dglZ51zh7atF6q7/Gds6yoBJs89jxOOX8MSAGFuFTHTXJr9yCZveU2LPN5UViwunXRDQVIOxz6mQ9qWfjaOzP/LMMsiKdQhddHNWgWAAXP4shvdPufjz/a6Awz9/yZR18MKFxI5wKNYCjgIMrjK0nHUYWv9GVlmqZ+tg3Kjaq1QqBAUFGffn5eUZv0+VSiU0Gg0KCgpMqhh5eXno2bOnWX/P5vnk7RnR/v37ceTIEXTo0ME4iGXRokVQqVRYtWoV2rdvj1WrVqFt27Y4duyY8by4uDj8/PPP+OuvvwAAa9euRa9evaokMOaaM2cOCgsLjVtWVpZF16trggA4OYn48ZtATB0RjedG3tyu5jpj89oQvDI5ytZhEt0VuYsB4m3T+Ax6AYLNP9nsU1k7T1xY0AGZ829uFaGuKL7XD5nzO9QqubiVwcMJBlcZXE4XwbFYh5JO3tYJvL6ywTTVOwkLC4NSqcTOnTuN+zQaDfbs2WNMHqKjo+Hk5GTSJicnB8ePHzc7wbBZBSM8PByCIOD06dMm+1u2bAkAcHExnRrl5+eHUaNGYdSoUUhKSkLnzp3x1ltvITU1FQAQGxuL0NBQpKSkYPbs2fjqq69qnKZjDrlcblEpqi5NiM/AwV98cSVHDlc3Pe5/IA9R3a7j1aeiUFzohOJCJ5P2ep2AgqtOuHTB1UYRN0wKVz2CwzTGx8oQDVp2KEfxdUdcucSpwVL6facXxk5XIe+SMzLPKtAqshwjn8rDjk2sXtwNUeEITVPTzwOD3BF6d5lxv0OpDk7XNJBdr3yPO6nKAQA6TyfovSo/Yzx/vQJNkAv07jIozpcgYNNFFMQGQqs0/Vxv6Gxxs7OSkhLjD22gcmDnkSNH4Ovri+bNmyM+Ph6JiYmIiIhAREQEEhMT4erqinHjxgGoHKMYFxeHmTNnws/PD76+vpg1axaioqIQGxtrViw2SzD8/PwwYMAArFixAtOmTatxHEZ1nJ2d0apVK5SW3lzfQRAEPPHEE1i9ejWaNWsGBwcHjB492hqh11vefhrMeuM0fJtoUFosQ8ZZN7z6VBQO/+bzzyeTZFp3Ksebm88ZHz/z2mUAwI5NPlj6QnNbhdUgvT8/BBNevIznErPg7a9FvsoJ3633x6fJDW8Ad33h/sd1KFMyjI+DPzoPAMgfFoz8hyoHdTrnVsB/SzYcS/XQ+jkj/4FgXI8NrPZ6JK2DBw+ib9++xsczZswAAEyYMMH4A7y8vBxTpkxBQUEBYmJisGPHDnh4eBjPWb58OWQyGUaPHo3y8nL0798fKSkpcHR0NCsWQaxp5GQdOHfuHHr16gUfHx8kJCSgY8eOcHBwwIEDBzBr1iyMHz8effv2xcaNGzF27Fi0bt0aoiji22+/xcsvv4x169bhscceM17v4sWLCAsLg5eXFx5++GF89NFH1f7dlJQUxMfH4/r162bHXFRUBC8vL/T3fgwygb9G64L+OlfCrHMO5n2QkGXOrupi6xAaFUN5BbKnL0BhYaHJzAyp3PieiI14ATJHyyrgOr0aaX8ut1qs1mTTaaqtWrXC4cOHkZiYiDlz5iA7OxtyuRzt27fHrFmzMGXKFKhUKri6umLmzJnIysqCXC5HREQEVq9ebZJcAEDz5s0RGxuLHTt2WDy4k4iIyCIGEbB02Xo7Xv3UphUMe8QKRt1jBcMGWMGoU6xg1K06q2C0ipemgnEumRUMIiIi+ls9m6Za15hgEBERWYUECQbsN8HgbHEiIiKSHCsYRERE1sAuEiIiIpKcQYTFXRx2PIuEXSREREQkOVYwiIiIrEE0oMrNcu7mGnaKCQYREZE1cAwGERERSY5jMIiIiIikxQoGERGRNbCLhIiIiCQnQoIEQ5JIbIJdJERERCQ5VjCIiIisgV0kREREJDmDAYCF61gY7HcdDHaREBERkeRYwSAiIrIGdpEQERGR5Bp5gsEuEiIiIpIcKxhERETW0MiXCmeCQUREZAWiaIBo4d1QLT3flphgEBERWYMoWl6B4BgMIiIioptYwSAiIrIGUYIxGHZcwWCCQUREZA0GAyBYOIbCjsdgsIuEiIiIJMcKBhERkTWwi4SIiIikJhoMEC3sIrHnaarsIiEiIiLJsYJBRERkDewiISIiIskZREBovAkGu0iIiIhIcqxgEBERWYMoArB0HQz7rWAwwSAiIrIC0SBCtLCLRGSCQURERCZEAyyvYHCaKhEREdUD77//PsLCwqBQKBAdHY1ffvnFJnEwwSAiIrIC0SBKsplj06ZNiI+Px7x583D48GH861//wpAhQ3Dx4kUrPcuaMcEgIiKyBtEgzWaGZcuWIS4uDpMmTUK7du2QnJyMkJAQrFy50kpPsmYcg2GmGwNudKLGxpE0HnpRa+sQGh877ve1R4byCluH0KjceL2tPYBSB63F62zpUPn5V1RUZLJfLpdDLpeb7NNoNEhPT8fLL79ssn/gwIHYt2+fZYHcBSYYZiouLgYA7CncZONIiKyI+UXdmv6VrSNolIqLi+Hl5SX5dZ2dnaFUKrFX9Z0k13N3d0dISIjJvgULFiAhIcFk39WrV6HX6xEYGGiyPzAwECqVSpJYzMEEw0zBwcHIysqCh4cHBEGwdTi1VlRUhJCQEGRlZcHT09PW4TQKfM3rFl/vumXPr7coiiguLkZwcLBVrq9QKJCRkQGNRppKtyiKVb5vbq9e3Or2ttWdXxeYYJjJwcEBzZo1s3UYd83T09PuPgzsHV/zusXXu27Z6+ttjcrFrRQKBRQKhVX/xu38/f3h6OhYpVqRl5dXpapRFzjIk4iIqAFwdnZGdHQ0du7cabJ/586d6NmzZ53HwwoGERFRAzFjxgw89thj6Nq1K3r06IEPP/wQFy9exDPPPFPnsTDBaCTkcjkWLFhwx347khZf87rF17tu8fWun8aMGYP8/HwsXLgQOTk5iIyMxHfffYfQ0NA6j0UQ7XmhcyIiIqqXOAaDiIiIJMcEg4iIiCTHBIOIiIgkxwSDiIiIJMcEw47t27cPjo6OGDx4sMn+CxcuQBCEKtujjz5qcvzIkSPVtnd2dkZ4eDhef/11q6/Vb+/y8vLw9NNPo3nz5pDL5VAqlRg0aBB+++03AECLFi2Mr6ujoyOCg4MRFxeHgoICG0duv8x5zV1cXNC2bVu8+eabfC9XQ6VS4fnnn0d4eDgUCgUCAwNx3333YdWqVSgrKwMAHD58GMOGDUNAQAAUCgVatGiBMWPG4OrVq0hPT4cgCNi7d2+11x80aBAeeuihaj+Pbt0mTpxYh8+a6gqnqdqxtWvXYtq0aVi9ejUuXryI5s2bmxxPS0tDhw4djI9dXFzueL0b7dVqNfbu3YtJkyYhKCgIcXFxVom/IXj44Yeh1WqRmpqKli1bIjc3F7t27cK1a9eMbRYuXIjJkydDr9fj7NmzeOqppzB9+nR88sknNozcfpnzmldUVCAtLQ3PPvssPD098fTTT9sw8vrl/Pnz6NWrF7y9vZGYmIioqCjodDqcPXsWa9euRXBwMLp3747Y2Fg8+OCD+OGHH+Dt7Y2MjAx88803KCsrQ3R0NDp16oR169bhvvvuM7l+VlYW0tLS8NVXX+HDDz807t+0aRNeffVVnDlzxrjvnz6byE6JZJdKSkpEDw8P8fTp0+KYMWPE1157zXgsIyNDBCAePny42nNvP15T+379+olTpkyx0jOwfwUFBSIAcffu3TW2CQ0NFZcvX26yb+HChWL79u2tHF3DdLeveZcuXcSRI0daOTr7MmjQILFZs2ZiSUlJtccNBoO4ZcsWUSaTiVqttsbrvPPOO6K7u3uV6yxcuFAMDAyscu66detELy8vi+On+o9dJHZq06ZNaNOmDdq0aYNHH30U69atk7QEfPDgQRw6dAgxMTGSXbOhcXd3h7u7O7Zu3Qq1Wl2rcy5duoRt27bxdb1L5r7moihi9+7dOHXqFJycnOogQvuQn5+PHTt2YOrUqXBzc6u2jSAIUCqV0Ol02LJlS42fL+PHj4dWq8UXX3xh3CeKIlJSUjBhwgTIZCyUN1q2zW/obvXs2VNMTk4WRVEUtVqt6O/vL+7cuVMUxZsVCRcXF9HNzc24HTp0yOT47RWMG+2dnJxEAOJTTz1lk+dmT7788kvRx8dHVCgUYs+ePcU5c+aIf/zxh/F4aGio6OzsLLq5uYkKhUIEIMbExIgFBQW2C9rOmfOa33gvKxQK8ddff7Vh1PXL77//LgIQv/rqK5P9fn5+xs+L2bNni6IoinPnzhVlMpno6+srDh48WFyyZImoUqlMzhszZox4//33Gx//+OOPIgDx9OnTVf42KxiNBysYdujMmTPYv38/xo4dCwCQyWQYM2YM1q5da9Ju06ZNOHLkiHFr3779Ha97o/0ff/yBTZs24euvv8bLL79stefREDz88MO4fPkyvvnmGwwaNAi7d+9Gly5dkJKSYmzz4osv4siRIzh69Ch27doFABg6dCj0er2NorZv5rzme/bsQd++fTFv3jyb3Oypvrv9Ft779+/HkSNHjGOxAGDRokVQqVRYtWoV2rdvj1WrVqFt27Y4duyY8by4uDj8/PPP+OuvvwBUjg/r1asX2rRpU3dPhuofW2c4ZL4XX3xRBCA6OjoaNwcHB1Eul4vXrl2TbAxGUlKSKJPJxPLycus+oQYmLi5ObN68uSiK1Y8H+O2330QAxooTWe5Or/m1a9dEX19fvt63uHr1qigIgpiUlFTt8d69e4vPP/98tcfUarXYvn178fHHHzfuMxgMYmhoqDhv3jyxsLBQdHV1FdeuXVvt+axgNB6sYNgZnU6Hjz/+GEuXLjWpTvzxxx8IDQ3Fp59+KtnfcnR0hE6ng0ajkeyajUH79u1RWlpa43FHR0cAQHl5eV2F1ODd6TX38fHBtGnTMGvWLE5V/Zufnx8GDBiAFStW3PG9Wh1nZ2e0atXK5DxBEPDEE08gNTUVGzZsgIODA0aPHi112GRnmGDYmW3btqGgoABxcXGIjIw02R555BGsWbPmrq+dn58PlUqF7OxsfP/993j77bfRt29feHp6SvgMGo78/Hz069cP69evx9GjR5GRkYEvvvgCS5YswfDhw43tiouLoVKpkJOTg/379+PFF1+Ev78/S/Z3obav+e2mTp2KM2fOYPPmzXUYbf32/vvvQ6fToWvXrti0aRNOnTqFM2fOYP369Th9+jQcHR2xbds2PProo9i2bRvOnj2LM2fO4K233sJ3331X5fV+4okncPnyZcydOxdjx46tcfAoNSK2LqGQeYYNGyY+8MAD1R5LT08XARj/19wukhubo6Oj2KxZM3Hy5MliXl6elZ6J/auoqBBffvllsUuXLqKXl5fo6uoqtmnTRnzllVfEsrIyURQry/W3vrZNmjQRH3jggRr/29Cd1fY1v71bShRFcfLkyWKHDh1EvV5fx1HXX5cvXxafe+45MSwsTHRychLd3d3Fe++9V3zzzTfF0tJS8dy5c+LkyZPF1q1biy4uLqK3t7fYrVs3cd26ddVeb+DAgSIAcd++fTX+TXaRNB68XTsRERFJjl0kREREJDkmGERERCQ5JhhEREQkOSYYREREJDkmGERERCQ5JhhEREQkOSYYREREJDkmGERERCQ5JhhEdighIQH33HOP8fHEiRMxYsSIOo/jwoULEAQBR44cqbFNixYtkJycXOtrpqSkwNvb2+LYBEHA1q1bLb4OEd0dJhhEEpk4cSIEQYAgCHByckLLli0xa9Yss28mdTfefvttk9uV30ltkgIiIkvJbB0AUUMyePBgrFu3DlqtFr/88gsmTZqE0tJSrFy5skpbrVYLJycnSf6ul5eXJNchIpIKKxhEEpLL5VAqlQgJCcG4ceMwfvx4Y5n+RrfG2rVr0bJlS8jlcoiiiMLCQjz11FMICAiAp6cn+vXrhz/++MPkum+88QYCAwPh4eGBuLg4VFRUmBy/vYvEYDBg8eLFCA8Ph1wuR/PmzbFo0SIAQFhYGACgc+fOEAQBffr0MZ63bt06tGvXDgqFAm3btsX7779v8nf279+Pzp07Q6FQoGvXrjh8+LDZr9GyZcsQFRUFNzc3hISEYMqUKSgpKanSbuvWrWjdujUUCgUGDBiArKwsk+PffvstoqOjoVAo0LJlS7z22mvQ6XRmx0NE1sEEg8iKXFxcoNVqjY//+usvfP7559i8ebOxi2Lo0KFQqVT47rvvkJ6eji5duqB///64du0aAODzzz/HggULsGjRIhw8eBBBQUFVvvhvN2fOHCxevBjz58/HyZMnsWHDBgQGBgKoTBIAIC0tDTk5Ofjqq68AAB999BHmzZuHRYsW4dSpU0hMTMT8+fORmpoKACgtLcWwYcPQpk0bpKenIyEhAbNmzTL7NXFwcMA777yD48ePIzU1FT/++CNmz55t0qasrAyLFi1Camoqfv31VxQVFWHs2LHG4z/88AMeffRRTJ8+HSdPnsQHH3yAlJQUYxJFRPWAje/mStRgTJgwQRw+fLjx8f/+9z/Rz89PHD16tCiKorhgwQLRyclJzMvLM7bZtWuX6OnpKVZUVJhcq1WrVuIHH3wgiqIo9ujRQ3zmmWdMjsfExIidOnWq9m8XFRWJcrlc/Oijj6qNMyMjQwRQ5ZbxISEh4oYNG0z2/ec//xF79OghiqIofvDBB6Kvr69YWlpqPL5y5cpqr3Wrmm6ffsPnn38u+vn5GR+vW7dOBCD+/vvvxn2nTp0SAYj/+9//RFEUxX/9619iYmKiyXU++eQTMSgoyPgYgLhly5Ya/y4RWRfHYBBJaNu2bXB3d4dOp4NWq8Xw4cPx7rvvGo+HhoaiSZMmxsfp6ekoKSmBn5+fyXXKy8tx7tw5AMCpU6fwzDPPmBzv0aMHfvrpp2pjOHXqFNRqNfr371/ruK9cuYKsrCzExcVh8uTJxv06nc44vuPUqVPo1KkTXF1dTeIw108//YTExEScPHkSRUVF0Ol0qKioQGlpKdzc3AAAMpkMXbt2NZ7Ttm1beHt749SpU7j33nuRnp6OAwcOmFQs9Ho9KioqUFZWZhIjEdkGEwwiCfXt2xcrV66Ek5MTgoODqwzivPEFeoPBYEBQUBB2795d5Vp3O1XTxcXF7HMMBgOAym6SmJgYk2OOjo4AAFEU7yqeW2VmZuKBBx7AM888g//85z/w9fXF3r17ERcXZ9KVBFROM73djX0GgwGvvfYaRo4cWaWNQqGwOE4ishwTDCIJubm5ITw8vNbtu3TpApVKBZlMhhYtWlTbpl27dvj999/x+OOPG/f9/vvvNV4zIiICLi4u2LVrFyZNmlTluLOzM4DKX/w3BAYGomnTpjh//jzGjx9f7XXbt2+PTz75BOXl5cYk5k5xVOfgwYPQ6XRYunQpHBwqh4B9/vnnVdrpdDocPHgQ9957LwDgzJkzuH79Otq2bQug8nU7c+aMWa81EdUtJhhENhQbG4sePXpgxIgRWLx4Mdq0aYPLly/ju+++w4gRI9C1a1c8//zzmDBhArp27Yr77rsPn376KU6cOIGWLVtWe02FQoGXXnoJs2fPhrOzM3r16oUrV67gxIkTiIuLQ0BAAFxcXLB9+3Y0a9YMCoUCXl5eSEhIwPTp0+Hp6YkhQ4ZArVbj4MGDKCgowIwZMzBu3DjMmzcPcXFxeOWVV3DhwgW89dZbZj3fVq1aQafT4d1338WDDz6IX3/9FatWrarSzsnJCdOmTcM777wDJycnPPfcc+jevbsx4Xj11VcxbNgwhISEYNSoUXBwcMDRo0dx7NgxvP766+b/hyAiyXEWCZENCYKA7777Dvfffz+efPJJtG7dGmPHjsWFCxeMsz7GjBmDV199FS+99BKio6ORmZmJZ5999o7XnT9/PmbOnIlXX30V7dq1w5gxY5CXlwegcnzDO++8gw8++ADBwcEYPnw4AGDSpElYvXo1UlJSEBUVhd69eyMlJcU4rdXd3R3ffvstTp48ic6dO2PevHlYvHixWc/3nnvuwbJly7B48WJERkbi008/RVJSUpV2rq6ueOmllzBu3Dj06NEDLi4u2Lhxo/H4oEGDsG3bNuzcuRPdunVD9+7dsWzZMoSGhpoVDxFZjyBK0bFKREREdAtWMIiIiEhyTDCIiIhIckwwiIiISHJMMIiIiEhyTDCIiIhIckwwiIiISHJMMIiIiEhyTDCIiIhIckwwiIiISHJMMIiIiEhyTDCIiIhIcv8Pz2Yqq14mFPgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.964319</td>\n",
       "      <td>0.923596</td>\n",
       "      <td>0.907285</td>\n",
       "      <td>0.915367</td>\n",
       "      <td>0.975074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.982160</td>\n",
       "      <td>0.984576</td>\n",
       "      <td>0.967172</td>\n",
       "      <td>0.975796</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.973709</td>\n",
       "      <td>0.919101</td>\n",
       "      <td>0.953380</td>\n",
       "      <td>0.935927</td>\n",
       "      <td>0.988131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.962441</td>\n",
       "      <td>0.906926</td>\n",
       "      <td>0.918860</td>\n",
       "      <td>0.912854</td>\n",
       "      <td>0.977818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.934986</td>\n",
       "      <td>0.936674</td>\n",
       "      <td>0.933550</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.941315</td>\n",
       "      <td>0.941315</td>\n",
       "      <td>0.941315</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.941190</td>\n",
       "      <td>0.941300</td>\n",
       "      <td>0.941315</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.964319  0.923596   0.907285  0.915367     0.975074\n",
       "1            SB  0.982160  0.984576   0.967172  0.975796     0.980769\n",
       "2            SR  0.973709  0.919101   0.953380  0.935927     0.988131\n",
       "3          GSVT  0.962441  0.906926   0.918860  0.912854     0.977818\n",
       "4     macro avg       NaN  0.934986   0.936674  0.933550          NaN\n",
       "5     micro avg       NaN  0.941315   0.941315  0.941315          NaN\n",
       "6  weighted avg       NaN  0.941190   0.941300  0.941315          NaN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"./Result/Blending_KNN_PCA.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
