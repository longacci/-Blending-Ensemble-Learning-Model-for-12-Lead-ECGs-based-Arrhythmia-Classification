{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>782.0</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>252.222222</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>87.777778</td>\n",
       "      <td>10339.061728</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>4315.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6555.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>697.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>594.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>1360.782222</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>420.090909</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1504.888889</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>569.437500</td>\n",
       "      <td>136.444444</td>\n",
       "      <td>43.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>615.733333</td>\n",
       "      <td>596.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.500000</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1746.285714</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>4722.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>654.428571</td>\n",
       "      <td>648.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>2686.204082</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3602.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>101.142857</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>-10.750000</td>\n",
       "      <td>7259.937500</td>\n",
       "      <td>88.222222</td>\n",
       "      <td>202.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1041.250000</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2            3       4           5      6         7         8  \\\n",
       "0     0.0  10.0   950.000000  1074.0  274.986868  782.0 -0.319753 -1.432466   \n",
       "1     0.0  17.0   574.500000   582.0  104.913059  378.0  0.158313 -0.696295   \n",
       "2     3.0  16.0   593.600000   594.0    4.687572   18.0  0.396421 -0.312612   \n",
       "3     3.0  23.0   420.090909   420.0    3.591772   12.0 -0.021014 -0.856142   \n",
       "4     1.0   9.0  1068.750000  1075.0   25.118469   76.0 -0.276816 -1.271399   \n",
       "...   ...   ...          ...     ...         ...    ...       ...       ...   \n",
       "8511  3.0  16.0   615.733333   596.0   51.114860  152.0  2.153820  2.645687   \n",
       "8512  1.0   9.0  1091.500000  1093.0    5.894913   18.0 -0.311206 -1.184514   \n",
       "8513  2.0  15.0   654.428571   648.0  107.653355  458.0  0.475616  0.784000   \n",
       "8514  1.0   9.0  1075.000000  1083.0   24.535688   66.0 -0.263431 -1.567800   \n",
       "8515  1.0   9.0  1041.250000  1040.0    8.242421   22.0  0.214800 -1.575835   \n",
       "\n",
       "               9        10  ...       204         205        206        207  \\\n",
       "0     325.821586  1.000000  ...  1.000000  172.000000  10.000000   9.000000   \n",
       "1     336.569414  1.000000  ...  0.882353  -15.000000  15.000000   4.000000   \n",
       "2      94.909877  1.000000  ...  1.000000   -4.000000  16.000000  15.000000   \n",
       "3     254.059787  0.826087  ...  0.739130   -9.000000   6.000000   4.000000   \n",
       "4     461.130814  1.000000  ...  1.000000    2.000000   9.000000   8.000000   \n",
       "...          ...       ...  ...       ...         ...        ...        ...   \n",
       "8511  365.256750  1.000000  ...  0.003757    0.022262   0.003757   0.003757   \n",
       "8512  358.414529  1.000000  ...  0.888889   -3.000000   9.000000   8.000000   \n",
       "8513  180.045117  1.000000  ...  1.000000   -4.000000  15.000000  14.000000   \n",
       "8514  251.455499  1.000000  ...  1.000000   14.000000   9.000000   8.000000   \n",
       "8515  505.203302  1.000000  ...  1.000000    0.000000   9.000000   8.000000   \n",
       "\n",
       "             208           209        210           211         212  \\\n",
       "0     252.222222  10656.395062  87.777778  10339.061728  135.800000   \n",
       "1     158.000000   3944.000000  73.000000   6555.000000   -1.066667   \n",
       "2     122.400000   2058.773333  12.533333   1360.782222   95.500000   \n",
       "3      40.666667   1120.888889   5.333333   1504.888889   12.000000   \n",
       "4     122.000000    671.000000  19.750000    569.437500  136.444444   \n",
       "...          ...           ...        ...           ...         ...   \n",
       "8511    0.044242      0.044242   0.043021      0.043021    0.037385   \n",
       "8512   81.428571   1294.530612 -40.000000   1746.285714  155.333333   \n",
       "8513   77.142857   2213.551020  -1.714286   2686.204082  104.000000   \n",
       "8514  101.142857   4933.551020 -10.750000   7259.937500   88.222222   \n",
       "8515  102.000000    350.000000 -20.000000    588.000000  150.000000   \n",
       "\n",
       "              213  \n",
       "0     4315.560000  \n",
       "1      697.528889  \n",
       "2       68.750000  \n",
       "3     1464.000000  \n",
       "4       43.358025  \n",
       "...           ...  \n",
       "8511     0.037385  \n",
       "8512  4722.666667  \n",
       "8513  3602.666667  \n",
       "8514   202.172840  \n",
       "8515     0.000000  \n",
       "\n",
       "[8516 rows x 213 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_frequency.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>710.769231</td>\n",
       "      <td>628.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3140.437500</td>\n",
       "      <td>127.600000</td>\n",
       "      <td>1041.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>968.666667</td>\n",
       "      <td>894.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>5249.000000</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>8081.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>8070.530612</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1078.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>757.500000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>7081.416667</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>264.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>413.909091</td>\n",
       "      <td>409.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>832.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>342.857143</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>205.142857</td>\n",
       "      <td>11207.836735</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2281.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>14282.775510</td>\n",
       "      <td>169.142857</td>\n",
       "      <td>46.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>361.489796</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>2186.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.285714</td>\n",
       "      <td>996.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>-45.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2       3           4      5         6          7  \\\n",
       "0     0.0  14.0   710.769231   628.0  153.204817  556.0  0.996355   0.207174   \n",
       "1     0.0  10.0   968.666667   894.0  266.399867  932.0  0.979352   0.388359   \n",
       "2     0.0  11.0   797.000000   780.0  251.329664  794.0  0.260470  -1.002325   \n",
       "3     2.0  13.0   757.500000   755.0    8.986100   26.0  0.048579  -1.449012   \n",
       "4     0.0  23.0   413.909091   409.0   82.344017  426.0  3.023659  10.404884   \n",
       "...   ...   ...          ...     ...         ...    ...       ...        ...   \n",
       "2125  1.0   9.0  1071.250000  1062.0   36.509417  118.0  1.263183   0.543003   \n",
       "2126  1.0   8.0  1196.000000  1202.0   33.839959  102.0 -0.454057  -1.036905   \n",
       "2127  3.0  16.0   595.600000   590.0   23.734082   82.0  0.371174  -0.657132   \n",
       "2128  1.0   8.0  1080.285714   996.0  180.470587  448.0  0.587475  -1.363827   \n",
       "2129  3.0  25.0   391.250000   390.0    2.569857    8.0  0.605786  -0.869886   \n",
       "\n",
       "               8         9  ...       203        204   205   206         207  \\\n",
       "0     459.037295  1.000000  ...  0.928571 -10.000000  10.0   9.0  146.000000   \n",
       "1     398.464564  1.000000  ...  0.600000  64.000000   7.0   7.0  140.500000   \n",
       "2     340.802438  1.000000  ...  1.000000  26.000000   9.0   7.0  154.285714   \n",
       "3     412.324324  1.000000  ...  1.000000  -4.000000  12.0  12.0  108.500000   \n",
       "4     168.041577  0.956522  ...  0.083333   0.022262  11.0  12.0    0.044242   \n",
       "...          ...       ...  ...       ...        ...   ...   ...         ...   \n",
       "2125  364.303573  0.888889  ...  0.777778   0.000000   9.0   8.0  342.857143   \n",
       "2126  181.876516  1.000000  ...  1.000000 -26.000000   8.0   7.0  137.666667   \n",
       "2127  137.696567  1.000000  ...  1.000000  -8.000000  16.0  14.0  102.714286   \n",
       "2128  561.988537  1.000000  ...  1.000000  18.000000   8.0   5.0   62.400000   \n",
       "2129  654.123072  0.400000  ...  0.240000   4.000000   0.0   0.0    0.044242   \n",
       "\n",
       "               208         209           210         211          212  \n",
       "0       729.000000   78.250000   3140.437500  127.600000  1041.440000  \n",
       "1     15314.750000  -27.000000   5249.000000  112.285714  8081.632653  \n",
       "2      1944.489796   18.571429   8070.530612  131.111111  1078.320988  \n",
       "3      6122.750000   46.500000   7081.416667  121.833333   264.305556  \n",
       "4         0.044242  -50.000000      0.000000   45.818182   832.330579  \n",
       "...            ...         ...           ...         ...          ...  \n",
       "2125   2843.265306  205.142857  11207.836735   96.000000  2281.142857  \n",
       "2126    228.555556   87.714286  14282.775510  169.142857    46.693878  \n",
       "2127   1270.061224    7.285714    361.489796   90.400000  2186.240000  \n",
       "2128     51.840000  -45.200000      0.960000  101.000000  5002.000000  \n",
       "2129      0.044242    0.043021      0.043021    0.037385     0.037385  \n",
       "\n",
       "[2130 rows x 213 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_frequency.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 0.9)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4258, 51)\n",
      "Vallidation: (4258, 51)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 5, max_features= 'sqrt', n_estimators= 1000)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 50)\n",
    "knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "# svc_clf = SVC(C= 100, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.1,max_depth= 5,min_child_weight= 1,n_estimators= 1000)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 5,max_features= 'sqrt',splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features='sqrt')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "# svc_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    knn_clf.predict_proba(x_val),\n",
    "    # svc_clf.predict_proba(x_val),\n",
    "    xgb_clf.predict_proba(x_val),\n",
    "    dt_clf.predict_proba(x_val)\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    knn_clf.predict_proba(x_test),\n",
    "    # svc_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    dt_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4258, 20)\n",
      "X_test_meta:(2130, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=rbf, probability=True;, score=(train=0.927, test=0.930) total time=   0.7s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=rbf, probability=True;, score=(train=0.924, test=0.937) total time=   0.7s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=rbf, probability=True;, score=(train=0.934, test=0.915) total time=   0.7s\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.926, test=0.930) total time=   0.4s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.923, test=0.937) total time=   0.4s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.934, test=0.917) total time=   0.4s\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=poly, probability=True;, score=(train=0.922, test=0.927) total time=   0.3s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=poly, probability=True;, score=(train=0.919, test=0.930) total time=   0.4s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=poly, probability=True;, score=(train=0.928, test=0.915) total time=   0.3s\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=linear, probability=True;, score=(train=0.927, test=0.931) total time=   0.1s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=linear, probability=True;, score=(train=0.924, test=0.937) total time=   0.1s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=linear, probability=True;, score=(train=0.934, test=0.915) total time=   0.1s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=rbf, probability=True;, score=(train=0.926, test=0.930) total time=   0.7s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=rbf, probability=True;, score=(train=0.923, test=0.937) total time=   0.7s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=rbf, probability=True;, score=(train=0.935, test=0.913) total time=   0.7s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.926, test=0.930) total time=   0.5s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.923, test=0.937) total time=   0.5s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.934, test=0.914) total time=   0.5s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=poly, probability=True;, score=(train=0.910, test=0.915) total time=   0.6s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=poly, probability=True;, score=(train=0.911, test=0.921) total time=   0.6s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=poly, probability=True;, score=(train=0.918, test=0.900) total time=   0.6s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=linear, probability=True;, score=(train=0.927, test=0.931) total time=   0.1s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=linear, probability=True;, score=(train=0.924, test=0.937) total time=   0.2s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=linear, probability=True;, score=(train=0.934, test=0.915) total time=   0.1s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.926, test=0.931) total time=   0.2s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.924, test=0.937) total time=   0.2s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.936, test=0.915) total time=   0.2s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.926, test=0.932) total time=   0.1s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.922, test=0.937) total time=   0.1s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.933, test=0.914) total time=   0.1s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=poly, probability=True;, score=(train=0.927, test=0.934) total time=   0.1s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=poly, probability=True;, score=(train=0.925, test=0.934) total time=   0.1s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=poly, probability=True;, score=(train=0.936, test=0.917) total time=   0.1s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=linear, probability=True;, score=(train=0.925, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=linear, probability=True;, score=(train=0.923, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=linear, probability=True;, score=(train=0.934, test=0.915) total time=   0.0s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.926, test=0.930) total time=   0.2s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.924, test=0.937) total time=   0.2s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.935, test=0.917) total time=   0.2s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.927, test=0.931) total time=   0.1s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.923, test=0.939) total time=   0.1s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.933, test=0.914) total time=   0.1s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=poly, probability=True;, score=(train=0.924, test=0.929) total time=   0.2s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=poly, probability=True;, score=(train=0.920, test=0.931) total time=   0.2s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=poly, probability=True;, score=(train=0.930, test=0.916) total time=   0.2s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=linear, probability=True;, score=(train=0.925, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=linear, probability=True;, score=(train=0.923, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=linear, probability=True;, score=(train=0.934, test=0.915) total time=   0.0s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.926, test=0.932) total time=   0.2s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.925, test=0.939) total time=   0.2s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.937, test=0.917) total time=   0.1s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.921, test=0.929) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.919, test=0.930) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.930, test=0.911) total time=   0.1s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=poly, probability=True;, score=(train=0.928, test=0.936) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=poly, probability=True;, score=(train=0.926, test=0.933) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=poly, probability=True;, score=(train=0.937, test=0.913) total time=   0.0s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=linear, probability=True;, score=(train=0.925, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=linear, probability=True;, score=(train=0.924, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=linear, probability=True;, score=(train=0.936, test=0.916) total time=   0.0s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.927, test=0.932) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.924, test=0.938) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.936, test=0.917) total time=   0.1s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.925, test=0.932) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.923, test=0.934) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.934, test=0.915) total time=   0.1s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=poly, probability=True;, score=(train=0.928, test=0.934) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=poly, probability=True;, score=(train=0.926, test=0.936) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=poly, probability=True;, score=(train=0.936, test=0.915) total time=   0.1s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=linear, probability=True;, score=(train=0.925, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=linear, probability=True;, score=(train=0.924, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=linear, probability=True;, score=(train=0.936, test=0.916) total time=   0.0s\n",
      "[CV 1/3] END C=10, gamma=scale, kernel=rbf, probability=True;, score=(train=0.928, test=0.933) total time=   0.2s\n",
      "[CV 2/3] END C=10, gamma=scale, kernel=rbf, probability=True;, score=(train=0.926, test=0.939) total time=   0.2s\n",
      "[CV 3/3] END C=10, gamma=scale, kernel=rbf, probability=True;, score=(train=0.938, test=0.916) total time=   0.1s\n",
      "[CV 1/3] END C=10, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.919, test=0.919) total time=   0.1s\n",
      "[CV 2/3] END C=10, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.918, test=0.934) total time=   0.1s\n",
      "[CV 3/3] END C=10, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.933, test=0.911) total time=   0.1s\n",
      "[CV 1/3] END C=10, gamma=scale, kernel=poly, probability=True;, score=(train=0.927, test=0.936) total time=   0.1s\n",
      "[CV 2/3] END C=10, gamma=scale, kernel=poly, probability=True;, score=(train=0.925, test=0.932) total time=   0.1s\n",
      "[CV 3/3] END C=10, gamma=scale, kernel=poly, probability=True;, score=(train=0.938, test=0.917) total time=   0.1s\n",
      "[CV 1/3] END C=10, gamma=scale, kernel=linear, probability=True;, score=(train=0.926, test=0.932) total time=   0.1s\n",
      "[CV 2/3] END C=10, gamma=scale, kernel=linear, probability=True;, score=(train=0.924, test=0.936) total time=   0.1s\n",
      "[CV 3/3] END C=10, gamma=scale, kernel=linear, probability=True;, score=(train=0.936, test=0.916) total time=   0.1s\n",
      "[CV 1/3] END C=10, gamma=auto, kernel=rbf, probability=True;, score=(train=0.928, test=0.932) total time=   0.2s\n",
      "[CV 2/3] END C=10, gamma=auto, kernel=rbf, probability=True;, score=(train=0.926, test=0.940) total time=   0.2s\n",
      "[CV 3/3] END C=10, gamma=auto, kernel=rbf, probability=True;, score=(train=0.937, test=0.915) total time=   0.1s\n",
      "[CV 1/3] END C=10, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.916, test=0.925) total time=   0.1s\n",
      "[CV 2/3] END C=10, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.922, test=0.934) total time=   0.1s\n",
      "[CV 3/3] END C=10, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.935, test=0.913) total time=   0.1s\n",
      "[CV 1/3] END C=10, gamma=auto, kernel=poly, probability=True;, score=(train=0.927, test=0.937) total time=   0.1s\n",
      "[CV 2/3] END C=10, gamma=auto, kernel=poly, probability=True;, score=(train=0.925, test=0.934) total time=   0.1s\n",
      "[CV 3/3] END C=10, gamma=auto, kernel=poly, probability=True;, score=(train=0.936, test=0.914) total time=   0.0s\n",
      "[CV 1/3] END C=10, gamma=auto, kernel=linear, probability=True;, score=(train=0.926, test=0.932) total time=   0.1s\n",
      "[CV 2/3] END C=10, gamma=auto, kernel=linear, probability=True;, score=(train=0.924, test=0.936) total time=   0.1s\n",
      "[CV 3/3] END C=10, gamma=auto, kernel=linear, probability=True;, score=(train=0.936, test=0.916) total time=   0.1s\n",
      "[CV 1/3] END C=100, gamma=scale, kernel=rbf, probability=True;, score=(train=0.929, test=0.935) total time=   0.4s\n",
      "[CV 2/3] END C=100, gamma=scale, kernel=rbf, probability=True;, score=(train=0.928, test=0.939) total time=   0.4s\n",
      "[CV 3/3] END C=100, gamma=scale, kernel=rbf, probability=True;, score=(train=0.939, test=0.915) total time=   0.3s\n",
      "[CV 1/3] END C=100, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.901, test=0.906) total time=   0.0s\n",
      "[CV 2/3] END C=100, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.896, test=0.903) total time=   0.1s\n",
      "[CV 3/3] END C=100, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.914, test=0.892) total time=   0.0s\n",
      "[CV 1/3] END C=100, gamma=scale, kernel=poly, probability=True;, score=(train=0.927, test=0.936) total time=   0.3s\n",
      "[CV 2/3] END C=100, gamma=scale, kernel=poly, probability=True;, score=(train=0.926, test=0.933) total time=   0.3s\n",
      "[CV 3/3] END C=100, gamma=scale, kernel=poly, probability=True;, score=(train=0.939, test=0.915) total time=   0.2s\n",
      "[CV 1/3] END C=100, gamma=scale, kernel=linear, probability=True;, score=(train=0.926, test=0.931) total time=   0.3s\n",
      "[CV 2/3] END C=100, gamma=scale, kernel=linear, probability=True;, score=(train=0.924, test=0.936) total time=   0.3s\n",
      "[CV 3/3] END C=100, gamma=scale, kernel=linear, probability=True;, score=(train=0.936, test=0.916) total time=   0.3s\n",
      "[CV 1/3] END C=100, gamma=auto, kernel=rbf, probability=True;, score=(train=0.929, test=0.934) total time=   0.4s\n",
      "[CV 2/3] END C=100, gamma=auto, kernel=rbf, probability=True;, score=(train=0.926, test=0.939) total time=   0.4s\n",
      "[CV 3/3] END C=100, gamma=auto, kernel=rbf, probability=True;, score=(train=0.938, test=0.915) total time=   0.3s\n",
      "[CV 1/3] END C=100, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.913, test=0.928) total time=   0.0s\n",
      "[CV 2/3] END C=100, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.905, test=0.917) total time=   0.1s\n",
      "[CV 3/3] END C=100, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.923, test=0.896) total time=   0.0s\n",
      "[CV 1/3] END C=100, gamma=auto, kernel=poly, probability=True;, score=(train=0.928, test=0.936) total time=   0.1s\n",
      "[CV 2/3] END C=100, gamma=auto, kernel=poly, probability=True;, score=(train=0.926, test=0.934) total time=   0.1s\n",
      "[CV 3/3] END C=100, gamma=auto, kernel=poly, probability=True;, score=(train=0.939, test=0.917) total time=   0.1s\n",
      "[CV 1/3] END C=100, gamma=auto, kernel=linear, probability=True;, score=(train=0.926, test=0.931) total time=   0.3s\n",
      "[CV 2/3] END C=100, gamma=auto, kernel=linear, probability=True;, score=(train=0.924, test=0.936) total time=   0.3s\n",
      "[CV 3/3] END C=100, gamma=auto, kernel=linear, probability=True;, score=(train=0.936, test=0.916) total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = SVC()\n",
    "params = {\n",
    "    'kernel': ['rbf', 'sigmoid', 'poly', 'linear'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'probability': [True]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9295430558450538"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.959155</td>\n",
       "      <td>0.907865</td>\n",
       "      <td>0.897778</td>\n",
       "      <td>0.902793</td>\n",
       "      <td>0.972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.976995</td>\n",
       "      <td>0.985861</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.969046</td>\n",
       "      <td>0.971893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.969014</td>\n",
       "      <td>0.894382</td>\n",
       "      <td>0.954436</td>\n",
       "      <td>0.923434</td>\n",
       "      <td>0.988724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.958685</td>\n",
       "      <td>0.900433</td>\n",
       "      <td>0.908297</td>\n",
       "      <td>0.904348</td>\n",
       "      <td>0.974820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.924905</td>\n",
       "      <td>0.928327</td>\n",
       "      <td>0.922135</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.931925</td>\n",
       "      <td>0.931925</td>\n",
       "      <td>0.931925</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.931642</td>\n",
       "      <td>0.931992</td>\n",
       "      <td>0.931925</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.959155  0.907865   0.897778  0.902793     0.972700\n",
       "1            SB  0.976995  0.985861   0.952795  0.969046     0.971893\n",
       "2            SR  0.969014  0.894382   0.954436  0.923434     0.988724\n",
       "3          GSVT  0.958685  0.900433   0.908297  0.904348     0.974820\n",
       "4     macro avg       NaN  0.924905   0.928327  0.922135          NaN\n",
       "5     micro avg       NaN  0.931925   0.931925  0.931925          NaN\n",
       "6  weighted avg       NaN  0.931642   0.931992  0.931925          NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"./Result/Blending_SVM_PCA.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
