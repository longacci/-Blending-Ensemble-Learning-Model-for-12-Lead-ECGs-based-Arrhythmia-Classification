{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>782.0</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>252.222222</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>87.777778</td>\n",
       "      <td>10339.061728</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>4315.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6555.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>697.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>594.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>1360.782222</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>420.090909</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1504.888889</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>569.437500</td>\n",
       "      <td>136.444444</td>\n",
       "      <td>43.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>615.733333</td>\n",
       "      <td>596.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.500000</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1746.285714</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>4722.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>654.428571</td>\n",
       "      <td>648.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>2686.204082</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3602.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>101.142857</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>-10.750000</td>\n",
       "      <td>7259.937500</td>\n",
       "      <td>88.222222</td>\n",
       "      <td>202.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1041.250000</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2            3       4           5      6         7         8  \\\n",
       "0     0.0  10.0   950.000000  1074.0  274.986868  782.0 -0.319753 -1.432466   \n",
       "1     0.0  17.0   574.500000   582.0  104.913059  378.0  0.158313 -0.696295   \n",
       "2     3.0  16.0   593.600000   594.0    4.687572   18.0  0.396421 -0.312612   \n",
       "3     3.0  23.0   420.090909   420.0    3.591772   12.0 -0.021014 -0.856142   \n",
       "4     1.0   9.0  1068.750000  1075.0   25.118469   76.0 -0.276816 -1.271399   \n",
       "...   ...   ...          ...     ...         ...    ...       ...       ...   \n",
       "8511  3.0  16.0   615.733333   596.0   51.114860  152.0  2.153820  2.645687   \n",
       "8512  1.0   9.0  1091.500000  1093.0    5.894913   18.0 -0.311206 -1.184514   \n",
       "8513  2.0  15.0   654.428571   648.0  107.653355  458.0  0.475616  0.784000   \n",
       "8514  1.0   9.0  1075.000000  1083.0   24.535688   66.0 -0.263431 -1.567800   \n",
       "8515  1.0   9.0  1041.250000  1040.0    8.242421   22.0  0.214800 -1.575835   \n",
       "\n",
       "               9        10  ...       204         205        206        207  \\\n",
       "0     325.821586  1.000000  ...  1.000000  172.000000  10.000000   9.000000   \n",
       "1     336.569414  1.000000  ...  0.882353  -15.000000  15.000000   4.000000   \n",
       "2      94.909877  1.000000  ...  1.000000   -4.000000  16.000000  15.000000   \n",
       "3     254.059787  0.826087  ...  0.739130   -9.000000   6.000000   4.000000   \n",
       "4     461.130814  1.000000  ...  1.000000    2.000000   9.000000   8.000000   \n",
       "...          ...       ...  ...       ...         ...        ...        ...   \n",
       "8511  365.256750  1.000000  ...  0.003757    0.022262   0.003757   0.003757   \n",
       "8512  358.414529  1.000000  ...  0.888889   -3.000000   9.000000   8.000000   \n",
       "8513  180.045117  1.000000  ...  1.000000   -4.000000  15.000000  14.000000   \n",
       "8514  251.455499  1.000000  ...  1.000000   14.000000   9.000000   8.000000   \n",
       "8515  505.203302  1.000000  ...  1.000000    0.000000   9.000000   8.000000   \n",
       "\n",
       "             208           209        210           211         212  \\\n",
       "0     252.222222  10656.395062  87.777778  10339.061728  135.800000   \n",
       "1     158.000000   3944.000000  73.000000   6555.000000   -1.066667   \n",
       "2     122.400000   2058.773333  12.533333   1360.782222   95.500000   \n",
       "3      40.666667   1120.888889   5.333333   1504.888889   12.000000   \n",
       "4     122.000000    671.000000  19.750000    569.437500  136.444444   \n",
       "...          ...           ...        ...           ...         ...   \n",
       "8511    0.044242      0.044242   0.043021      0.043021    0.037385   \n",
       "8512   81.428571   1294.530612 -40.000000   1746.285714  155.333333   \n",
       "8513   77.142857   2213.551020  -1.714286   2686.204082  104.000000   \n",
       "8514  101.142857   4933.551020 -10.750000   7259.937500   88.222222   \n",
       "8515  102.000000    350.000000 -20.000000    588.000000  150.000000   \n",
       "\n",
       "              213  \n",
       "0     4315.560000  \n",
       "1      697.528889  \n",
       "2       68.750000  \n",
       "3     1464.000000  \n",
       "4       43.358025  \n",
       "...           ...  \n",
       "8511     0.037385  \n",
       "8512  4722.666667  \n",
       "8513  3602.666667  \n",
       "8514   202.172840  \n",
       "8515     0.000000  \n",
       "\n",
       "[8516 rows x 213 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_frequency.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>710.769231</td>\n",
       "      <td>628.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3140.437500</td>\n",
       "      <td>127.600000</td>\n",
       "      <td>1041.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>968.666667</td>\n",
       "      <td>894.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>5249.000000</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>8081.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>8070.530612</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1078.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>757.500000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>7081.416667</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>264.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>413.909091</td>\n",
       "      <td>409.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>832.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>342.857143</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>205.142857</td>\n",
       "      <td>11207.836735</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2281.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>14282.775510</td>\n",
       "      <td>169.142857</td>\n",
       "      <td>46.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>361.489796</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>2186.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.285714</td>\n",
       "      <td>996.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>-45.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2       3           4      5         6          7  \\\n",
       "0     0.0  14.0   710.769231   628.0  153.204817  556.0  0.996355   0.207174   \n",
       "1     0.0  10.0   968.666667   894.0  266.399867  932.0  0.979352   0.388359   \n",
       "2     0.0  11.0   797.000000   780.0  251.329664  794.0  0.260470  -1.002325   \n",
       "3     2.0  13.0   757.500000   755.0    8.986100   26.0  0.048579  -1.449012   \n",
       "4     0.0  23.0   413.909091   409.0   82.344017  426.0  3.023659  10.404884   \n",
       "...   ...   ...          ...     ...         ...    ...       ...        ...   \n",
       "2125  1.0   9.0  1071.250000  1062.0   36.509417  118.0  1.263183   0.543003   \n",
       "2126  1.0   8.0  1196.000000  1202.0   33.839959  102.0 -0.454057  -1.036905   \n",
       "2127  3.0  16.0   595.600000   590.0   23.734082   82.0  0.371174  -0.657132   \n",
       "2128  1.0   8.0  1080.285714   996.0  180.470587  448.0  0.587475  -1.363827   \n",
       "2129  3.0  25.0   391.250000   390.0    2.569857    8.0  0.605786  -0.869886   \n",
       "\n",
       "               8         9  ...       203        204   205   206         207  \\\n",
       "0     459.037295  1.000000  ...  0.928571 -10.000000  10.0   9.0  146.000000   \n",
       "1     398.464564  1.000000  ...  0.600000  64.000000   7.0   7.0  140.500000   \n",
       "2     340.802438  1.000000  ...  1.000000  26.000000   9.0   7.0  154.285714   \n",
       "3     412.324324  1.000000  ...  1.000000  -4.000000  12.0  12.0  108.500000   \n",
       "4     168.041577  0.956522  ...  0.083333   0.022262  11.0  12.0    0.044242   \n",
       "...          ...       ...  ...       ...        ...   ...   ...         ...   \n",
       "2125  364.303573  0.888889  ...  0.777778   0.000000   9.0   8.0  342.857143   \n",
       "2126  181.876516  1.000000  ...  1.000000 -26.000000   8.0   7.0  137.666667   \n",
       "2127  137.696567  1.000000  ...  1.000000  -8.000000  16.0  14.0  102.714286   \n",
       "2128  561.988537  1.000000  ...  1.000000  18.000000   8.0   5.0   62.400000   \n",
       "2129  654.123072  0.400000  ...  0.240000   4.000000   0.0   0.0    0.044242   \n",
       "\n",
       "               208         209           210         211          212  \n",
       "0       729.000000   78.250000   3140.437500  127.600000  1041.440000  \n",
       "1     15314.750000  -27.000000   5249.000000  112.285714  8081.632653  \n",
       "2      1944.489796   18.571429   8070.530612  131.111111  1078.320988  \n",
       "3      6122.750000   46.500000   7081.416667  121.833333   264.305556  \n",
       "4         0.044242  -50.000000      0.000000   45.818182   832.330579  \n",
       "...            ...         ...           ...         ...          ...  \n",
       "2125   2843.265306  205.142857  11207.836735   96.000000  2281.142857  \n",
       "2126    228.555556   87.714286  14282.775510  169.142857    46.693878  \n",
       "2127   1270.061224    7.285714    361.489796   90.400000  2186.240000  \n",
       "2128     51.840000  -45.200000      0.960000  101.000000  5002.000000  \n",
       "2129      0.044242    0.043021      0.043021    0.037385     0.037385  \n",
       "\n",
       "[2130 rows x 213 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_frequency.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 0.9)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4258, 51)\n",
      "Vallidation: (4258, 51)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 5, max_features= 'sqrt', n_estimators= 1000)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 50)\n",
    "knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 100, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "# xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.1,max_depth= 5,min_child_weight= 1,n_estimators= 1000)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 5,max_features= 'sqrt',splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features='sqrt')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "svc_clf.fit(x_train, y_train)\n",
    "# xgb_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    knn_clf.predict_proba(x_val),\n",
    "    svc_clf.predict_proba(x_val),\n",
    "    # xgb_clf.predict_proba(x_val),\n",
    "    dt_clf.predict_proba(x_val)\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    knn_clf.predict_proba(x_test),\n",
    "    svc_clf.predict_proba(x_test),\n",
    "    # xgb_clf.predict_proba(x_test),\n",
    "    dt_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4258, 20)\n",
      "X_test_meta:(2130, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.948, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.942, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.945, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.949, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.940, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.948, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.949, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.940, test=0.944) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.952, test=0.928) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.971, test=0.934) total time=   1.4s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.964, test=0.934) total time=   1.3s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.973, test=0.927) total time=   1.4s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.955, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.951, test=0.940) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.957, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.953, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.951, test=0.938) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.962, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.959, test=0.937) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.953, test=0.936) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.927) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.985, test=0.936) total time=   1.9s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.983, test=0.936) total time=   1.8s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.987, test=0.927) total time=   1.6s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.963, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.963, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.965, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.967, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.965, test=0.938) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.967, test=0.921) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.969, test=0.935) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.968, test=0.937) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.971, test=0.924) total time=   0.2s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.996, test=0.936) total time=   1.9s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.996, test=0.937) total time=   2.2s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.998, test=0.926) total time=   2.2s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.949, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.941, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.952, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.960, test=0.933) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.949, test=0.939) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.958, test=0.931) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.972, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.966, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.971, test=0.926) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.930) total time=   1.4s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.934) total time=   1.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.919) total time=   1.2s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.959, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.954, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.963, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.970, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.965, test=0.939) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.973, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.986, test=0.936) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.983, test=0.935) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.988, test=0.925) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.932) total time=   1.3s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.932) total time=   1.5s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.918) total time=   1.2s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.969, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.969, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.970, test=0.923) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.982, test=0.933) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.986, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.986, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.997, test=0.935) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.996, test=0.936) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.998, test=0.925) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.932) total time=   1.5s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.936) total time=   1.4s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.918) total time=   1.4s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.973, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.968, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.974, test=0.922) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.932) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.927) total time=   0.8s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.933) total time=   0.8s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.915) total time=   0.9s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.987, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.988, test=0.933) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.991, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.939) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.940) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.935) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.924) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.934) total time=   0.8s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.931) total time=   0.7s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.921) total time=   0.8s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.997, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.997, test=0.931) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.999, test=0.917) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.934) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.930) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.932) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.918) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.931) total time=   0.8s\n",
      "[CV 2/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.935) total time=   0.8s\n",
      "[CV 3/3] END gamma=0, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.918) total time=   0.7s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.234, test=0.239) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.366, test=0.365) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.551, test=0.555) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.234, test=0.239) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.366, test=0.365) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.551, test=0.555) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.234, test=0.239) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.366, test=0.365) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.551, test=0.555) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.234, test=0.239) total time=   0.5s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.366, test=0.365) total time=   0.6s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.551, test=0.555) total time=   0.5s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.369, test=0.368) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.022, test=0.012) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.924, test=0.911) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.369, test=0.368) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.022, test=0.012) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.924, test=0.911) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.369, test=0.368) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.022, test=0.012) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.924, test=0.911) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.369, test=0.368) total time=   0.4s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.022, test=0.012) total time=   0.4s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.924, test=0.911) total time=   0.5s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.543, test=0.546) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.217, test=0.216) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.845, test=0.829) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.543, test=0.546) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.217, test=0.216) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.845, test=0.829) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.543, test=0.546) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.217, test=0.216) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.845, test=0.829) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.543, test=0.546) total time=   0.4s\n",
      "[CV 2/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.217, test=0.216) total time=   0.4s\n",
      "[CV 3/3] END gamma=0, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.845, test=0.829) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.948, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.941, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.945, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.949, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.940, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.948, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.949, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.940, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.952, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.970, test=0.934) total time=   1.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.963, test=0.934) total time=   1.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.973, test=0.927) total time=   1.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.954, test=0.933) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.951, test=0.940) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.957, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.953, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.951, test=0.938) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.962, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.959, test=0.936) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.953, test=0.937) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.927) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.986, test=0.935) total time=   1.4s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.983, test=0.934) total time=   1.4s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.987, test=0.928) total time=   1.3s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.963, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.963, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.965, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.966, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.965, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.966, test=0.921) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.969, test=0.935) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.968, test=0.938) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.971, test=0.924) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.995, test=0.936) total time=   2.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.995, test=0.939) total time=   1.9s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.998, test=0.926) total time=   2.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.949, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.941, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.952, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.959, test=0.933) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.949, test=0.939) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.959, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.972, test=0.937) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.934) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.973, test=0.925) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.997, test=0.930) total time=   0.7s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.994, test=0.935) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.998, test=0.922) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.959, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.953, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.962, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.970, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.966, test=0.938) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.973, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.985, test=0.934) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.983, test=0.936) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.987, test=0.925) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.999, test=0.931) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.997, test=0.938) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.999, test=0.925) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.968, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.969, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.969, test=0.924) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.981, test=0.938) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.983, test=0.937) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.986, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.996, test=0.937) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.995, test=0.940) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.998, test=0.925) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.999, test=0.935) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.999, test=0.937) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.925) total time=   0.7s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.973, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.966, test=0.938) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.973, test=0.922) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.932) total time=   0.5s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.934) total time=   0.5s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.918) total time=   0.4s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.988, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.989, test=0.931) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.992, test=0.915) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.936) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.936) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.936) total time=   0.5s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.930) total time=   0.4s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.918) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.996, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.997, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.936) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.936) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.936) total time=   0.5s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.937) total time=   0.4s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.918) total time=   0.4s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.234, test=0.239) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.366, test=0.365) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.551, test=0.555) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.234, test=0.239) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.366, test=0.365) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.551, test=0.555) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.234, test=0.239) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.366, test=0.365) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.551, test=0.555) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.234, test=0.239) total time=   0.4s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.366, test=0.365) total time=   0.5s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.551, test=0.555) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.547, test=0.551) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.022, test=0.012) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.917, test=0.909) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.547, test=0.551) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.022, test=0.012) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.917, test=0.909) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.547, test=0.551) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.022, test=0.012) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.917, test=0.909) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.547, test=0.551) total time=   0.5s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.022, test=0.012) total time=   0.5s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.917, test=0.909) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.365, test=0.365) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.217, test=0.216) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.663, test=0.648) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.365, test=0.365) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.217, test=0.216) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.663, test=0.648) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.365, test=0.365) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.217, test=0.216) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.663, test=0.648) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.365, test=0.365) total time=   0.5s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.217, test=0.216) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.663, test=0.648) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.948, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.941, test=0.942) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.945, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.949, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.940, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.948, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.949, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.940, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.952, test=0.928) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.970, test=0.935) total time=   1.3s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.963, test=0.934) total time=   1.3s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.973, test=0.927) total time=   1.2s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.954, test=0.933) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.951, test=0.940) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.957, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.953, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.951, test=0.939) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.962, test=0.927) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.959, test=0.937) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.953, test=0.937) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.927) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.935) total time=   1.5s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.983, test=0.936) total time=   1.3s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.987, test=0.927) total time=   1.9s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.964, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.963, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.964, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.966, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.965, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.966, test=0.922) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.968, test=0.935) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.968, test=0.937) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.970, test=0.923) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.994, test=0.935) total time=   2.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.995, test=0.938) total time=   2.4s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.996, test=0.926) total time=   2.4s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.949, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.941, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.952, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.959, test=0.934) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.950, test=0.939) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.959, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.971, test=0.936) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.964, test=0.935) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.986, test=0.935) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.933) total time=   0.7s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.988, test=0.922) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.959, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.954, test=0.934) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.963, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.969, test=0.936) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.966, test=0.939) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.973, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.985, test=0.936) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.983, test=0.937) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.987, test=0.927) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.990, test=0.935) total time=   0.7s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.989, test=0.936) total time=   0.7s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.992, test=0.926) total time=   0.7s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.969, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.968, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.969, test=0.924) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.981, test=0.935) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.984, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.985, test=0.929) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.995, test=0.938) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.994, test=0.939) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.996, test=0.925) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.995, test=0.937) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.995, test=0.939) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.997, test=0.925) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.973, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.970, test=0.940) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.975, test=0.924) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.999, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.996, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.996, test=0.919) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.999, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.996, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.996, test=0.919) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.999, test=0.932) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.996, test=0.936) total time=   0.5s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.996, test=0.919) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.986, test=0.935) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.988, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.992, test=0.917) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.998, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.998, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.999, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.998, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.998, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.999, test=0.918) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.998, test=0.937) total time=   0.4s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.998, test=0.936) total time=   0.5s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.999, test=0.918) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.998, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.997, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.999, test=0.921) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.999, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.998, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.999, test=0.930) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.998, test=0.936) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.999, test=0.930) total time=   0.5s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.998, test=0.936) total time=   0.5s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.920) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.234, test=0.239) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.366, test=0.365) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=10;, score=(train=0.551, test=0.555) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.234, test=0.239) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.366, test=0.365) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=50;, score=(train=0.551, test=0.555) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.234, test=0.239) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.366, test=0.365) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.551, test=0.555) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.234, test=0.239) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.366, test=0.365) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.551, test=0.555) total time=   0.7s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.547, test=0.551) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.022, test=0.012) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=10;, score=(train=0.531, test=0.538) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.547, test=0.551) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.022, test=0.012) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=50;, score=(train=0.531, test=0.538) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.547, test=0.551) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.022, test=0.012) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.531, test=0.538) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.547, test=0.551) total time=   0.7s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.022, test=0.012) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.531, test=0.538) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.365, test=0.365) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.217, test=0.216) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=10;, score=(train=0.555, test=0.557) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.365, test=0.365) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.217, test=0.216) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=50;, score=(train=0.555, test=0.557) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.365, test=0.365) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.217, test=0.216) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.555, test=0.557) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.365, test=0.365) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.217, test=0.216) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=10, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.555, test=0.557) total time=   0.7s\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = XGBClassifier()\n",
    "params = {\n",
    "    'n_estimators': [10,50,100,1000],\n",
    "    'learning_rate': [0.01,0.1,1,10],\n",
    "    'max_depth': [3,4,5],\n",
    "    'min_child_weight':[1],\n",
    "    'gamma':[0,0.1,0.2],\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9351811597799151"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.889888</td>\n",
       "      <td>0.906178</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.975668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.983568</td>\n",
       "      <td>0.982005</td>\n",
       "      <td>0.973248</td>\n",
       "      <td>0.977607</td>\n",
       "      <td>0.984467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.974648</td>\n",
       "      <td>0.919101</td>\n",
       "      <td>0.957845</td>\n",
       "      <td>0.938073</td>\n",
       "      <td>0.989318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.959155</td>\n",
       "      <td>0.926407</td>\n",
       "      <td>0.889813</td>\n",
       "      <td>0.907741</td>\n",
       "      <td>0.968225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.930345</td>\n",
       "      <td>0.931771</td>\n",
       "      <td>0.929350</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.937559</td>\n",
       "      <td>0.937559</td>\n",
       "      <td>0.937559</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.937554</td>\n",
       "      <td>0.937921</td>\n",
       "      <td>0.937559</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.957746  0.889888   0.906178  0.897959     0.975668\n",
       "1            SB  0.983568  0.982005   0.973248  0.977607     0.984467\n",
       "2            SR  0.974648  0.919101   0.957845  0.938073     0.989318\n",
       "3          GSVT  0.959155  0.926407   0.889813  0.907741     0.968225\n",
       "4     macro avg       NaN  0.930345   0.931771  0.929350          NaN\n",
       "5     micro avg       NaN  0.937559   0.937559  0.937559          NaN\n",
       "6  weighted avg       NaN  0.937554   0.937921  0.937559          NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"./Result/Blending_XGB_PCA.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
