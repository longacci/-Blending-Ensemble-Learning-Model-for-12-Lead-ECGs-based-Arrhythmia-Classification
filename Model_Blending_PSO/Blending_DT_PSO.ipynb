{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>181</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>193</th>\n",
       "      <th>197</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>209</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>84.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>437.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>2383.209877</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>-0.338865</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>950.222222</td>\n",
       "      <td>991.309467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>135.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>312.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>2193.439446</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>0.095966</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>912.932251</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>329.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.109375</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.217133</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>593.733333</td>\n",
       "      <td>338.632833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>95.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045933</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-0.026782</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>420.181818</td>\n",
       "      <td>325.369999</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>427.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>736.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>-0.285584</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>877.512514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>136.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>342.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>22201.000000</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>481.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>2913.580247</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>-0.625647</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1091.750000</td>\n",
       "      <td>267.711052</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>155.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>341.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>2954.775510</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.385381</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>654.571429</td>\n",
       "      <td>484.863590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>449.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>-0.320207</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>704.569046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>88.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>463.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.358025</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.218367</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1041.000000</td>\n",
       "      <td>1946.010560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     2           5         7         8           9    11    12  \\\n",
       "0       0.0  10.0  274.986868 -0.319753 -1.432466  325.821586  84.0   9.0   \n",
       "1       0.0  17.0  104.913059  0.158313 -0.696295  336.569414  32.0  10.0   \n",
       "2       3.0  16.0    4.687572  0.396421 -0.312612   94.909877  -2.0  16.0   \n",
       "3       3.0  23.0    3.591772 -0.021014 -0.856142  254.059787   9.0  10.0   \n",
       "4       1.0   9.0   25.118469 -0.276816 -1.271399  461.130814  -1.0   9.0   \n",
       "...     ...   ...         ...       ...       ...         ...   ...   ...   \n",
       "8511    3.0  16.0   51.114860  2.153820  2.645687  365.256750  -2.0  15.0   \n",
       "8512    1.0   9.0    5.894913 -0.311206 -1.184514  358.414529  -5.0   9.0   \n",
       "8513    2.0  15.0  107.653355  0.475616  0.784000  180.045117  20.0  14.0   \n",
       "8514    1.0   9.0   24.535688 -0.263431 -1.567800  251.455499  -1.0   9.0   \n",
       "8515    1.0   9.0    8.242421  0.214800 -1.575835  505.203302  -2.0   9.0   \n",
       "\n",
       "        13          14  ...           181         186       187        193  \\\n",
       "0      9.0  437.750000  ...   2383.209877  650.000000 -0.338865   9.000000   \n",
       "1     16.0  312.222222  ...   2193.439446  384.000000  0.095966   3.000000   \n",
       "2     15.0  329.600000  ...     49.109375   14.000000  0.217133  15.000000   \n",
       "3      0.0    0.036070  ...      0.045933   14.000000 -0.026782   6.000000   \n",
       "4      8.0  427.250000  ...    736.000000   72.000000 -0.285584   8.000000   \n",
       "...    ...         ...  ...           ...         ...       ...        ...   \n",
       "8511  15.0  342.666667  ...  22201.000000    0.003006  0.003006   0.003006   \n",
       "8512   8.0  481.250000  ...   2913.580247   24.000000 -0.625647   8.000000   \n",
       "8513  14.0  341.714286  ...   2954.775510  136.000000  0.385381  12.000000   \n",
       "8514   8.0  449.750000  ...     24.000000   64.000000 -0.320207   7.000000   \n",
       "8515   8.0  463.500000  ...     11.358025   22.000000  0.218367   7.000000   \n",
       "\n",
       "              197          203       204         205           209         212  \n",
       "0      950.222222   991.309467  1.000000  172.000000  10656.395062  135.800000  \n",
       "1      574.500000   912.932251  0.882353  -15.000000   3944.000000   -1.066667  \n",
       "2      593.733333   338.632833  1.000000   -4.000000   2058.773333   95.500000  \n",
       "3      420.181818   325.369999  0.739130   -9.000000   1120.888889   12.000000  \n",
       "4     1068.750000   877.512514  1.000000    2.000000    671.000000  136.444444  \n",
       "...           ...          ...       ...         ...           ...         ...  \n",
       "8511     0.003757     0.003757  0.003757    0.022262      0.044242    0.037385  \n",
       "8512  1091.750000   267.711052  0.888889   -3.000000   1294.530612  155.333333  \n",
       "8513   654.571429   484.863590  1.000000   -4.000000   2213.551020  104.000000  \n",
       "8514  1075.000000   704.569046  1.000000   14.000000   4933.551020   88.222222  \n",
       "8515  1041.000000  1946.010560  1.000000    0.000000    350.000000  150.000000  \n",
       "\n",
       "[8516 rows x 99 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./data_train_pso.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>180</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>192</th>\n",
       "      <th>196</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>208</th>\n",
       "      <th>211</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>358.307692</td>\n",
       "      <td>...</td>\n",
       "      <td>92.686391</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>10.0</td>\n",
       "      <td>710.615385</td>\n",
       "      <td>794.307350</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>127.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>532.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>7281.937500</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.965488</td>\n",
       "      <td>4.0</td>\n",
       "      <td>968.222222</td>\n",
       "      <td>900.143486</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>112.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2661.728395</td>\n",
       "      <td>784.0</td>\n",
       "      <td>0.270281</td>\n",
       "      <td>6.0</td>\n",
       "      <td>796.400000</td>\n",
       "      <td>1236.308241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>131.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>322.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>787.638889</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.014314</td>\n",
       "      <td>12.0</td>\n",
       "      <td>757.333333</td>\n",
       "      <td>803.828940</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>121.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>223.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>1288.640000</td>\n",
       "      <td>398.0</td>\n",
       "      <td>1.761865</td>\n",
       "      <td>16.0</td>\n",
       "      <td>396.173913</td>\n",
       "      <td>316.582423</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>45.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>438.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>4051.918367</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>856.643246</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>463.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-0.457057</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>746.905354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>169.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>335.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>739.982222</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.348673</td>\n",
       "      <td>14.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>333.718093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>90.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>431.750000</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1080.571429</td>\n",
       "      <td>588.205240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045933</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.989051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>1293.658260</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1           4         6          7           8    10    11  \\\n",
       "0     0.0  14.0  153.204817  0.996355   0.207174  459.037295 -28.0  13.0   \n",
       "1     0.0  10.0  266.399867  0.979352   0.388359  398.464564 -60.0  10.0   \n",
       "2     0.0  11.0  251.329664  0.260470  -1.002325  340.802438 -52.0   8.0   \n",
       "3     2.0  13.0    8.986100  0.048579  -1.449012  412.324324  -5.0  12.0   \n",
       "4     0.0  23.0   82.344017  3.023659  10.404884  168.041577   7.0   9.0   \n",
       "...   ...   ...         ...       ...        ...         ...   ...   ...   \n",
       "2125  1.0   9.0   36.509417  1.263183   0.543003  364.303573 -18.0   9.0   \n",
       "2126  1.0   8.0   33.839959 -0.454057  -1.036905  181.876516   0.0   8.0   \n",
       "2127  3.0  16.0   23.734082  0.371174  -0.657132  137.696567 -10.0  16.0   \n",
       "2128  1.0   8.0  180.470587  0.587475  -1.363827  561.988537  12.0   8.0   \n",
       "2129  3.0  25.0    2.569857  0.605786  -0.869886  654.123072  46.0   0.0   \n",
       "\n",
       "        12          13  ...          180    185       186   192          196  \\\n",
       "0     13.0  358.307692  ...    92.686391  554.0  0.999941  10.0   710.615385   \n",
       "1      6.0  532.800000  ...  7281.937500  932.0  0.965488   4.0   968.222222   \n",
       "2      7.0  403.000000  ...  2661.728395  784.0  0.270281   6.0   796.400000   \n",
       "3     12.0  322.333333  ...   787.638889   26.0 -0.014314  12.0   757.333333   \n",
       "4     20.0  223.750000  ...  1288.640000  398.0  1.761865  16.0   396.173913   \n",
       "...    ...         ...  ...          ...    ...       ...   ...          ...   \n",
       "2125   8.0  438.571429  ...  4051.918367  118.0  1.263183   8.0  1071.250000   \n",
       "2126   7.0  463.142857  ...    10.750000  104.0 -0.457057   5.0  1196.000000   \n",
       "2127  15.0  335.733333  ...   739.982222   82.0  0.348673  14.0   595.600000   \n",
       "2128   7.0  462.000000  ...   431.750000  448.0  0.587475   5.0  1080.571429   \n",
       "2129   5.0    0.036070  ...     0.045933   10.0  0.989051   0.0   391.250000   \n",
       "\n",
       "              202       203        204           208         211  \n",
       "0      794.307350  0.928571 -10.000000    729.000000  127.600000  \n",
       "1      900.143486  0.600000  64.000000  15314.750000  112.285714  \n",
       "2     1236.308241  1.000000  26.000000   1944.489796  131.111111  \n",
       "3      803.828940  1.000000  -4.000000   6122.750000  121.833333  \n",
       "4      316.582423  0.083333   0.022262      0.044242   45.818182  \n",
       "...           ...       ...        ...           ...         ...  \n",
       "2125   856.643246  0.777778   0.000000   2843.265306   96.000000  \n",
       "2126   746.905354  1.000000 -26.000000    228.555556  169.142857  \n",
       "2127   333.718093  1.000000  -8.000000   1270.061224   90.400000  \n",
       "2128   588.205240  1.000000  18.000000     51.840000  101.000000  \n",
       "2129  1293.658260  0.240000   4.000000      0.044242    0.037385  \n",
       "\n",
       "[2130 rows x 99 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./data_test_pso.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4258, 98)\n",
      "Vallidation: (4258, 98)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 5, max_features= 'sqrt', n_estimators= 1000)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 50)\n",
    "knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 100, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.1,max_depth= 5,min_child_weight= 1,n_estimators= 1000)\n",
    "# dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 5,max_features= 'sqrt',splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "svc_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "# dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    knn_clf.predict_proba(x_val),\n",
    "    svc_clf.predict_proba(x_val),\n",
    "    xgb_clf.predict_proba(x_val),\n",
    "    # dt_clf.predict_proba(x_val)\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    knn_clf.predict_proba(x_test),\n",
    "    svc_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    # dt_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4258, 20)\n",
      "X_test_meta:(2130, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.953, test=0.943) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.944, test=0.949) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.957, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.938, test=0.943) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.836, test=0.830) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.947, test=0.939) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, splitter=best;, score=(train=0.956, test=0.956) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, splitter=best;, score=(train=0.922, test=0.929) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, splitter=best;, score=(train=0.949, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, splitter=random;, score=(train=0.928, test=0.927) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, splitter=random;, score=(train=0.907, test=0.913) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, splitter=random;, score=(train=0.896, test=0.883) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.957, test=0.946) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.956, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.955, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.912, test=0.920) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.922, test=0.930) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.954, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=(train=0.961, test=0.953) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=(train=0.954, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=(train=0.954, test=0.943) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=(train=0.952, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=(train=0.951, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=(train=0.941, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.961, test=0.946) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.963, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.960, test=0.941) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.939, test=0.942) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.953, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.959, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=(train=0.959, test=0.949) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=(train=0.961, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=(train=0.941, test=0.944) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=(train=0.955, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=(train=0.957, test=0.949) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.925, test=0.901) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.894, test=0.890) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.949, test=0.931) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.921, test=0.926) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.845, test=0.838) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.930, test=0.927) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=best;, score=(train=0.942, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=best;, score=(train=0.893, test=0.895) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=best;, score=(train=0.949, test=0.937) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=random;, score=(train=0.901, test=0.894) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=random;, score=(train=0.896, test=0.911) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, splitter=random;, score=(train=0.894, test=0.881) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.949, test=0.946) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.953, test=0.951) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.950, test=0.936) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.939, test=0.937) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.954, test=0.961) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.954, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=(train=0.953, test=0.940) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=(train=0.948, test=0.948) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=(train=0.958, test=0.934) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=(train=0.901, test=0.891) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=(train=0.933, test=0.937) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=(train=0.946, test=0.939) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.954, test=0.944) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.952, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.957, test=0.932) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.948, test=0.944) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.947, test=0.950) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.959, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=(train=0.961, test=0.947) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=(train=0.954, test=0.949) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=(train=0.964, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=(train=0.959, test=0.956) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=(train=0.906, test=0.923) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=(train=0.951, test=0.934) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.932, test=0.931) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.936, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=best;, score=(train=0.948, test=0.930) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.936, test=0.938) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.908, test=0.922) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=random;, score=(train=0.947, test=0.937) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=best;, score=(train=0.954, test=0.953) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=best;, score=(train=0.949, test=0.952) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=best;, score=(train=0.947, test=0.936) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=random;, score=(train=0.936, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=random;, score=(train=0.921, test=0.932) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, splitter=random;, score=(train=0.948, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.946, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.956, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.952, test=0.939) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.948, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.945, test=0.949) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.953, test=0.943) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=best;, score=(train=0.959, test=0.954) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=best;, score=(train=0.952, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=best;, score=(train=0.954, test=0.939) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=random;, score=(train=0.932, test=0.932) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=random;, score=(train=0.936, test=0.944) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, splitter=random;, score=(train=0.950, test=0.933) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.955, test=0.946) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.959, test=0.949) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.959, test=0.939) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.955, test=0.948) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.951, test=0.946) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.957, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=best;, score=(train=0.961, test=0.940) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=best;, score=(train=0.957, test=0.952) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=best;, score=(train=0.964, test=0.943) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=random;, score=(train=0.954, test=0.944) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=random;, score=(train=0.951, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, splitter=random;, score=(train=0.949, test=0.939) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:542: FitFailedWarning: \n",
      "54 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.94574983 0.90417126 0.93752494 0.9076985\n",
      "        nan        nan 0.94950769 0.93119088 0.9485664  0.94480822\n",
      "        nan        nan 0.94715862 0.94715961 0.95138628 0.94809874\n",
      "        nan        nan 0.90723498 0.8968931  0.92320006 0.8954911\n",
      "        nan        nan 0.94433956 0.94716077 0.94058254 0.92227135\n",
      "        nan        nan 0.93987699 0.94715911 0.94668847 0.93776001\n",
      "        nan        nan 0.93565164 0.93236128 0.94692205 0.93166136\n",
      "        nan        nan 0.94222887 0.9466883  0.94598226 0.93635619\n",
      "        nan        nan 0.94457464 0.94715812 0.94504577 0.9455146 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.95126842 0.90711968 0.94222801 0.91040607\n",
      "        nan        nan 0.95620023 0.92919004 0.95643547 0.94821562\n",
      "        nan        nan 0.96136674 0.95056233 0.96054465 0.95079736\n",
      "        nan        nan 0.92273398 0.8988988  0.92766724 0.89713526\n",
      "        nan        nan 0.95079832 0.94880107 0.95314706 0.92672314\n",
      "        nan        nan 0.95432122 0.95150267 0.95960556 0.93858856\n",
      "        nan        nan 0.93870283 0.93024956 0.95009442 0.93494605\n",
      "        nan        nan 0.95161983 0.94856732 0.95479145 0.93952476\n",
      "        nan        nan 0.9577263  0.9543213  0.96077972 0.95138596]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = DecisionTreeClassifier()\n",
    "params = {\n",
    "    'criterion':['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [3,4,5],\n",
    "    'splitter':['best', 'random'],\n",
    "    'max_features':['auto', 'sqrt', 'log2']\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'log2',\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9513862834039709"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.956338</td>\n",
       "      <td>0.912360</td>\n",
       "      <td>0.882609</td>\n",
       "      <td>0.897238</td>\n",
       "      <td>0.967953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.987793</td>\n",
       "      <td>0.976864</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.983182</td>\n",
       "      <td>0.994083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.984507</td>\n",
       "      <td>0.964045</td>\n",
       "      <td>0.961883</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.989911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.968075</td>\n",
       "      <td>0.919913</td>\n",
       "      <td>0.932018</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.981415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.942327</td>\n",
       "      <td>0.941523</td>\n",
       "      <td>0.943295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.948584</td>\n",
       "      <td>0.948961</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.956338  0.912360   0.882609  0.897238     0.967953\n",
       "1            SB  0.987793  0.976864   0.989583  0.983182     0.994083\n",
       "2            SR  0.984507  0.964045   0.961883  0.962963     0.989911\n",
       "3          GSVT  0.968075  0.919913   0.932018  0.925926     0.981415\n",
       "4     macro avg       NaN  0.942327   0.941523  0.943295          NaN\n",
       "5     micro avg       NaN  0.948357   0.948357  0.948357          NaN\n",
       "6  weighted avg       NaN  0.948584   0.948961  0.948357          NaN"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"./Result/Blending_DT_pso.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
