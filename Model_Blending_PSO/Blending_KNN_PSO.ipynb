{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>181</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>193</th>\n",
       "      <th>197</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>209</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>84.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>437.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>2383.209877</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>-0.338865</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>950.222222</td>\n",
       "      <td>991.309467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>135.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>312.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>2193.439446</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>0.095966</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>912.932251</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>329.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.109375</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.217133</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>593.733333</td>\n",
       "      <td>338.632833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>95.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045933</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-0.026782</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>420.181818</td>\n",
       "      <td>325.369999</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>427.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>736.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>-0.285584</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>877.512514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>136.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>342.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>22201.000000</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>481.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>2913.580247</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>-0.625647</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1091.750000</td>\n",
       "      <td>267.711052</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>155.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>341.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>2954.775510</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.385381</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>654.571429</td>\n",
       "      <td>484.863590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>449.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>-0.320207</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>704.569046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>88.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>463.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.358025</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.218367</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1041.000000</td>\n",
       "      <td>1946.010560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     2           5         7         8           9    11    12  \\\n",
       "0       0.0  10.0  274.986868 -0.319753 -1.432466  325.821586  84.0   9.0   \n",
       "1       0.0  17.0  104.913059  0.158313 -0.696295  336.569414  32.0  10.0   \n",
       "2       3.0  16.0    4.687572  0.396421 -0.312612   94.909877  -2.0  16.0   \n",
       "3       3.0  23.0    3.591772 -0.021014 -0.856142  254.059787   9.0  10.0   \n",
       "4       1.0   9.0   25.118469 -0.276816 -1.271399  461.130814  -1.0   9.0   \n",
       "...     ...   ...         ...       ...       ...         ...   ...   ...   \n",
       "8511    3.0  16.0   51.114860  2.153820  2.645687  365.256750  -2.0  15.0   \n",
       "8512    1.0   9.0    5.894913 -0.311206 -1.184514  358.414529  -5.0   9.0   \n",
       "8513    2.0  15.0  107.653355  0.475616  0.784000  180.045117  20.0  14.0   \n",
       "8514    1.0   9.0   24.535688 -0.263431 -1.567800  251.455499  -1.0   9.0   \n",
       "8515    1.0   9.0    8.242421  0.214800 -1.575835  505.203302  -2.0   9.0   \n",
       "\n",
       "        13          14  ...           181         186       187        193  \\\n",
       "0      9.0  437.750000  ...   2383.209877  650.000000 -0.338865   9.000000   \n",
       "1     16.0  312.222222  ...   2193.439446  384.000000  0.095966   3.000000   \n",
       "2     15.0  329.600000  ...     49.109375   14.000000  0.217133  15.000000   \n",
       "3      0.0    0.036070  ...      0.045933   14.000000 -0.026782   6.000000   \n",
       "4      8.0  427.250000  ...    736.000000   72.000000 -0.285584   8.000000   \n",
       "...    ...         ...  ...           ...         ...       ...        ...   \n",
       "8511  15.0  342.666667  ...  22201.000000    0.003006  0.003006   0.003006   \n",
       "8512   8.0  481.250000  ...   2913.580247   24.000000 -0.625647   8.000000   \n",
       "8513  14.0  341.714286  ...   2954.775510  136.000000  0.385381  12.000000   \n",
       "8514   8.0  449.750000  ...     24.000000   64.000000 -0.320207   7.000000   \n",
       "8515   8.0  463.500000  ...     11.358025   22.000000  0.218367   7.000000   \n",
       "\n",
       "              197          203       204         205           209         212  \n",
       "0      950.222222   991.309467  1.000000  172.000000  10656.395062  135.800000  \n",
       "1      574.500000   912.932251  0.882353  -15.000000   3944.000000   -1.066667  \n",
       "2      593.733333   338.632833  1.000000   -4.000000   2058.773333   95.500000  \n",
       "3      420.181818   325.369999  0.739130   -9.000000   1120.888889   12.000000  \n",
       "4     1068.750000   877.512514  1.000000    2.000000    671.000000  136.444444  \n",
       "...           ...          ...       ...         ...           ...         ...  \n",
       "8511     0.003757     0.003757  0.003757    0.022262      0.044242    0.037385  \n",
       "8512  1091.750000   267.711052  0.888889   -3.000000   1294.530612  155.333333  \n",
       "8513   654.571429   484.863590  1.000000   -4.000000   2213.551020  104.000000  \n",
       "8514  1075.000000   704.569046  1.000000   14.000000   4933.551020   88.222222  \n",
       "8515  1041.000000  1946.010560  1.000000    0.000000    350.000000  150.000000  \n",
       "\n",
       "[8516 rows x 99 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./data_train_pso.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>180</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>192</th>\n",
       "      <th>196</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>208</th>\n",
       "      <th>211</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>358.307692</td>\n",
       "      <td>...</td>\n",
       "      <td>92.686391</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>10.0</td>\n",
       "      <td>710.615385</td>\n",
       "      <td>794.307350</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>127.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>532.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>7281.937500</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.965488</td>\n",
       "      <td>4.0</td>\n",
       "      <td>968.222222</td>\n",
       "      <td>900.143486</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>112.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2661.728395</td>\n",
       "      <td>784.0</td>\n",
       "      <td>0.270281</td>\n",
       "      <td>6.0</td>\n",
       "      <td>796.400000</td>\n",
       "      <td>1236.308241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>131.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>322.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>787.638889</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.014314</td>\n",
       "      <td>12.0</td>\n",
       "      <td>757.333333</td>\n",
       "      <td>803.828940</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>121.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>223.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>1288.640000</td>\n",
       "      <td>398.0</td>\n",
       "      <td>1.761865</td>\n",
       "      <td>16.0</td>\n",
       "      <td>396.173913</td>\n",
       "      <td>316.582423</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>45.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>438.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>4051.918367</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>856.643246</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>463.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-0.457057</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>746.905354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>169.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>335.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>739.982222</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.348673</td>\n",
       "      <td>14.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>333.718093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>90.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>431.750000</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1080.571429</td>\n",
       "      <td>588.205240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045933</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.989051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>1293.658260</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1           4         6          7           8    10    11  \\\n",
       "0     0.0  14.0  153.204817  0.996355   0.207174  459.037295 -28.0  13.0   \n",
       "1     0.0  10.0  266.399867  0.979352   0.388359  398.464564 -60.0  10.0   \n",
       "2     0.0  11.0  251.329664  0.260470  -1.002325  340.802438 -52.0   8.0   \n",
       "3     2.0  13.0    8.986100  0.048579  -1.449012  412.324324  -5.0  12.0   \n",
       "4     0.0  23.0   82.344017  3.023659  10.404884  168.041577   7.0   9.0   \n",
       "...   ...   ...         ...       ...        ...         ...   ...   ...   \n",
       "2125  1.0   9.0   36.509417  1.263183   0.543003  364.303573 -18.0   9.0   \n",
       "2126  1.0   8.0   33.839959 -0.454057  -1.036905  181.876516   0.0   8.0   \n",
       "2127  3.0  16.0   23.734082  0.371174  -0.657132  137.696567 -10.0  16.0   \n",
       "2128  1.0   8.0  180.470587  0.587475  -1.363827  561.988537  12.0   8.0   \n",
       "2129  3.0  25.0    2.569857  0.605786  -0.869886  654.123072  46.0   0.0   \n",
       "\n",
       "        12          13  ...          180    185       186   192          196  \\\n",
       "0     13.0  358.307692  ...    92.686391  554.0  0.999941  10.0   710.615385   \n",
       "1      6.0  532.800000  ...  7281.937500  932.0  0.965488   4.0   968.222222   \n",
       "2      7.0  403.000000  ...  2661.728395  784.0  0.270281   6.0   796.400000   \n",
       "3     12.0  322.333333  ...   787.638889   26.0 -0.014314  12.0   757.333333   \n",
       "4     20.0  223.750000  ...  1288.640000  398.0  1.761865  16.0   396.173913   \n",
       "...    ...         ...  ...          ...    ...       ...   ...          ...   \n",
       "2125   8.0  438.571429  ...  4051.918367  118.0  1.263183   8.0  1071.250000   \n",
       "2126   7.0  463.142857  ...    10.750000  104.0 -0.457057   5.0  1196.000000   \n",
       "2127  15.0  335.733333  ...   739.982222   82.0  0.348673  14.0   595.600000   \n",
       "2128   7.0  462.000000  ...   431.750000  448.0  0.587475   5.0  1080.571429   \n",
       "2129   5.0    0.036070  ...     0.045933   10.0  0.989051   0.0   391.250000   \n",
       "\n",
       "              202       203        204           208         211  \n",
       "0      794.307350  0.928571 -10.000000    729.000000  127.600000  \n",
       "1      900.143486  0.600000  64.000000  15314.750000  112.285714  \n",
       "2     1236.308241  1.000000  26.000000   1944.489796  131.111111  \n",
       "3      803.828940  1.000000  -4.000000   6122.750000  121.833333  \n",
       "4      316.582423  0.083333   0.022262      0.044242   45.818182  \n",
       "...           ...       ...        ...           ...         ...  \n",
       "2125   856.643246  0.777778   0.000000   2843.265306   96.000000  \n",
       "2126   746.905354  1.000000 -26.000000    228.555556  169.142857  \n",
       "2127   333.718093  1.000000  -8.000000   1270.061224   90.400000  \n",
       "2128   588.205240  1.000000  18.000000     51.840000  101.000000  \n",
       "2129  1293.658260  0.240000   4.000000      0.044242    0.037385  \n",
       "\n",
       "[2130 rows x 99 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./data_test_pso.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4258, 98)\n",
      "Vallidation: (4258, 98)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 5, max_features= 'sqrt', n_estimators= 1000)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 50)\n",
    "# knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 100, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.1,max_depth= 5,min_child_weight= 1,n_estimators= 1000)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 5,max_features= 'sqrt',splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=5, max_features=&#x27;sqrt&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features='sqrt')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "# knn_clf.fit(x_train, y_train)\n",
    "svc_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    # knn_clf.predict_proba(x_val),\n",
    "    svc_clf.predict_proba(x_val),\n",
    "    xgb_clf.predict_proba(x_val),\n",
    "    dt_clf.predict_proba(x_val)\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    # knn_clf.predict_proba(x_test),\n",
    "    svc_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    dt_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4258, 20)\n",
      "X_test_meta:(2130, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=(train=0.962, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=(train=0.968, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=(train=0.964, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=(train=0.965, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=(train=0.963, test=0.950) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=(train=0.963, test=0.955) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=3, weights=uniform;, score=(train=0.965, test=0.946) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.952) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.941) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=(train=0.965, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=(train=0.963, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=(train=0.966, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.957) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.943) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=(train=0.963, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=(train=0.964, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=(train=0.963, test=0.949) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=(train=0.963, test=0.956) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=3, weights=uniform;, score=(train=0.964, test=0.944) total time=   0.4s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.949) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.956) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.942) total time=   0.4s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=(train=0.962, test=0.949) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=(train=0.961, test=0.957) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=1, weights=uniform;, score=(train=0.963, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=(train=0.962, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=(train=0.960, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=2, weights=uniform;, score=(train=0.963, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=(train=0.962, test=0.948) total time=   0.3s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=(train=0.961, test=0.956) total time=   0.3s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=3, weights=uniform;, score=(train=0.964, test=0.946) total time=   0.3s\n",
      "[CV 1/3] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.951) total time=   0.4s\n",
      "[CV 2/3] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.954) total time=   0.4s\n",
      "[CV 3/3] END algorithm=auto, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.944) total time=   0.5s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.962, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.968, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.964, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.965, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.963, test=0.950) total time=   0.8s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.963, test=0.955) total time=   0.7s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.965, test=0.946) total time=   0.7s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.7s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.952) total time=   0.7s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.941) total time=   0.7s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.965, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.963, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.966, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.957) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.943) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.963, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.964, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.963, test=0.949) total time=   0.8s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.963, test=0.956) total time=   0.8s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.964, test=0.944) total time=   0.8s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.949) total time=   0.7s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.956) total time=   0.7s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.942) total time=   0.8s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.962, test=0.949) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.961, test=0.957) total time=   0.1s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.963, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.962, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.960, test=0.956) total time=   0.1s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.963, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.962, test=0.948) total time=   0.8s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.961, test=0.956) total time=   0.7s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.964, test=0.946) total time=   0.7s\n",
      "[CV 1/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.951) total time=   0.7s\n",
      "[CV 2/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.954) total time=   0.7s\n",
      "[CV 3/3] END algorithm=ball_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.944) total time=   0.7s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.962, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=(train=0.968, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.964, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=(train=0.965, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.963, test=0.950) total time=   0.2s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.963, test=0.955) total time=   0.2s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=uniform;, score=(train=0.965, test=0.946) total time=   0.3s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.2s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.952) total time=   0.2s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.941) total time=   0.2s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.965, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.963, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=(train=0.966, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.957) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.943) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.963, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=(train=0.964, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.963, test=0.949) total time=   0.3s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.963, test=0.956) total time=   0.2s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=uniform;, score=(train=0.964, test=0.944) total time=   0.3s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.949) total time=   0.2s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.956) total time=   0.2s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.942) total time=   0.2s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.962, test=0.949) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.961, test=0.957) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=uniform;, score=(train=0.963, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.962, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.960, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=uniform;, score=(train=0.963, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.962, test=0.948) total time=   0.3s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.961, test=0.956) total time=   0.2s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=uniform;, score=(train=0.964, test=0.946) total time=   0.3s\n",
      "[CV 1/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.951) total time=   0.2s\n",
      "[CV 2/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.954) total time=   0.2s\n",
      "[CV 3/3] END algorithm=kd_tree, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.944) total time=   0.2s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=(train=0.962, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=(train=0.968, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=(train=1.000, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=(train=0.964, test=0.955) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=(train=0.965, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=(train=0.963, test=0.950) total time=   0.4s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=(train=0.963, test=0.955) total time=   0.4s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=3, weights=uniform;, score=(train=0.965, test=0.946) total time=   0.4s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.950) total time=   0.4s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.952) total time=   0.4s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=4, p=3, weights=distance;, score=(train=1.000, test=0.941) total time=   0.4s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=(train=0.965, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=(train=0.963, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=(train=0.966, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.957) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=(train=1.000, test=0.943) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=(train=0.962, test=0.951) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=(train=0.963, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=(train=0.964, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=(train=1.000, test=0.944) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=(train=0.963, test=0.949) total time=   0.5s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=(train=0.963, test=0.956) total time=   0.4s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=3, weights=uniform;, score=(train=0.964, test=0.944) total time=   0.4s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.949) total time=   0.4s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.956) total time=   0.5s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=5, p=3, weights=distance;, score=(train=1.000, test=0.942) total time=   0.5s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=(train=0.962, test=0.949) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=(train=0.961, test=0.957) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=1, weights=uniform;, score=(train=0.963, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.952) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.954) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=1, weights=distance;, score=(train=1.000, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=(train=0.962, test=0.950) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=(train=0.960, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=2, weights=uniform;, score=(train=0.963, test=0.946) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=2, weights=distance;, score=(train=1.000, test=0.945) total time=   0.0s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=(train=0.962, test=0.948) total time=   0.4s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=(train=0.961, test=0.956) total time=   0.5s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=3, weights=uniform;, score=(train=0.964, test=0.946) total time=   0.5s\n",
      "[CV 1/3] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.951) total time=   1.0s\n",
      "[CV 2/3] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.954) total time=   0.8s\n",
      "[CV 3/3] END algorithm=brute, n_neighbors=6, p=3, weights=distance;, score=(train=1.000, test=0.944) total time=   0.6s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = KNeighborsClassifier()\n",
    "params = {\n",
    "    'n_neighbors': [4,5,6],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1,2,3]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto', 'n_neighbors': 6, 'p': 2, 'weights': 'distance'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9513852908382878"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.960563</td>\n",
       "      <td>0.905618</td>\n",
       "      <td>0.905618</td>\n",
       "      <td>0.905618</td>\n",
       "      <td>0.975074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.990610</td>\n",
       "      <td>0.988432</td>\n",
       "      <td>0.985897</td>\n",
       "      <td>0.987163</td>\n",
       "      <td>0.991864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.986854</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.970655</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>0.992285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.966197</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.978417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.945832</td>\n",
       "      <td>0.946062</td>\n",
       "      <td>0.945605</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.952113</td>\n",
       "      <td>0.952113</td>\n",
       "      <td>0.952113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.952104</td>\n",
       "      <td>0.952098</td>\n",
       "      <td>0.952113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.960563  0.905618   0.905618  0.905618     0.975074\n",
       "1            SB  0.990610  0.988432   0.985897  0.987163     0.991864\n",
       "2            SR  0.986854  0.966292   0.970655  0.968468     0.992285\n",
       "3          GSVT  0.966197  0.922078   0.922078  0.922078     0.978417\n",
       "4     macro avg       NaN  0.945832   0.946062  0.945605          NaN\n",
       "5     micro avg       NaN  0.952113   0.952113  0.952113          NaN\n",
       "6  weighted avg       NaN  0.952104   0.952098  0.952113          NaN"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"./Result/Blending_KNN_pso.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
