{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>782.0</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>252.222222</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>87.777778</td>\n",
       "      <td>10339.061728</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>4315.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6555.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>697.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>594.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>1360.782222</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>420.090909</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1504.888889</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>569.437500</td>\n",
       "      <td>136.444444</td>\n",
       "      <td>43.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>615.733333</td>\n",
       "      <td>596.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.500000</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1746.285714</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>4722.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>654.428571</td>\n",
       "      <td>648.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>2686.204082</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3602.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>101.142857</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>-10.750000</td>\n",
       "      <td>7259.937500</td>\n",
       "      <td>88.222222</td>\n",
       "      <td>202.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1041.250000</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2            3       4           5      6         7         8  \\\n",
       "0     0.0  10.0   950.000000  1074.0  274.986868  782.0 -0.319753 -1.432466   \n",
       "1     0.0  17.0   574.500000   582.0  104.913059  378.0  0.158313 -0.696295   \n",
       "2     3.0  16.0   593.600000   594.0    4.687572   18.0  0.396421 -0.312612   \n",
       "3     3.0  23.0   420.090909   420.0    3.591772   12.0 -0.021014 -0.856142   \n",
       "4     1.0   9.0  1068.750000  1075.0   25.118469   76.0 -0.276816 -1.271399   \n",
       "...   ...   ...          ...     ...         ...    ...       ...       ...   \n",
       "8511  3.0  16.0   615.733333   596.0   51.114860  152.0  2.153820  2.645687   \n",
       "8512  1.0   9.0  1091.500000  1093.0    5.894913   18.0 -0.311206 -1.184514   \n",
       "8513  2.0  15.0   654.428571   648.0  107.653355  458.0  0.475616  0.784000   \n",
       "8514  1.0   9.0  1075.000000  1083.0   24.535688   66.0 -0.263431 -1.567800   \n",
       "8515  1.0   9.0  1041.250000  1040.0    8.242421   22.0  0.214800 -1.575835   \n",
       "\n",
       "               9        10  ...       204         205        206        207  \\\n",
       "0     325.821586  1.000000  ...  1.000000  172.000000  10.000000   9.000000   \n",
       "1     336.569414  1.000000  ...  0.882353  -15.000000  15.000000   4.000000   \n",
       "2      94.909877  1.000000  ...  1.000000   -4.000000  16.000000  15.000000   \n",
       "3     254.059787  0.826087  ...  0.739130   -9.000000   6.000000   4.000000   \n",
       "4     461.130814  1.000000  ...  1.000000    2.000000   9.000000   8.000000   \n",
       "...          ...       ...  ...       ...         ...        ...        ...   \n",
       "8511  365.256750  1.000000  ...  0.003757    0.022262   0.003757   0.003757   \n",
       "8512  358.414529  1.000000  ...  0.888889   -3.000000   9.000000   8.000000   \n",
       "8513  180.045117  1.000000  ...  1.000000   -4.000000  15.000000  14.000000   \n",
       "8514  251.455499  1.000000  ...  1.000000   14.000000   9.000000   8.000000   \n",
       "8515  505.203302  1.000000  ...  1.000000    0.000000   9.000000   8.000000   \n",
       "\n",
       "             208           209        210           211         212  \\\n",
       "0     252.222222  10656.395062  87.777778  10339.061728  135.800000   \n",
       "1     158.000000   3944.000000  73.000000   6555.000000   -1.066667   \n",
       "2     122.400000   2058.773333  12.533333   1360.782222   95.500000   \n",
       "3      40.666667   1120.888889   5.333333   1504.888889   12.000000   \n",
       "4     122.000000    671.000000  19.750000    569.437500  136.444444   \n",
       "...          ...           ...        ...           ...         ...   \n",
       "8511    0.044242      0.044242   0.043021      0.043021    0.037385   \n",
       "8512   81.428571   1294.530612 -40.000000   1746.285714  155.333333   \n",
       "8513   77.142857   2213.551020  -1.714286   2686.204082  104.000000   \n",
       "8514  101.142857   4933.551020 -10.750000   7259.937500   88.222222   \n",
       "8515  102.000000    350.000000 -20.000000    588.000000  150.000000   \n",
       "\n",
       "              213  \n",
       "0     4315.560000  \n",
       "1      697.528889  \n",
       "2       68.750000  \n",
       "3     1464.000000  \n",
       "4       43.358025  \n",
       "...           ...  \n",
       "8511     0.037385  \n",
       "8512  4722.666667  \n",
       "8513  3602.666667  \n",
       "8514   202.172840  \n",
       "8515     0.000000  \n",
       "\n",
       "[8516 rows x 213 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_frequency.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>710.769231</td>\n",
       "      <td>628.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3140.437500</td>\n",
       "      <td>127.600000</td>\n",
       "      <td>1041.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>968.666667</td>\n",
       "      <td>894.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>5249.000000</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>8081.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>8070.530612</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1078.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>757.500000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>7081.416667</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>264.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>413.909091</td>\n",
       "      <td>409.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>832.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>342.857143</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>205.142857</td>\n",
       "      <td>11207.836735</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2281.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>14282.775510</td>\n",
       "      <td>169.142857</td>\n",
       "      <td>46.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>361.489796</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>2186.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.285714</td>\n",
       "      <td>996.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>-45.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2       3           4      5         6          7  \\\n",
       "0     0.0  14.0   710.769231   628.0  153.204817  556.0  0.996355   0.207174   \n",
       "1     0.0  10.0   968.666667   894.0  266.399867  932.0  0.979352   0.388359   \n",
       "2     0.0  11.0   797.000000   780.0  251.329664  794.0  0.260470  -1.002325   \n",
       "3     2.0  13.0   757.500000   755.0    8.986100   26.0  0.048579  -1.449012   \n",
       "4     0.0  23.0   413.909091   409.0   82.344017  426.0  3.023659  10.404884   \n",
       "...   ...   ...          ...     ...         ...    ...       ...        ...   \n",
       "2125  1.0   9.0  1071.250000  1062.0   36.509417  118.0  1.263183   0.543003   \n",
       "2126  1.0   8.0  1196.000000  1202.0   33.839959  102.0 -0.454057  -1.036905   \n",
       "2127  3.0  16.0   595.600000   590.0   23.734082   82.0  0.371174  -0.657132   \n",
       "2128  1.0   8.0  1080.285714   996.0  180.470587  448.0  0.587475  -1.363827   \n",
       "2129  3.0  25.0   391.250000   390.0    2.569857    8.0  0.605786  -0.869886   \n",
       "\n",
       "               8         9  ...       203        204   205   206         207  \\\n",
       "0     459.037295  1.000000  ...  0.928571 -10.000000  10.0   9.0  146.000000   \n",
       "1     398.464564  1.000000  ...  0.600000  64.000000   7.0   7.0  140.500000   \n",
       "2     340.802438  1.000000  ...  1.000000  26.000000   9.0   7.0  154.285714   \n",
       "3     412.324324  1.000000  ...  1.000000  -4.000000  12.0  12.0  108.500000   \n",
       "4     168.041577  0.956522  ...  0.083333   0.022262  11.0  12.0    0.044242   \n",
       "...          ...       ...  ...       ...        ...   ...   ...         ...   \n",
       "2125  364.303573  0.888889  ...  0.777778   0.000000   9.0   8.0  342.857143   \n",
       "2126  181.876516  1.000000  ...  1.000000 -26.000000   8.0   7.0  137.666667   \n",
       "2127  137.696567  1.000000  ...  1.000000  -8.000000  16.0  14.0  102.714286   \n",
       "2128  561.988537  1.000000  ...  1.000000  18.000000   8.0   5.0   62.400000   \n",
       "2129  654.123072  0.400000  ...  0.240000   4.000000   0.0   0.0    0.044242   \n",
       "\n",
       "               208         209           210         211          212  \n",
       "0       729.000000   78.250000   3140.437500  127.600000  1041.440000  \n",
       "1     15314.750000  -27.000000   5249.000000  112.285714  8081.632653  \n",
       "2      1944.489796   18.571429   8070.530612  131.111111  1078.320988  \n",
       "3      6122.750000   46.500000   7081.416667  121.833333   264.305556  \n",
       "4         0.044242  -50.000000      0.000000   45.818182   832.330579  \n",
       "...            ...         ...           ...         ...          ...  \n",
       "2125   2843.265306  205.142857  11207.836735   96.000000  2281.142857  \n",
       "2126    228.555556   87.714286  14282.775510  169.142857    46.693878  \n",
       "2127   1270.061224    7.285714    361.489796   90.400000  2186.240000  \n",
       "2128     51.840000  -45.200000      0.960000  101.000000  5002.000000  \n",
       "2129      0.044242    0.043021      0.043021    0.037385     0.037385  \n",
       "\n",
       "[2130 rows x 213 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_frequency.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4258, 212)\n",
      "Vallidation: (4258, 212)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion= 'entropy', max_depth= 15, max_features= 'sqrt', n_estimators= 40)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 61)\n",
    "knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 8, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 15, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.05,max_depth= 5,min_child_weight= 1,n_estimators= 950)\n",
    "lr_clf = LogisticRegression(C= 0.14, max_iter= 30, multi_class= 'auto', n_jobs= -1, penalty= 'l2', solver= 'sag', tol= 0.015)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 6,max_features= 'sqrt',splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.14, max_iter=30, n_jobs=-1, solver=&#x27;sag&#x27;, tol=0.015)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.14, max_iter=30, n_jobs=-1, solver=&#x27;sag&#x27;, tol=0.015)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.14, max_iter=30, n_jobs=-1, solver='sag', tol=0.015)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "# svc_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train,y_train)\n",
    "lr_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_val),\n",
    "    xgb_clf.predict_proba(x_val),\n",
    "    knn_clf.predict_proba(x_val),\n",
    "    # svc_clf.predict_proba(x_val),\n",
    "    dt_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    lr_clf.predict_proba(x_val),\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    knn_clf.predict_proba(x_test),\n",
    "    # svc_clf.predict_proba(x_test),\n",
    "    dt_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    lr_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4258, 24)\n",
      "X_test_meta:(2130, 24)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=rbf, probability=True;, score=(train=0.956, test=0.951) total time=   0.7s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=rbf, probability=True;, score=(train=0.951, test=0.961) total time=   0.7s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=rbf, probability=True;, score=(train=0.956, test=0.951) total time=   0.7s\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.955, test=0.951) total time=   0.6s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.951, test=0.962) total time=   0.6s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.957, test=0.951) total time=   0.6s\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=poly, probability=True;, score=(train=0.956, test=0.952) total time=   0.2s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=poly, probability=True;, score=(train=0.951, test=0.961) total time=   0.2s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=poly, probability=True;, score=(train=0.957, test=0.952) total time=   0.2s\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=linear, probability=True;, score=(train=0.958, test=0.954) total time=   0.1s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=linear, probability=True;, score=(train=0.953, test=0.962) total time=   0.1s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=linear, probability=True;, score=(train=0.958, test=0.952) total time=   0.1s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=rbf, probability=True;, score=(train=0.956, test=0.950) total time=   1.5s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=rbf, probability=True;, score=(train=0.950, test=0.961) total time=   1.8s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=rbf, probability=True;, score=(train=0.956, test=0.951) total time=   3.1s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.954, test=0.952) total time=   2.7s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.951, test=0.961) total time=   2.7s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.956, test=0.949) total time=   2.6s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=poly, probability=True;, score=(train=0.365, test=0.365) total time=   2.1s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=poly, probability=True;, score=(train=0.366, test=0.365) total time=   2.1s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=poly, probability=True;, score=(train=0.365, test=0.366) total time=   2.2s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=linear, probability=True;, score=(train=0.958, test=0.954) total time=   0.2s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=linear, probability=True;, score=(train=0.953, test=0.962) total time=   0.2s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=linear, probability=True;, score=(train=0.958, test=0.952) total time=   0.2s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.959, test=0.956) total time=   0.4s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.955, test=0.963) total time=   0.4s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.960, test=0.954) total time=   0.4s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.957, test=0.952) total time=   0.3s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.952, test=0.963) total time=   0.3s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.957, test=0.951) total time=   0.3s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=poly, probability=True;, score=(train=0.961, test=0.956) total time=   0.1s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=poly, probability=True;, score=(train=0.956, test=0.963) total time=   0.1s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=poly, probability=True;, score=(train=0.960, test=0.955) total time=   0.1s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=linear, probability=True;, score=(train=0.959, test=0.956) total time=   0.1s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=linear, probability=True;, score=(train=0.956, test=0.963) total time=   0.1s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=linear, probability=True;, score=(train=0.961, test=0.953) total time=   0.1s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.957, test=0.953) total time=   0.6s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.952, test=0.963) total time=   0.7s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.958, test=0.951) total time=   0.8s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.957, test=0.949) total time=   0.6s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.951, test=0.963) total time=   0.6s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.956, test=0.951) total time=   0.5s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=poly, probability=True;, score=(train=0.365, test=0.365) total time=   2.2s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=poly, probability=True;, score=(train=0.366, test=0.365) total time=   2.1s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=poly, probability=True;, score=(train=0.365, test=0.366) total time=   2.2s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=linear, probability=True;, score=(train=0.959, test=0.956) total time=   0.1s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=linear, probability=True;, score=(train=0.956, test=0.963) total time=   0.1s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=linear, probability=True;, score=(train=0.961, test=0.953) total time=   0.1s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.962, test=0.959) total time=   0.2s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.961, test=0.963) total time=   0.2s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.962, test=0.955) total time=   0.2s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.953, test=0.947) total time=   0.2s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.952, test=0.962) total time=   0.2s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.957, test=0.951) total time=   0.1s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=poly, probability=True;, score=(train=0.963, test=0.960) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=poly, probability=True;, score=(train=0.962, test=0.964) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=poly, probability=True;, score=(train=0.962, test=0.955) total time=   0.1s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=linear, probability=True;, score=(train=0.961, test=0.958) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=linear, probability=True;, score=(train=0.958, test=0.964) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=linear, probability=True;, score=(train=0.962, test=0.954) total time=   0.1s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.960, test=0.957) total time=   0.3s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.955, test=0.963) total time=   0.3s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.961, test=0.953) total time=   0.2s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.958, test=0.956) total time=   0.2s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.955, test=0.963) total time=   0.2s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.961, test=0.952) total time=   0.2s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=poly, probability=True;, score=(train=0.953, test=0.951) total time=   0.8s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=poly, probability=True;, score=(train=0.950, test=0.958) total time=   0.9s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=poly, probability=True;, score=(train=0.954, test=0.949) total time=   0.9s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=linear, probability=True;, score=(train=0.961, test=0.958) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=linear, probability=True;, score=(train=0.958, test=0.964) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=linear, probability=True;, score=(train=0.962, test=0.954) total time=   0.1s\n",
      "[CV 1/3] END C=10, gamma=scale, kernel=rbf, probability=True;, score=(train=0.965, test=0.959) total time=   0.3s\n",
      "[CV 2/3] END C=10, gamma=scale, kernel=rbf, probability=True;, score=(train=0.963, test=0.963) total time=   0.3s\n",
      "[CV 3/3] END C=10, gamma=scale, kernel=rbf, probability=True;, score=(train=0.966, test=0.957) total time=   0.2s\n",
      "[CV 1/3] END C=10, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.951, test=0.946) total time=   0.1s\n",
      "[CV 2/3] END C=10, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.944, test=0.954) total time=   0.1s\n",
      "[CV 3/3] END C=10, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.946, test=0.943) total time=   0.1s\n",
      "[CV 1/3] END C=10, gamma=scale, kernel=poly, probability=True;, score=(train=0.967, test=0.959) total time=   0.2s\n",
      "[CV 2/3] END C=10, gamma=scale, kernel=poly, probability=True;, score=(train=0.965, test=0.960) total time=   0.2s\n",
      "[CV 3/3] END C=10, gamma=scale, kernel=poly, probability=True;, score=(train=0.968, test=0.954) total time=   0.2s\n",
      "[CV 1/3] END C=10, gamma=scale, kernel=linear, probability=True;, score=(train=0.963, test=0.956) total time=   0.2s\n",
      "[CV 2/3] END C=10, gamma=scale, kernel=linear, probability=True;, score=(train=0.959, test=0.964) total time=   0.3s\n",
      "[CV 3/3] END C=10, gamma=scale, kernel=linear, probability=True;, score=(train=0.963, test=0.956) total time=   0.2s\n",
      "[CV 1/3] END C=10, gamma=auto, kernel=rbf, probability=True;, score=(train=0.962, test=0.958) total time=   0.2s\n",
      "[CV 2/3] END C=10, gamma=auto, kernel=rbf, probability=True;, score=(train=0.959, test=0.963) total time=   0.2s\n",
      "[CV 3/3] END C=10, gamma=auto, kernel=rbf, probability=True;, score=(train=0.962, test=0.954) total time=   0.2s\n",
      "[CV 1/3] END C=10, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.960, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END C=10, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.957, test=0.963) total time=   0.1s\n",
      "[CV 3/3] END C=10, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.961, test=0.953) total time=   0.1s\n",
      "[CV 1/3] END C=10, gamma=auto, kernel=poly, probability=True;, score=(train=0.958, test=0.954) total time=   0.2s\n",
      "[CV 2/3] END C=10, gamma=auto, kernel=poly, probability=True;, score=(train=0.953, test=0.961) total time=   0.2s\n",
      "[CV 3/3] END C=10, gamma=auto, kernel=poly, probability=True;, score=(train=0.958, test=0.954) total time=   0.2s\n",
      "[CV 1/3] END C=10, gamma=auto, kernel=linear, probability=True;, score=(train=0.963, test=0.956) total time=   0.2s\n",
      "[CV 2/3] END C=10, gamma=auto, kernel=linear, probability=True;, score=(train=0.959, test=0.964) total time=   0.2s\n",
      "[CV 3/3] END C=10, gamma=auto, kernel=linear, probability=True;, score=(train=0.963, test=0.956) total time=   0.2s\n",
      "[CV 1/3] END C=100, gamma=scale, kernel=rbf, probability=True;, score=(train=0.974, test=0.955) total time=   0.4s\n",
      "[CV 2/3] END C=100, gamma=scale, kernel=rbf, probability=True;, score=(train=0.971, test=0.953) total time=   0.4s\n",
      "[CV 3/3] END C=100, gamma=scale, kernel=rbf, probability=True;, score=(train=0.977, test=0.953) total time=   0.3s\n",
      "[CV 1/3] END C=100, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.943, test=0.930) total time=   0.1s\n",
      "[CV 2/3] END C=100, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.927, test=0.930) total time=   0.1s\n",
      "[CV 3/3] END C=100, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.942, test=0.930) total time=   0.1s\n",
      "[CV 1/3] END C=100, gamma=scale, kernel=poly, probability=True;, score=(train=0.975, test=0.958) total time=   0.5s\n",
      "[CV 2/3] END C=100, gamma=scale, kernel=poly, probability=True;, score=(train=0.974, test=0.952) total time=   0.4s\n",
      "[CV 3/3] END C=100, gamma=scale, kernel=poly, probability=True;, score=(train=0.977, test=0.951) total time=   0.4s\n",
      "[CV 1/3] END C=100, gamma=scale, kernel=linear, probability=True;, score=(train=0.965, test=0.954) total time=   0.7s\n",
      "[CV 2/3] END C=100, gamma=scale, kernel=linear, probability=True;, score=(train=0.960, test=0.965) total time=   0.8s\n",
      "[CV 3/3] END C=100, gamma=scale, kernel=linear, probability=True;, score=(train=0.965, test=0.958) total time=   0.6s\n",
      "[CV 1/3] END C=100, gamma=auto, kernel=rbf, probability=True;, score=(train=0.964, test=0.958) total time=   0.3s\n",
      "[CV 2/3] END C=100, gamma=auto, kernel=rbf, probability=True;, score=(train=0.962, test=0.964) total time=   0.3s\n",
      "[CV 3/3] END C=100, gamma=auto, kernel=rbf, probability=True;, score=(train=0.965, test=0.956) total time=   0.2s\n",
      "[CV 1/3] END C=100, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.961, test=0.955) total time=   0.2s\n",
      "[CV 2/3] END C=100, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.955, test=0.963) total time=   0.2s\n",
      "[CV 3/3] END C=100, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.961, test=0.953) total time=   0.2s\n",
      "[CV 1/3] END C=100, gamma=auto, kernel=poly, probability=True;, score=(train=0.961, test=0.958) total time=   0.1s\n",
      "[CV 2/3] END C=100, gamma=auto, kernel=poly, probability=True;, score=(train=0.958, test=0.963) total time=   0.1s\n",
      "[CV 3/3] END C=100, gamma=auto, kernel=poly, probability=True;, score=(train=0.961, test=0.954) total time=   0.1s\n",
      "[CV 1/3] END C=100, gamma=auto, kernel=linear, probability=True;, score=(train=0.965, test=0.954) total time=   0.6s\n",
      "[CV 2/3] END C=100, gamma=auto, kernel=linear, probability=True;, score=(train=0.960, test=0.965) total time=   0.8s\n",
      "[CV 3/3] END C=100, gamma=auto, kernel=linear, probability=True;, score=(train=0.965, test=0.958) total time=   0.6s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = SVC()\n",
    "params = {\n",
    "    'kernel': ['rbf', 'sigmoid', 'poly', 'linear'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'probability': [True]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9596057198251762"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.968075</td>\n",
       "      <td>0.914607</td>\n",
       "      <td>0.931350</td>\n",
       "      <td>0.922902</td>\n",
       "      <td>0.982196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.991549</td>\n",
       "      <td>0.993573</td>\n",
       "      <td>0.983461</td>\n",
       "      <td>0.988491</td>\n",
       "      <td>0.990385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.987324</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.969765</td>\n",
       "      <td>0.991098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.972300</td>\n",
       "      <td>0.932900</td>\n",
       "      <td>0.938998</td>\n",
       "      <td>0.935939</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.954274</td>\n",
       "      <td>0.955082</td>\n",
       "      <td>0.953529</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959624</td>\n",
       "      <td>0.959624</td>\n",
       "      <td>0.959624</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959477</td>\n",
       "      <td>0.959390</td>\n",
       "      <td>0.959624</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.968075  0.914607   0.931350  0.922902     0.982196\n",
       "1            SB  0.991549  0.993573   0.983461  0.988491     0.990385\n",
       "2            SR  0.987324  0.973034   0.966518  0.969765     0.991098\n",
       "3          GSVT  0.972300  0.932900   0.938998  0.935939     0.983213\n",
       "4     macro avg       NaN  0.954274   0.955082  0.953529          NaN\n",
       "5     micro avg       NaN  0.959624   0.959624  0.959624          NaN\n",
       "6  weighted avg       NaN  0.959477   0.959390  0.959624          NaN"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"./Result/Blending_SVM_6.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testdatasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
