{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>782.0</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>252.222222</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>87.777778</td>\n",
       "      <td>10339.061728</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>4315.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6555.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>697.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>594.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>1360.782222</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>420.090909</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1504.888889</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>569.437500</td>\n",
       "      <td>136.444444</td>\n",
       "      <td>43.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>615.733333</td>\n",
       "      <td>596.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.500000</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1746.285714</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>4722.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>654.428571</td>\n",
       "      <td>648.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>2686.204082</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3602.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>101.142857</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>-10.750000</td>\n",
       "      <td>7259.937500</td>\n",
       "      <td>88.222222</td>\n",
       "      <td>202.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1041.250000</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2            3       4           5      6         7         8  \\\n",
       "0     0.0  10.0   950.000000  1074.0  274.986868  782.0 -0.319753 -1.432466   \n",
       "1     0.0  17.0   574.500000   582.0  104.913059  378.0  0.158313 -0.696295   \n",
       "2     3.0  16.0   593.600000   594.0    4.687572   18.0  0.396421 -0.312612   \n",
       "3     3.0  23.0   420.090909   420.0    3.591772   12.0 -0.021014 -0.856142   \n",
       "4     1.0   9.0  1068.750000  1075.0   25.118469   76.0 -0.276816 -1.271399   \n",
       "...   ...   ...          ...     ...         ...    ...       ...       ...   \n",
       "8511  3.0  16.0   615.733333   596.0   51.114860  152.0  2.153820  2.645687   \n",
       "8512  1.0   9.0  1091.500000  1093.0    5.894913   18.0 -0.311206 -1.184514   \n",
       "8513  2.0  15.0   654.428571   648.0  107.653355  458.0  0.475616  0.784000   \n",
       "8514  1.0   9.0  1075.000000  1083.0   24.535688   66.0 -0.263431 -1.567800   \n",
       "8515  1.0   9.0  1041.250000  1040.0    8.242421   22.0  0.214800 -1.575835   \n",
       "\n",
       "               9        10  ...       204         205        206        207  \\\n",
       "0     325.821586  1.000000  ...  1.000000  172.000000  10.000000   9.000000   \n",
       "1     336.569414  1.000000  ...  0.882353  -15.000000  15.000000   4.000000   \n",
       "2      94.909877  1.000000  ...  1.000000   -4.000000  16.000000  15.000000   \n",
       "3     254.059787  0.826087  ...  0.739130   -9.000000   6.000000   4.000000   \n",
       "4     461.130814  1.000000  ...  1.000000    2.000000   9.000000   8.000000   \n",
       "...          ...       ...  ...       ...         ...        ...        ...   \n",
       "8511  365.256750  1.000000  ...  0.003757    0.022262   0.003757   0.003757   \n",
       "8512  358.414529  1.000000  ...  0.888889   -3.000000   9.000000   8.000000   \n",
       "8513  180.045117  1.000000  ...  1.000000   -4.000000  15.000000  14.000000   \n",
       "8514  251.455499  1.000000  ...  1.000000   14.000000   9.000000   8.000000   \n",
       "8515  505.203302  1.000000  ...  1.000000    0.000000   9.000000   8.000000   \n",
       "\n",
       "             208           209        210           211         212  \\\n",
       "0     252.222222  10656.395062  87.777778  10339.061728  135.800000   \n",
       "1     158.000000   3944.000000  73.000000   6555.000000   -1.066667   \n",
       "2     122.400000   2058.773333  12.533333   1360.782222   95.500000   \n",
       "3      40.666667   1120.888889   5.333333   1504.888889   12.000000   \n",
       "4     122.000000    671.000000  19.750000    569.437500  136.444444   \n",
       "...          ...           ...        ...           ...         ...   \n",
       "8511    0.044242      0.044242   0.043021      0.043021    0.037385   \n",
       "8512   81.428571   1294.530612 -40.000000   1746.285714  155.333333   \n",
       "8513   77.142857   2213.551020  -1.714286   2686.204082  104.000000   \n",
       "8514  101.142857   4933.551020 -10.750000   7259.937500   88.222222   \n",
       "8515  102.000000    350.000000 -20.000000    588.000000  150.000000   \n",
       "\n",
       "              213  \n",
       "0     4315.560000  \n",
       "1      697.528889  \n",
       "2       68.750000  \n",
       "3     1464.000000  \n",
       "4       43.358025  \n",
       "...           ...  \n",
       "8511     0.037385  \n",
       "8512  4722.666667  \n",
       "8513  3602.666667  \n",
       "8514   202.172840  \n",
       "8515     0.000000  \n",
       "\n",
       "[8516 rows x 213 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_frequency.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>710.769231</td>\n",
       "      <td>628.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3140.437500</td>\n",
       "      <td>127.600000</td>\n",
       "      <td>1041.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>968.666667</td>\n",
       "      <td>894.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>5249.000000</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>8081.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>8070.530612</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1078.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>757.500000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>7081.416667</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>264.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>413.909091</td>\n",
       "      <td>409.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>832.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>342.857143</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>205.142857</td>\n",
       "      <td>11207.836735</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2281.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>14282.775510</td>\n",
       "      <td>169.142857</td>\n",
       "      <td>46.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>361.489796</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>2186.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.285714</td>\n",
       "      <td>996.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>-45.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2       3           4      5         6          7  \\\n",
       "0     0.0  14.0   710.769231   628.0  153.204817  556.0  0.996355   0.207174   \n",
       "1     0.0  10.0   968.666667   894.0  266.399867  932.0  0.979352   0.388359   \n",
       "2     0.0  11.0   797.000000   780.0  251.329664  794.0  0.260470  -1.002325   \n",
       "3     2.0  13.0   757.500000   755.0    8.986100   26.0  0.048579  -1.449012   \n",
       "4     0.0  23.0   413.909091   409.0   82.344017  426.0  3.023659  10.404884   \n",
       "...   ...   ...          ...     ...         ...    ...       ...        ...   \n",
       "2125  1.0   9.0  1071.250000  1062.0   36.509417  118.0  1.263183   0.543003   \n",
       "2126  1.0   8.0  1196.000000  1202.0   33.839959  102.0 -0.454057  -1.036905   \n",
       "2127  3.0  16.0   595.600000   590.0   23.734082   82.0  0.371174  -0.657132   \n",
       "2128  1.0   8.0  1080.285714   996.0  180.470587  448.0  0.587475  -1.363827   \n",
       "2129  3.0  25.0   391.250000   390.0    2.569857    8.0  0.605786  -0.869886   \n",
       "\n",
       "               8         9  ...       203        204   205   206         207  \\\n",
       "0     459.037295  1.000000  ...  0.928571 -10.000000  10.0   9.0  146.000000   \n",
       "1     398.464564  1.000000  ...  0.600000  64.000000   7.0   7.0  140.500000   \n",
       "2     340.802438  1.000000  ...  1.000000  26.000000   9.0   7.0  154.285714   \n",
       "3     412.324324  1.000000  ...  1.000000  -4.000000  12.0  12.0  108.500000   \n",
       "4     168.041577  0.956522  ...  0.083333   0.022262  11.0  12.0    0.044242   \n",
       "...          ...       ...  ...       ...        ...   ...   ...         ...   \n",
       "2125  364.303573  0.888889  ...  0.777778   0.000000   9.0   8.0  342.857143   \n",
       "2126  181.876516  1.000000  ...  1.000000 -26.000000   8.0   7.0  137.666667   \n",
       "2127  137.696567  1.000000  ...  1.000000  -8.000000  16.0  14.0  102.714286   \n",
       "2128  561.988537  1.000000  ...  1.000000  18.000000   8.0   5.0   62.400000   \n",
       "2129  654.123072  0.400000  ...  0.240000   4.000000   0.0   0.0    0.044242   \n",
       "\n",
       "               208         209           210         211          212  \n",
       "0       729.000000   78.250000   3140.437500  127.600000  1041.440000  \n",
       "1     15314.750000  -27.000000   5249.000000  112.285714  8081.632653  \n",
       "2      1944.489796   18.571429   8070.530612  131.111111  1078.320988  \n",
       "3      6122.750000   46.500000   7081.416667  121.833333   264.305556  \n",
       "4         0.044242  -50.000000      0.000000   45.818182   832.330579  \n",
       "...            ...         ...           ...         ...          ...  \n",
       "2125   2843.265306  205.142857  11207.836735   96.000000  2281.142857  \n",
       "2126    228.555556   87.714286  14282.775510  169.142857    46.693878  \n",
       "2127   1270.061224    7.285714    361.489796   90.400000  2186.240000  \n",
       "2128     51.840000  -45.200000      0.960000  101.000000  5002.000000  \n",
       "2129      0.044242    0.043021      0.043021    0.037385     0.037385  \n",
       "\n",
       "[2130 rows x 213 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_frequency.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4258, 212)\n",
      "Vallidation: (4258, 212)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion= 'entropy', max_depth= 15, max_features= 'sqrt', n_estimators= 40)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 61)\n",
    "knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 8, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 15, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.05,max_depth= 5,min_child_weight= 1,n_estimators= 950)\n",
    "lr_clf = LogisticRegression(C= 0.14, max_iter= 30, multi_class= 'auto', n_jobs= -1, penalty= 'l2', solver= 'sag', tol= 0.015)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 6,max_features= 'sqrt',splitter= 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.14, max_iter=30, n_jobs=-1, solver=&#x27;sag&#x27;, tol=0.015)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.14, max_iter=30, n_jobs=-1, solver=&#x27;sag&#x27;, tol=0.015)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.14, max_iter=30, n_jobs=-1, solver='sag', tol=0.015)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "# svc_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train,y_train)\n",
    "lr_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    knn_clf.predict_proba(x_val),\n",
    "    # svc_clf.predict_proba(x_val),\n",
    "    xgb_clf.predict_proba(x_val),\n",
    "    dt_clf.predict_proba(x_val),\n",
    "    lr_clf.predict_proba(x_val)\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    knn_clf.predict_proba(x_test),\n",
    "    # svc_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    dt_clf.predict_proba(x_test),\n",
    "    lr_clf.predict_proba(x_test),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4258, 24)\n",
      "X_test_meta:(2130, 24)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=rbf, probability=True;, score=(train=0.957, test=0.952) total time=   0.8s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=rbf, probability=True;, score=(train=0.952, test=0.962) total time=   0.7s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=rbf, probability=True;, score=(train=0.958, test=0.951) total time=   0.7s\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.956, test=0.953) total time=   0.6s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.952, test=0.961) total time=   0.6s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.957, test=0.952) total time=   0.6s\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=poly, probability=True;, score=(train=0.955, test=0.953) total time=   0.2s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=poly, probability=True;, score=(train=0.950, test=0.961) total time=   0.2s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=poly, probability=True;, score=(train=0.957, test=0.948) total time=   0.2s\n",
      "[CV 1/3] END C=0.01, gamma=scale, kernel=linear, probability=True;, score=(train=0.957, test=0.954) total time=   0.1s\n",
      "[CV 2/3] END C=0.01, gamma=scale, kernel=linear, probability=True;, score=(train=0.953, test=0.962) total time=   0.1s\n",
      "[CV 3/3] END C=0.01, gamma=scale, kernel=linear, probability=True;, score=(train=0.958, test=0.953) total time=   0.1s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=rbf, probability=True;, score=(train=0.956, test=0.953) total time=   1.5s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=rbf, probability=True;, score=(train=0.952, test=0.959) total time=   1.6s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=rbf, probability=True;, score=(train=0.957, test=0.952) total time=   1.5s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.956, test=0.953) total time=   1.4s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.952, test=0.958) total time=   1.6s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.955, test=0.954) total time=   1.5s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=poly, probability=True;, score=(train=0.365, test=0.365) total time=   1.2s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=poly, probability=True;, score=(train=0.366, test=0.365) total time=   1.2s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=poly, probability=True;, score=(train=0.365, test=0.366) total time=   1.2s\n",
      "[CV 1/3] END C=0.01, gamma=auto, kernel=linear, probability=True;, score=(train=0.957, test=0.954) total time=   0.1s\n",
      "[CV 2/3] END C=0.01, gamma=auto, kernel=linear, probability=True;, score=(train=0.953, test=0.962) total time=   0.1s\n",
      "[CV 3/3] END C=0.01, gamma=auto, kernel=linear, probability=True;, score=(train=0.958, test=0.953) total time=   0.1s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.958, test=0.956) total time=   0.2s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.955, test=0.962) total time=   0.1s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.959, test=0.954) total time=   0.2s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.958, test=0.953) total time=   0.1s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.953, test=0.963) total time=   0.1s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.959, test=0.952) total time=   0.1s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=poly, probability=True;, score=(train=0.959, test=0.956) total time=   0.0s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=poly, probability=True;, score=(train=0.956, test=0.963) total time=   0.0s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=poly, probability=True;, score=(train=0.960, test=0.952) total time=   0.0s\n",
      "[CV 1/3] END C=0.1, gamma=scale, kernel=linear, probability=True;, score=(train=0.958, test=0.957) total time=   0.0s\n",
      "[CV 2/3] END C=0.1, gamma=scale, kernel=linear, probability=True;, score=(train=0.955, test=0.963) total time=   0.0s\n",
      "[CV 3/3] END C=0.1, gamma=scale, kernel=linear, probability=True;, score=(train=0.960, test=0.952) total time=   0.0s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.957, test=0.955) total time=   0.3s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.954, test=0.963) total time=   0.3s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.958, test=0.953) total time=   0.3s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.956, test=0.954) total time=   0.3s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.952, test=0.962) total time=   0.3s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.958, test=0.951) total time=   0.2s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=poly, probability=True;, score=(train=0.365, test=0.365) total time=   1.1s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=poly, probability=True;, score=(train=0.366, test=0.365) total time=   1.1s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=poly, probability=True;, score=(train=0.365, test=0.366) total time=   1.1s\n",
      "[CV 1/3] END C=0.1, gamma=auto, kernel=linear, probability=True;, score=(train=0.958, test=0.957) total time=   0.0s\n",
      "[CV 2/3] END C=0.1, gamma=auto, kernel=linear, probability=True;, score=(train=0.955, test=0.963) total time=   0.0s\n",
      "[CV 3/3] END C=0.1, gamma=auto, kernel=linear, probability=True;, score=(train=0.960, test=0.952) total time=   0.0s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.961, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.958, test=0.963) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=rbf, probability=True;, score=(train=0.962, test=0.955) total time=   0.1s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.951, test=0.946) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.949, test=0.962) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=sigmoid, probability=True;, score=(train=0.956, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=poly, probability=True;, score=(train=0.962, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=poly, probability=True;, score=(train=0.960, test=0.965) total time=   0.0s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=poly, probability=True;, score=(train=0.963, test=0.955) total time=   0.0s\n",
      "[CV 1/3] END C=1, gamma=scale, kernel=linear, probability=True;, score=(train=0.959, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END C=1, gamma=scale, kernel=linear, probability=True;, score=(train=0.956, test=0.965) total time=   0.0s\n",
      "[CV 3/3] END C=1, gamma=scale, kernel=linear, probability=True;, score=(train=0.961, test=0.950) total time=   0.0s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.959, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.956, test=0.963) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=rbf, probability=True;, score=(train=0.960, test=0.953) total time=   0.1s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.958, test=0.956) total time=   0.1s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.954, test=0.963) total time=   0.1s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=sigmoid, probability=True;, score=(train=0.959, test=0.953) total time=   0.0s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=poly, probability=True;, score=(train=0.954, test=0.951) total time=   0.5s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=poly, probability=True;, score=(train=0.950, test=0.959) total time=   0.5s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=poly, probability=True;, score=(train=0.955, test=0.949) total time=   0.4s\n",
      "[CV 1/3] END C=1, gamma=auto, kernel=linear, probability=True;, score=(train=0.959, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END C=1, gamma=auto, kernel=linear, probability=True;, score=(train=0.956, test=0.965) total time=   0.0s\n",
      "[CV 3/3] END C=1, gamma=auto, kernel=linear, probability=True;, score=(train=0.961, test=0.950) total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = SVC()\n",
    "params = {\n",
    "    'kernel': ['rbf', 'sigmoid', 'poly', 'linear'],\n",
    "    'C': [0.01, 0.1, 1],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'probability': [True]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 'scale', 'kernel': 'poly', 'probability': True}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9593708126135247"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.967606</td>\n",
       "      <td>0.919101</td>\n",
       "      <td>0.925339</td>\n",
       "      <td>0.922210</td>\n",
       "      <td>0.980415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.991080</td>\n",
       "      <td>0.991003</td>\n",
       "      <td>0.984674</td>\n",
       "      <td>0.987828</td>\n",
       "      <td>0.991124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.987793</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.968680</td>\n",
       "      <td>0.970852</td>\n",
       "      <td>0.991691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.930736</td>\n",
       "      <td>0.938865</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953918</td>\n",
       "      <td>0.954390</td>\n",
       "      <td>0.953468</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959155</td>\n",
       "      <td>0.959155</td>\n",
       "      <td>0.959155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959067</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>0.959155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.967606  0.919101   0.925339  0.922210     0.980415\n",
       "1            SB  0.991080  0.991003   0.984674  0.987828     0.991124\n",
       "2            SR  0.987793  0.973034   0.968680  0.970852     0.991691\n",
       "3          GSVT  0.971831  0.930736   0.938865  0.934783     0.983213\n",
       "4     macro avg       NaN  0.953918   0.954390  0.953468          NaN\n",
       "5     micro avg       NaN  0.959155   0.959155  0.959155          NaN\n",
       "6  weighted avg       NaN  0.959067   0.959000  0.959155          NaN"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"./Result/Blending_SVM.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testdatasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
