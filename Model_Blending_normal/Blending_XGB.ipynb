{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>782.0</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>252.222222</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>87.777778</td>\n",
       "      <td>10339.061728</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>4315.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6555.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>697.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>594.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>1360.782222</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>420.090909</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1504.888889</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>569.437500</td>\n",
       "      <td>136.444444</td>\n",
       "      <td>43.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>615.733333</td>\n",
       "      <td>596.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.500000</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1746.285714</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>4722.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>654.428571</td>\n",
       "      <td>648.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>2686.204082</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3602.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>101.142857</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>-10.750000</td>\n",
       "      <td>7259.937500</td>\n",
       "      <td>88.222222</td>\n",
       "      <td>202.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1041.250000</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2            3       4           5      6         7         8  \\\n",
       "0     0.0  10.0   950.000000  1074.0  274.986868  782.0 -0.319753 -1.432466   \n",
       "1     0.0  17.0   574.500000   582.0  104.913059  378.0  0.158313 -0.696295   \n",
       "2     3.0  16.0   593.600000   594.0    4.687572   18.0  0.396421 -0.312612   \n",
       "3     3.0  23.0   420.090909   420.0    3.591772   12.0 -0.021014 -0.856142   \n",
       "4     1.0   9.0  1068.750000  1075.0   25.118469   76.0 -0.276816 -1.271399   \n",
       "...   ...   ...          ...     ...         ...    ...       ...       ...   \n",
       "8511  3.0  16.0   615.733333   596.0   51.114860  152.0  2.153820  2.645687   \n",
       "8512  1.0   9.0  1091.500000  1093.0    5.894913   18.0 -0.311206 -1.184514   \n",
       "8513  2.0  15.0   654.428571   648.0  107.653355  458.0  0.475616  0.784000   \n",
       "8514  1.0   9.0  1075.000000  1083.0   24.535688   66.0 -0.263431 -1.567800   \n",
       "8515  1.0   9.0  1041.250000  1040.0    8.242421   22.0  0.214800 -1.575835   \n",
       "\n",
       "               9        10  ...       204         205        206        207  \\\n",
       "0     325.821586  1.000000  ...  1.000000  172.000000  10.000000   9.000000   \n",
       "1     336.569414  1.000000  ...  0.882353  -15.000000  15.000000   4.000000   \n",
       "2      94.909877  1.000000  ...  1.000000   -4.000000  16.000000  15.000000   \n",
       "3     254.059787  0.826087  ...  0.739130   -9.000000   6.000000   4.000000   \n",
       "4     461.130814  1.000000  ...  1.000000    2.000000   9.000000   8.000000   \n",
       "...          ...       ...  ...       ...         ...        ...        ...   \n",
       "8511  365.256750  1.000000  ...  0.003757    0.022262   0.003757   0.003757   \n",
       "8512  358.414529  1.000000  ...  0.888889   -3.000000   9.000000   8.000000   \n",
       "8513  180.045117  1.000000  ...  1.000000   -4.000000  15.000000  14.000000   \n",
       "8514  251.455499  1.000000  ...  1.000000   14.000000   9.000000   8.000000   \n",
       "8515  505.203302  1.000000  ...  1.000000    0.000000   9.000000   8.000000   \n",
       "\n",
       "             208           209        210           211         212  \\\n",
       "0     252.222222  10656.395062  87.777778  10339.061728  135.800000   \n",
       "1     158.000000   3944.000000  73.000000   6555.000000   -1.066667   \n",
       "2     122.400000   2058.773333  12.533333   1360.782222   95.500000   \n",
       "3      40.666667   1120.888889   5.333333   1504.888889   12.000000   \n",
       "4     122.000000    671.000000  19.750000    569.437500  136.444444   \n",
       "...          ...           ...        ...           ...         ...   \n",
       "8511    0.044242      0.044242   0.043021      0.043021    0.037385   \n",
       "8512   81.428571   1294.530612 -40.000000   1746.285714  155.333333   \n",
       "8513   77.142857   2213.551020  -1.714286   2686.204082  104.000000   \n",
       "8514  101.142857   4933.551020 -10.750000   7259.937500   88.222222   \n",
       "8515  102.000000    350.000000 -20.000000    588.000000  150.000000   \n",
       "\n",
       "              213  \n",
       "0     4315.560000  \n",
       "1      697.528889  \n",
       "2       68.750000  \n",
       "3     1464.000000  \n",
       "4       43.358025  \n",
       "...           ...  \n",
       "8511     0.037385  \n",
       "8512  4722.666667  \n",
       "8513  3602.666667  \n",
       "8514   202.172840  \n",
       "8515     0.000000  \n",
       "\n",
       "[8516 rows x 213 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_frequency.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>710.769231</td>\n",
       "      <td>628.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3140.437500</td>\n",
       "      <td>127.600000</td>\n",
       "      <td>1041.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>968.666667</td>\n",
       "      <td>894.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>5249.000000</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>8081.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>8070.530612</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1078.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>757.500000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>7081.416667</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>264.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>413.909091</td>\n",
       "      <td>409.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>832.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>342.857143</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>205.142857</td>\n",
       "      <td>11207.836735</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2281.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>14282.775510</td>\n",
       "      <td>169.142857</td>\n",
       "      <td>46.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>361.489796</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>2186.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.285714</td>\n",
       "      <td>996.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>-45.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2       3           4      5         6          7  \\\n",
       "0     0.0  14.0   710.769231   628.0  153.204817  556.0  0.996355   0.207174   \n",
       "1     0.0  10.0   968.666667   894.0  266.399867  932.0  0.979352   0.388359   \n",
       "2     0.0  11.0   797.000000   780.0  251.329664  794.0  0.260470  -1.002325   \n",
       "3     2.0  13.0   757.500000   755.0    8.986100   26.0  0.048579  -1.449012   \n",
       "4     0.0  23.0   413.909091   409.0   82.344017  426.0  3.023659  10.404884   \n",
       "...   ...   ...          ...     ...         ...    ...       ...        ...   \n",
       "2125  1.0   9.0  1071.250000  1062.0   36.509417  118.0  1.263183   0.543003   \n",
       "2126  1.0   8.0  1196.000000  1202.0   33.839959  102.0 -0.454057  -1.036905   \n",
       "2127  3.0  16.0   595.600000   590.0   23.734082   82.0  0.371174  -0.657132   \n",
       "2128  1.0   8.0  1080.285714   996.0  180.470587  448.0  0.587475  -1.363827   \n",
       "2129  3.0  25.0   391.250000   390.0    2.569857    8.0  0.605786  -0.869886   \n",
       "\n",
       "               8         9  ...       203        204   205   206         207  \\\n",
       "0     459.037295  1.000000  ...  0.928571 -10.000000  10.0   9.0  146.000000   \n",
       "1     398.464564  1.000000  ...  0.600000  64.000000   7.0   7.0  140.500000   \n",
       "2     340.802438  1.000000  ...  1.000000  26.000000   9.0   7.0  154.285714   \n",
       "3     412.324324  1.000000  ...  1.000000  -4.000000  12.0  12.0  108.500000   \n",
       "4     168.041577  0.956522  ...  0.083333   0.022262  11.0  12.0    0.044242   \n",
       "...          ...       ...  ...       ...        ...   ...   ...         ...   \n",
       "2125  364.303573  0.888889  ...  0.777778   0.000000   9.0   8.0  342.857143   \n",
       "2126  181.876516  1.000000  ...  1.000000 -26.000000   8.0   7.0  137.666667   \n",
       "2127  137.696567  1.000000  ...  1.000000  -8.000000  16.0  14.0  102.714286   \n",
       "2128  561.988537  1.000000  ...  1.000000  18.000000   8.0   5.0   62.400000   \n",
       "2129  654.123072  0.400000  ...  0.240000   4.000000   0.0   0.0    0.044242   \n",
       "\n",
       "               208         209           210         211          212  \n",
       "0       729.000000   78.250000   3140.437500  127.600000  1041.440000  \n",
       "1     15314.750000  -27.000000   5249.000000  112.285714  8081.632653  \n",
       "2      1944.489796   18.571429   8070.530612  131.111111  1078.320988  \n",
       "3      6122.750000   46.500000   7081.416667  121.833333   264.305556  \n",
       "4         0.044242  -50.000000      0.000000   45.818182   832.330579  \n",
       "...            ...         ...           ...         ...          ...  \n",
       "2125   2843.265306  205.142857  11207.836735   96.000000  2281.142857  \n",
       "2126    228.555556   87.714286  14282.775510  169.142857    46.693878  \n",
       "2127   1270.061224    7.285714    361.489796   90.400000  2186.240000  \n",
       "2128     51.840000  -45.200000      0.960000  101.000000  5002.000000  \n",
       "2129      0.044242    0.043021      0.043021    0.037385     0.037385  \n",
       "\n",
       "[2130 rows x 213 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_frequency.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3406, 212)\n",
      "Vallidation: (5110, 212)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.6, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 15, max_features= 'sqrt', n_estimators= 40)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 61)\n",
    "knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 8, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 15, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "# xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.05,max_depth= 5,min_child_weight= 1,n_estimators= 1000)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'gini',max_depth= 6,max_features= 'sqrt',splitter= 'best')\n",
    "lr_clf = LogisticRegression(C= 0.14, max_iter= 20, multi_class= 'auto', n_jobs= -1, penalty= 'l2', solver= 'sag', tol= 0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=6, max_features=&#x27;sqrt&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=6, max_features=&#x27;sqrt&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=6, max_features='sqrt')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "svc_clf.fit(x_train, y_train)\n",
    "# xgb_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    knn_clf.predict_proba(x_val),\n",
    "    svc_clf.predict_proba(x_val),\n",
    "    # xgb_clf.predict_proba(x_val),\n",
    "    dt_clf.predict_proba(x_val)\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    knn_clf.predict_proba(x_test),\n",
    "    svc_clf.predict_proba(x_test),\n",
    "    # xgb_clf.predict_proba(x_test),\n",
    "    dt_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(5110, 20)\n",
      "X_test_meta:(2130, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "[CV 1/3] END gamma=0, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.964, test=0.954) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.956) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.948) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.964, test=0.954) total time=   1.2s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.962, test=0.959) total time=   1.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.966, test=0.948) total time=   0.8s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.963, test=0.955) total time=   1.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.963, test=0.958) total time=   1.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.966, test=0.950) total time=   1.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.966, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.967, test=0.956) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.969, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.967, test=0.957) total time=   0.6s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.968, test=0.960) total time=   0.8s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.972, test=0.947) total time=   0.7s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.971, test=0.957) total time=   1.3s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.969, test=0.960) total time=   1.2s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.972, test=0.948) total time=   1.3s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.958) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.972, test=0.948) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.973, test=0.953) total time=   0.8s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.974, test=0.960) total time=   0.8s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.975, test=0.947) total time=   0.8s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.976, test=0.956) total time=   1.9s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.976, test=0.959) total time=   2.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.977, test=0.947) total time=   2.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.964, test=0.954) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.962, test=0.959) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.966, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.965, test=0.955) total time=   0.5s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.963, test=0.960) total time=   0.5s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.966, test=0.951) total time=   0.5s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.968, test=0.957) total time=   1.2s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.965, test=0.962) total time=   1.3s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.971, test=0.950) total time=   1.3s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.967, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.968, test=0.961) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.971, test=0.947) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.974, test=0.957) total time=   0.9s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.977, test=0.958) total time=   0.9s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.974, test=0.950) total time=   0.8s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.978, test=0.957) total time=   1.4s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.978, test=0.958) total time=   1.4s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.979, test=0.951) total time=   1.4s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.973, test=0.953) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.960) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.975, test=0.946) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.979, test=0.957) total time=   0.9s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.981, test=0.958) total time=   0.9s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.979, test=0.950) total time=   0.9s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.957) total time=   1.7s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.961) total time=   1.8s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.987, test=0.950) total time=   1.8s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.955) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.959) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.966, test=0.950) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.968, test=0.957) total time=   0.5s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.965, test=0.961) total time=   0.5s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.971, test=0.950) total time=   0.5s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.973, test=0.957) total time=   1.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.974, test=0.958) total time=   1.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.978, test=0.950) total time=   1.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.971, test=0.957) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.969, test=0.961) total time=   0.2s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.972, test=0.948) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.978, test=0.957) total time=   0.6s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.978, test=0.958) total time=   0.6s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.979, test=0.951) total time=   0.6s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.957) total time=   1.3s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.958) total time=   1.4s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.986, test=0.950) total time=   1.3s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.976, test=0.956) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.975, test=0.959) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.977, test=0.947) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.985, test=0.957) total time=   0.9s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.984, test=0.960) total time=   0.8s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.987, test=0.950) total time=   0.8s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.991, test=0.955) total time=   1.5s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.994, test=0.958) total time=   1.8s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.993, test=0.950) total time=   1.6s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.973, test=0.956) total time=   0.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.957) total time=   0.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.979, test=0.951) total time=   0.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.951) total time=   0.4s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.955) total time=   0.5s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.947) total time=   0.5s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.951) total time=   1.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.956) total time=   1.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.945) total time=   1.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.984, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.985, test=0.957) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.986, test=0.952) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.952) total time=   0.6s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.958) total time=   0.6s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.948) total time=   1.2s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.952) total time=   2.3s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.957) total time=   1.3s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.949) total time=   1.2s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.991, test=0.954) total time=   0.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.994, test=0.960) total time=   0.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.994, test=0.950) total time=   0.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.951) total time=   0.7s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.957) total time=   0.9s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.949) total time=   0.7s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.951) total time=   1.5s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.955) total time=   1.5s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=1.000, test=0.947) total time=   1.4s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.964, test=0.954) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.964, test=0.954) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.962, test=0.959) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.966, test=0.948) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.963, test=0.955) total time=   1.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.963, test=0.958) total time=   1.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.966, test=0.950) total time=   1.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.966, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.967, test=0.956) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.969, test=0.948) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.967, test=0.957) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.968, test=0.961) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.972, test=0.947) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.971, test=0.957) total time=   1.4s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.969, test=0.960) total time=   1.3s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.972, test=0.948) total time=   1.5s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.973, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.958) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.972, test=0.948) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.973, test=0.953) total time=   0.9s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.974, test=0.960) total time=   1.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.976, test=0.947) total time=   0.8s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.975, test=0.956) total time=   1.7s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.976, test=0.959) total time=   1.6s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.977, test=0.947) total time=   2.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.964, test=0.954) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.962, test=0.959) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.966, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.965, test=0.955) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.963, test=0.960) total time=   0.5s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.966, test=0.951) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.968, test=0.957) total time=   1.2s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.965, test=0.962) total time=   1.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.971, test=0.950) total time=   1.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.967, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.968, test=0.961) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.971, test=0.947) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.974, test=0.957) total time=   0.7s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.977, test=0.959) total time=   0.7s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.974, test=0.950) total time=   0.7s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.978, test=0.957) total time=   1.5s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.978, test=0.958) total time=   1.5s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.979, test=0.951) total time=   1.5s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.973, test=0.954) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.960) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.976, test=0.947) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.979, test=0.956) total time=   1.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.981, test=0.958) total time=   0.9s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.979, test=0.949) total time=   1.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.956) total time=   1.6s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.958) total time=   1.8s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.986, test=0.950) total time=   1.7s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.955) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.959) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.965, test=0.950) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.968, test=0.957) total time=   0.5s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.965, test=0.962) total time=   0.5s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.971, test=0.950) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.973, test=0.957) total time=   1.2s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.974, test=0.958) total time=   1.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.978, test=0.950) total time=   1.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.971, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.969, test=0.960) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.973, test=0.948) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.978, test=0.957) total time=   0.8s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.978, test=0.958) total time=   0.7s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.979, test=0.951) total time=   0.7s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.985, test=0.957) total time=   1.4s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.985, test=0.957) total time=   1.4s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.986, test=0.950) total time=   1.3s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.976, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.976, test=0.959) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.977, test=0.947) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.984, test=0.956) total time=   0.8s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.984, test=0.958) total time=   0.8s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.987, test=0.950) total time=   0.8s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.992, test=0.954) total time=   1.6s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.994, test=0.958) total time=   1.6s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.994, test=0.950) total time=   1.6s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.957) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.975, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.978, test=0.951) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.993, test=0.954) total time=   0.3s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.993, test=0.959) total time=   0.3s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.991, test=0.950) total time=   0.3s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.993, test=0.954) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.993, test=0.959) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.991, test=0.950) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.985, test=0.957) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.984, test=0.957) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.987, test=0.951) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.995, test=0.954) total time=   0.3s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.994, test=0.958) total time=   0.3s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.994, test=0.948) total time=   0.4s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.995, test=0.954) total time=   0.7s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.994, test=0.958) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.994, test=0.948) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.992, test=0.955) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.994, test=0.962) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.994, test=0.950) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.997, test=0.954) total time=   0.3s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.998, test=0.958) total time=   0.3s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.996, test=0.950) total time=   0.3s\n",
      "[CV 1/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.997, test=0.954) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.998, test=0.958) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.996, test=0.950) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.964, test=0.954) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.964, test=0.954) total time=   0.4s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.962, test=0.959) total time=   0.5s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.966, test=0.948) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.963, test=0.955) total time=   1.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.963, test=0.958) total time=   1.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.001, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.966, test=0.950) total time=   1.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.966, test=0.957) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.967, test=0.956) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.969, test=0.948) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.967, test=0.957) total time=   0.7s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.968, test=0.961) total time=   0.7s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.972, test=0.947) total time=   0.7s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.971, test=0.957) total time=   1.3s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.969, test=0.960) total time=   1.3s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.973, test=0.948) total time=   1.3s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.973, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.958) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.973, test=0.948) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.973, test=0.955) total time=   1.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.974, test=0.960) total time=   0.9s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.975, test=0.947) total time=   0.8s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.976, test=0.957) total time=   1.6s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.976, test=0.959) total time=   1.8s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.977, test=0.948) total time=   1.9s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.964, test=0.954) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.962, test=0.959) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.966, test=0.948) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.965, test=0.955) total time=   0.5s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.963, test=0.960) total time=   0.5s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.966, test=0.951) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.968, test=0.957) total time=   1.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.965, test=0.962) total time=   1.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.005, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.971, test=0.950) total time=   1.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.967, test=0.956) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.968, test=0.961) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.971, test=0.947) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.974, test=0.957) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.977, test=0.959) total time=   0.7s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.974, test=0.950) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.978, test=0.958) total time=   3.7s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.979, test=0.958) total time=   2.6s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.005, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.979, test=0.951) total time=   1.7s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.973, test=0.955) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.960) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.975, test=0.947) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.979, test=0.955) total time=   0.9s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.981, test=0.958) total time=   0.9s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.979, test=0.951) total time=   0.8s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.956) total time=   2.4s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.959) total time=   3.4s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.005, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.986, test=0.950) total time=   1.8s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.955) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.963, test=0.959) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.965, test=0.950) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.968, test=0.957) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.965, test=0.962) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.971, test=0.950) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.973, test=0.957) total time=   1.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.974, test=0.957) total time=   1.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.978, test=0.950) total time=   1.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.971, test=0.957) total time=   0.9s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.969, test=0.960) total time=   0.4s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.972, test=0.947) total time=   0.2s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.978, test=0.958) total time=   0.9s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.979, test=0.958) total time=   0.7s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.979, test=0.951) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.957) total time=   1.7s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.957) total time=   1.6s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.986, test=0.951) total time=   1.4s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.976, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.976, test=0.959) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.977, test=0.948) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.984, test=0.956) total time=   0.8s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.984, test=0.959) total time=   0.8s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.986, test=0.949) total time=   0.7s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.991, test=0.955) total time=   1.3s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.991, test=0.959) total time=   1.4s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.992, test=0.950) total time=   1.5s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.957) total time=   0.0s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.974, test=0.957) total time=   0.0s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100;, score=(train=0.978, test=0.951) total time=   0.0s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.981, test=0.955) total time=   0.2s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.984, test=0.961) total time=   0.2s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=0.985, test=0.950) total time=   0.3s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.981, test=0.955) total time=   0.5s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.984, test=0.961) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=1000;, score=(train=0.985, test=0.950) total time=   0.5s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.984, test=0.957) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.985, test=0.958) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100;, score=(train=0.987, test=0.951) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.986, test=0.956) total time=   0.3s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.988, test=0.959) total time=   0.3s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=0.988, test=0.950) total time=   0.4s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.986, test=0.956) total time=   0.7s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.988, test=0.959) total time=   0.5s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=1000;, score=(train=0.988, test=0.950) total time=   0.6s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.991, test=0.956) total time=   0.1s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.992, test=0.960) total time=   0.1s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100;, score=(train=0.991, test=0.950) total time=   0.1s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.991, test=0.955) total time=   0.5s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.993, test=0.960) total time=   0.4s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=0.992, test=0.950) total time=   0.3s\n",
      "[CV 1/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.991, test=0.955) total time=   0.6s\n",
      "[CV 2/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.993, test=0.960) total time=   0.6s\n",
      "[CV 3/3] END gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=1000;, score=(train=0.992, test=0.950) total time=   0.5s\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = XGBClassifier()\n",
    "params = {\n",
    "    'n_estimators': [100,500,1000],\n",
    "    'learning_rate': [0.001,0.005,0.01,0.1],\n",
    "    'max_depth': [3,4,5],\n",
    "    'min_child_weight':[1],\n",
    "    'gamma':[0,0.1,0.2],\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0,\n",
       " 'learning_rate': 0.005,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956164303626942"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.967606</td>\n",
       "      <td>0.907865</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.921323</td>\n",
       "      <td>0.983383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.991080</td>\n",
       "      <td>0.989717</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.987813</td>\n",
       "      <td>0.991864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.988263</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.972004</td>\n",
       "      <td>0.991691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.970423</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.979017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953368</td>\n",
       "      <td>0.953806</td>\n",
       "      <td>0.953064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958685</td>\n",
       "      <td>0.958685</td>\n",
       "      <td>0.958685</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958585</td>\n",
       "      <td>0.958599</td>\n",
       "      <td>0.958685</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.967606  0.907865   0.935185  0.921323     0.983383\n",
       "1            SB  0.991080  0.989717   0.985915  0.987813     0.991864\n",
       "2            SR  0.988263  0.975281   0.968750  0.972004     0.991691\n",
       "3          GSVT  0.970423  0.939394   0.925373  0.932331     0.979017\n",
       "4     macro avg       NaN  0.953368   0.953806  0.953064          NaN\n",
       "5     micro avg       NaN  0.958685   0.958685  0.958685          NaN\n",
       "6  weighted avg       NaN  0.958585   0.958599  0.958685          NaN"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_evaluation_test.to_csv(\"./Result/Blending_XGB.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testdatasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
