{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm</th>\n",
       "      <th>Rcount_lead1</th>\n",
       "      <th>RRInterval_mean_lead1</th>\n",
       "      <th>RRInterval_median_lead1</th>\n",
       "      <th>RRInterval_std_lead1</th>\n",
       "      <th>RRInterval_range_lead1</th>\n",
       "      <th>RRInterval_skew_lead1</th>\n",
       "      <th>RRInterval_kurtosis_lead1</th>\n",
       "      <th>R_peaks_amplitude_from_isoelectric_mean_lead1</th>\n",
       "      <th>PRovercount_lead1</th>\n",
       "      <th>...</th>\n",
       "      <th>AtrialRate</th>\n",
       "      <th>QRSDuration</th>\n",
       "      <th>QTInterval</th>\n",
       "      <th>QTCorrected</th>\n",
       "      <th>RAxis</th>\n",
       "      <th>TAxis</th>\n",
       "      <th>QRSCount</th>\n",
       "      <th>QOnset</th>\n",
       "      <th>QOffset</th>\n",
       "      <th>TOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.857143</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>21.879074</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.622052</td>\n",
       "      <td>-0.821453</td>\n",
       "      <td>694.163664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>106</td>\n",
       "      <td>436</td>\n",
       "      <td>420</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>219</td>\n",
       "      <td>272</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>535.764706</td>\n",
       "      <td>536.0</td>\n",
       "      <td>1.351662</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.146383</td>\n",
       "      <td>-0.825069</td>\n",
       "      <td>149.028032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>70</td>\n",
       "      <td>354</td>\n",
       "      <td>483</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "      <td>229</td>\n",
       "      <td>264</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1344.333333</td>\n",
       "      <td>1581.0</td>\n",
       "      <td>402.603886</td>\n",
       "      <td>974.0</td>\n",
       "      <td>-0.717501</td>\n",
       "      <td>-1.392992</td>\n",
       "      <td>302.224787</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>426</td>\n",
       "      <td>368</td>\n",
       "      <td>51</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>216</td>\n",
       "      <td>262</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>561.500000</td>\n",
       "      <td>562.0</td>\n",
       "      <td>4.609772</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.367506</td>\n",
       "      <td>-0.701176</td>\n",
       "      <td>804.877251</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>88</td>\n",
       "      <td>338</td>\n",
       "      <td>451</td>\n",
       "      <td>-12</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>216</td>\n",
       "      <td>260</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>612.400000</td>\n",
       "      <td>612.0</td>\n",
       "      <td>4.963869</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.163258</td>\n",
       "      <td>-1.136195</td>\n",
       "      <td>451.559324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>78</td>\n",
       "      <td>352</td>\n",
       "      <td>449</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>218</td>\n",
       "      <td>257</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>559.750000</td>\n",
       "      <td>561.0</td>\n",
       "      <td>3.929058</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.666167</td>\n",
       "      <td>0.137849</td>\n",
       "      <td>630.195529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>80</td>\n",
       "      <td>348</td>\n",
       "      <td>464</td>\n",
       "      <td>22</td>\n",
       "      <td>135</td>\n",
       "      <td>17</td>\n",
       "      <td>225</td>\n",
       "      <td>265</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1211.714286</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>20.126133</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.117312</td>\n",
       "      <td>-1.249265</td>\n",
       "      <td>441.849082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>110</td>\n",
       "      <td>402</td>\n",
       "      <td>366</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>216</td>\n",
       "      <td>271</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>789.272727</td>\n",
       "      <td>792.0</td>\n",
       "      <td>24.764678</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-1.129683</td>\n",
       "      <td>0.997705</td>\n",
       "      <td>278.529342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>374</td>\n",
       "      <td>420</td>\n",
       "      <td>42</td>\n",
       "      <td>-4</td>\n",
       "      <td>12</td>\n",
       "      <td>219</td>\n",
       "      <td>257</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>514.823529</td>\n",
       "      <td>490.0</td>\n",
       "      <td>115.746292</td>\n",
       "      <td>402.0</td>\n",
       "      <td>0.832975</td>\n",
       "      <td>-0.335017</td>\n",
       "      <td>92.402139</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129</td>\n",
       "      <td>72</td>\n",
       "      <td>274</td>\n",
       "      <td>415</td>\n",
       "      <td>86</td>\n",
       "      <td>-81</td>\n",
       "      <td>23</td>\n",
       "      <td>218</td>\n",
       "      <td>254</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1133.500000</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>13.444330</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-0.654613</td>\n",
       "      <td>-0.225903</td>\n",
       "      <td>592.118309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>86</td>\n",
       "      <td>470</td>\n",
       "      <td>441</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>220</td>\n",
       "      <td>263</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rhythm  Rcount_lead1  RRInterval_mean_lead1  RRInterval_median_lead1  \\\n",
       "0          1           8.0            1080.857143                   1086.0   \n",
       "1          3          18.0             535.764706                    536.0   \n",
       "2          1           7.0            1344.333333                   1581.0   \n",
       "3          3          17.0             561.500000                    562.0   \n",
       "4          2          16.0             612.400000                    612.0   \n",
       "...      ...           ...                    ...                      ...   \n",
       "8511       3          17.0             559.750000                    561.0   \n",
       "8512       1           8.0            1211.714286                   1212.0   \n",
       "8513       2          12.0             789.272727                    792.0   \n",
       "8514       0          18.0             514.823529                    490.0   \n",
       "8515       1           9.0            1133.500000                   1135.0   \n",
       "\n",
       "      RRInterval_std_lead1  RRInterval_range_lead1  RRInterval_skew_lead1  \\\n",
       "0                21.879074                    66.0              -0.622052   \n",
       "1                 1.351662                     4.0               0.146383   \n",
       "2               402.603886                   974.0              -0.717501   \n",
       "3                 4.609772                    16.0              -0.367506   \n",
       "4                 4.963869                    14.0               0.163258   \n",
       "...                    ...                     ...                    ...   \n",
       "8511              3.929058                    16.0              -0.666167   \n",
       "8512             20.126133                    60.0               0.117312   \n",
       "8513             24.764678                    96.0              -1.129683   \n",
       "8514            115.746292                   402.0               0.832975   \n",
       "8515             13.444330                    46.0              -0.654613   \n",
       "\n",
       "      RRInterval_kurtosis_lead1  \\\n",
       "0                     -0.821453   \n",
       "1                     -0.825069   \n",
       "2                     -1.392992   \n",
       "3                     -0.701176   \n",
       "4                     -1.136195   \n",
       "...                         ...   \n",
       "8511                   0.137849   \n",
       "8512                  -1.249265   \n",
       "8513                   0.997705   \n",
       "8514                  -0.335017   \n",
       "8515                  -0.225903   \n",
       "\n",
       "      R_peaks_amplitude_from_isoelectric_mean_lead1  PRovercount_lead1  ...  \\\n",
       "0                                        694.163664           1.000000  ...   \n",
       "1                                        149.028032           1.000000  ...   \n",
       "2                                        302.224787           0.857143  ...   \n",
       "3                                        804.877251           1.000000  ...   \n",
       "4                                        451.559324           1.000000  ...   \n",
       "...                                             ...                ...  ...   \n",
       "8511                                     630.195529           1.000000  ...   \n",
       "8512                                     441.849082           1.000000  ...   \n",
       "8513                                     278.529342           1.000000  ...   \n",
       "8514                                      92.402139           1.000000  ...   \n",
       "8515                                     592.118309           1.000000  ...   \n",
       "\n",
       "      AtrialRate  QRSDuration  QTInterval  QTCorrected  RAxis  TAxis  \\\n",
       "0             56          106         436          420     50      7   \n",
       "1            112           70         354          483     56     45   \n",
       "2              0           92         426          368     51     70   \n",
       "3            107           88         338          451    -12     74   \n",
       "4             98           78         352          449     54     33   \n",
       "...          ...          ...         ...          ...    ...    ...   \n",
       "8511         107           80         348          464     22    135   \n",
       "8512          50          110         402          366     55     56   \n",
       "8513          76           76         374          420     42     -4   \n",
       "8514         129           72         274          415     86    -81   \n",
       "8515          53           86         470          441     26     45   \n",
       "\n",
       "      QRSCount  QOnset  QOffset  TOffset  \n",
       "0           10     219      272      437  \n",
       "1           18     229      264      406  \n",
       "2            7     216      262      429  \n",
       "3           18     216      260      385  \n",
       "4           16     218      257      394  \n",
       "...        ...     ...      ...      ...  \n",
       "8511        17     225      265      399  \n",
       "8512         8     216      271      417  \n",
       "8513        12     219      257      406  \n",
       "8514        23     218      254      355  \n",
       "8515         9     220      263      455  \n",
       "\n",
       "[8516 rows x 226 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./data_train_frequency_merge.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm</th>\n",
       "      <th>Rcount_lead1</th>\n",
       "      <th>RRInterval_mean_lead1</th>\n",
       "      <th>RRInterval_median_lead1</th>\n",
       "      <th>RRInterval_std_lead1</th>\n",
       "      <th>RRInterval_range_lead1</th>\n",
       "      <th>RRInterval_skew_lead1</th>\n",
       "      <th>RRInterval_kurtosis_lead1</th>\n",
       "      <th>R_peaks_amplitude_from_isoelectric_mean_lead1</th>\n",
       "      <th>PRovercount_lead1</th>\n",
       "      <th>...</th>\n",
       "      <th>AtrialRate</th>\n",
       "      <th>QRSDuration</th>\n",
       "      <th>QTInterval</th>\n",
       "      <th>QTCorrected</th>\n",
       "      <th>RAxis</th>\n",
       "      <th>TAxis</th>\n",
       "      <th>QRSCount</th>\n",
       "      <th>QOnset</th>\n",
       "      <th>QOffset</th>\n",
       "      <th>TOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>806.545455</td>\n",
       "      <td>742.0</td>\n",
       "      <td>139.662166</td>\n",
       "      <td>498.0</td>\n",
       "      <td>1.930425</td>\n",
       "      <td>2.666314</td>\n",
       "      <td>72.781980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>370</td>\n",
       "      <td>407</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>220</td>\n",
       "      <td>260</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.0</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.246691</td>\n",
       "      <td>-0.553719</td>\n",
       "      <td>196.378284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>98</td>\n",
       "      <td>368</td>\n",
       "      <td>486</td>\n",
       "      <td>75</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "      <td>214</td>\n",
       "      <td>263</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1159.500000</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>30.995967</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>-1.646515</td>\n",
       "      <td>131.265115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>158</td>\n",
       "      <td>492</td>\n",
       "      <td>457</td>\n",
       "      <td>203</td>\n",
       "      <td>-2</td>\n",
       "      <td>9</td>\n",
       "      <td>226</td>\n",
       "      <td>305</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>460.900000</td>\n",
       "      <td>370.0</td>\n",
       "      <td>197.475543</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2.060318</td>\n",
       "      <td>3.244488</td>\n",
       "      <td>92.225535</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>163</td>\n",
       "      <td>138</td>\n",
       "      <td>270</td>\n",
       "      <td>444</td>\n",
       "      <td>97</td>\n",
       "      <td>262</td>\n",
       "      <td>27</td>\n",
       "      <td>207</td>\n",
       "      <td>276</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>555.882353</td>\n",
       "      <td>556.0</td>\n",
       "      <td>8.525963</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.187149</td>\n",
       "      <td>-1.101203</td>\n",
       "      <td>187.851047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>76</td>\n",
       "      <td>346</td>\n",
       "      <td>463</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>216</td>\n",
       "      <td>254</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1023.250000</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>7.996093</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.157885</td>\n",
       "      <td>-1.293608</td>\n",
       "      <td>872.646176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>102</td>\n",
       "      <td>464</td>\n",
       "      <td>459</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>215</td>\n",
       "      <td>266</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>652.461538</td>\n",
       "      <td>646.0</td>\n",
       "      <td>31.183367</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.254349</td>\n",
       "      <td>-0.953411</td>\n",
       "      <td>344.958851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>356</td>\n",
       "      <td>440</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>15</td>\n",
       "      <td>222</td>\n",
       "      <td>266</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1124.000000</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>33.075671</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-0.221530</td>\n",
       "      <td>-1.372342</td>\n",
       "      <td>467.241572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>84</td>\n",
       "      <td>418</td>\n",
       "      <td>392</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>220</td>\n",
       "      <td>262</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1144.000000</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>20.674346</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.481105</td>\n",
       "      <td>-0.769574</td>\n",
       "      <td>123.061280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>100</td>\n",
       "      <td>422</td>\n",
       "      <td>392</td>\n",
       "      <td>83</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>215</td>\n",
       "      <td>265</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>804.363636</td>\n",
       "      <td>800.0</td>\n",
       "      <td>20.392836</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.381454</td>\n",
       "      <td>-0.685607</td>\n",
       "      <td>244.418751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>74</td>\n",
       "      <td>336</td>\n",
       "      <td>375</td>\n",
       "      <td>77</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>220</td>\n",
       "      <td>257</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rhythm  Rcount_lead1  RRInterval_mean_lead1  RRInterval_median_lead1  \\\n",
       "0          2          12.0             806.545455                    742.0   \n",
       "1          3          17.0             570.000000                    570.0   \n",
       "2          1           9.0            1159.500000                   1156.0   \n",
       "3          3          21.0             460.900000                    370.0   \n",
       "4          3          18.0             555.882353                    556.0   \n",
       "...      ...           ...                    ...                      ...   \n",
       "2125       1           9.0            1023.250000                   1023.0   \n",
       "2126       2          14.0             652.461538                    646.0   \n",
       "2127       1           9.0            1124.000000                   1135.0   \n",
       "2128       1           8.0            1144.000000                   1148.0   \n",
       "2129       2          12.0             804.363636                    800.0   \n",
       "\n",
       "      RRInterval_std_lead1  RRInterval_range_lead1  RRInterval_skew_lead1  \\\n",
       "0               139.662166                   498.0               1.930425   \n",
       "1                 3.316625                    12.0               0.246691   \n",
       "2                30.995967                    80.0               0.143027   \n",
       "3               197.475543                   740.0               2.060318   \n",
       "4                 8.525963                    28.0              -0.187149   \n",
       "...                    ...                     ...                    ...   \n",
       "2125              7.996093                    24.0              -0.157885   \n",
       "2126             31.183367                   104.0               0.254349   \n",
       "2127             33.075671                    98.0              -0.221530   \n",
       "2128             20.674346                    66.0              -0.481105   \n",
       "2129             20.392836                    68.0               0.381454   \n",
       "\n",
       "      RRInterval_kurtosis_lead1  \\\n",
       "0                      2.666314   \n",
       "1                     -0.553719   \n",
       "2                     -1.646515   \n",
       "3                      3.244488   \n",
       "4                     -1.101203   \n",
       "...                         ...   \n",
       "2125                  -1.293608   \n",
       "2126                  -0.953411   \n",
       "2127                  -1.372342   \n",
       "2128                  -0.769574   \n",
       "2129                  -0.685607   \n",
       "\n",
       "      R_peaks_amplitude_from_isoelectric_mean_lead1  PRovercount_lead1  ...  \\\n",
       "0                                         72.781980           1.000000  ...   \n",
       "1                                        196.378284           1.000000  ...   \n",
       "2                                        131.265115           1.000000  ...   \n",
       "3                                         92.225535           0.857143  ...   \n",
       "4                                        187.851047           1.000000  ...   \n",
       "...                                             ...                ...  ...   \n",
       "2125                                     872.646176           1.000000  ...   \n",
       "2126                                     344.958851           1.000000  ...   \n",
       "2127                                     467.241572           1.000000  ...   \n",
       "2128                                     123.061280           1.000000  ...   \n",
       "2129                                     244.418751           1.000000  ...   \n",
       "\n",
       "      AtrialRate  QRSDuration  QTInterval  QTCorrected  RAxis  TAxis  \\\n",
       "0             73           80         370          407     88     58   \n",
       "1            105           98         368          486     75     52   \n",
       "2             52          158         492          457    203     -2   \n",
       "3            163          138         270          444     97    262   \n",
       "4            108           76         346          463     18     50   \n",
       "...          ...          ...         ...          ...    ...    ...   \n",
       "2125          59          102         464          459     25     15   \n",
       "2126          92           88         356          440     65     48   \n",
       "2127          53           84         418          392     24     22   \n",
       "2128          52          100         422          392     83     70   \n",
       "2129          75           74         336          375     77     47   \n",
       "\n",
       "      QRSCount  QOnset  QOffset  TOffset  \n",
       "0           12     220      260      405  \n",
       "1           17     214      263      398  \n",
       "2            9     226      305      472  \n",
       "3           27     207      276      342  \n",
       "4           18     216      254      389  \n",
       "...        ...     ...      ...      ...  \n",
       "2125        10     215      266      447  \n",
       "2126        15     222      266      400  \n",
       "2127         9     220      262      429  \n",
       "2128         8     215      265      426  \n",
       "2129        12     220      257      388  \n",
       "\n",
       "[2130 rows x 226 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./data_test_frequency_merge.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (4258, 225)\n",
      "Vallidation: (4258, 225)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train , test_size=0.5, shuffle=True, stratify=y_train, random_state=119)\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Vallidation: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24995376, 0.70945293, 0.73244118, ..., 0.74074074, 0.20731707,\n",
       "        0.56478405],\n",
       "       [0.43746532, 0.39491557, 0.39353334, ..., 0.62962963, 0.06097561,\n",
       "        0.40199336],\n",
       "       [0.46871725, 0.37533379, 0.36343297, ..., 0.7037037 , 0.18292683,\n",
       "        0.42192691],\n",
       "       ...,\n",
       "       [0.37496147, 0.48206922, 0.44593027, ..., 0.77777778, 0.24390244,\n",
       "        0.44186047],\n",
       "       [0.31245762, 0.55962428, 0.55741311, ..., 0.75308642, 0.1097561 ,\n",
       "        0.45847176],\n",
       "       [0.31245762, 0.56546406, 0.59754694, ..., 0.81481481, 0.23170732,\n",
       "        0.5282392 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_clf = RandomForestClassifier(criterion= 'log_loss', max_depth= 5, max_features= 'sqrt', n_estimators= 1000)\n",
    "ab_clf = AdaBoostClassifier(algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 50)\n",
    "knn_clf = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "svc_clf = SVC(C= 100, gamma= 'scale', kernel= 'rbf', probability= True)\n",
    "xgb_clf = XGBClassifier(gamma= 0,learning_rate= 0.1,max_depth= 5,min_child_weight= 1,n_estimators= 1000)\n",
    "dt_clf = DecisionTreeClassifier(criterion= 'entropy',max_depth= 5,max_features= 'sqrt',splitter= 'best')\n",
    "lr_clf = LogisticRegression(C= 0.14, max_iter= 20, multi_class= 'auto', n_jobs= -1, penalty= 'l2', solver= 'sag', tol= 0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.14, max_iter=20, n_jobs=-1, solver=&#x27;sag&#x27;, tol=0.015)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.14, max_iter=20, n_jobs=-1, solver=&#x27;sag&#x27;, tol=0.015)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.14, max_iter=20, n_jobs=-1, solver='sag', tol=0.015)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện các mô hình con\n",
    "# rf_clf.fit(x_train,y_train)\n",
    "ab_clf.fit(x_train, y_train)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "svc_clf.fit(x_train, y_train)\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "dt_clf.fit(x_train,y_train)\n",
    "lr_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập huấn luyện để tạo đặc trưng mới cho mô hình blending\n",
    "X_train_meta = np.column_stack((\n",
    "    # rf_clf.predict_proba(x_val),\n",
    "    ab_clf.predict_proba(x_val),\n",
    "    knn_clf.predict_proba(x_val),\n",
    "    svc_clf.predict_proba(x_val),\n",
    "    xgb_clf.predict_proba(x_val),\n",
    "    dt_clf.predict_proba(x_val),\n",
    "    lr_clf.predict_proba(x_val),\n",
    "))\n",
    "# Dự đoán trên tập kiểm tra để tạo đặc trưng mới cho mô hình blending\n",
    "X_test_meta = np.column_stack((\n",
    "    # rf_clf.predict_proba(x_test),\n",
    "    ab_clf.predict_proba(x_test),\n",
    "    knn_clf.predict_proba(x_test),\n",
    "    svc_clf.predict_proba(x_test),\n",
    "    xgb_clf.predict_proba(x_test),\n",
    "    dt_clf.predict_proba(x_test),\n",
    "    lr_clf.predict_proba(x_test)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_meta:(4258, 24)\n",
      "X_test_meta:(2130, 24)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_meta:{X_train_meta.shape}\")\n",
    "print(f\"X_test_meta:{X_test_meta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.964, test=0.956) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.959, test=0.960) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.959, test=0.963) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.967, test=0.958) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.965, test=0.957) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.962, test=0.962) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.965, test=0.959) total time=   0.3s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.966, test=0.961) total time=   0.3s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.963, test=0.965) total time=   0.3s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.966, test=0.960) total time=   4.5s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.965, test=0.960) total time=   4.3s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.963, test=0.963) total time=   4.6s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.963, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.965, test=0.960) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.961, test=0.963) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.963, test=0.956) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.965, test=0.960) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.965, test=0.965) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.966, test=0.959) total time=   0.3s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.965, test=0.960) total time=   0.3s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.964, test=0.964) total time=   0.3s\n",
      "[CV 1/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.966, test=0.958) total time=   3.5s\n",
      "[CV 2/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.965, test=0.960) total time=   3.4s\n",
      "[CV 3/3] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.963, test=0.963) total time=   3.4s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.969, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.966, test=0.962) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.965, test=0.963) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.969, test=0.958) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.969, test=0.961) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.967, test=0.964) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.970, test=0.958) total time=   0.3s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.969, test=0.961) total time=   0.3s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.968, test=0.966) total time=   0.3s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.968, test=0.956) total time=   4.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.968, test=0.961) total time=   4.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.967, test=0.964) total time=   4.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.969, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.965, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.966, test=0.960) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.968, test=0.958) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.967, test=0.961) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.968, test=0.966) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.970, test=0.957) total time=   0.4s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.968, test=0.959) total time=   0.6s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.966, test=0.964) total time=   0.4s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.969, test=0.958) total time=   4.5s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.968, test=0.961) total time=   4.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.967, test=0.965) total time=   3.9s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.971, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.970, test=0.963) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.971, test=0.962) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.971, test=0.960) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.969, test=0.963) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.970, test=0.967) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.971, test=0.960) total time=   0.4s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.969, test=0.963) total time=   0.4s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.970, test=0.968) total time=   0.3s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.971, test=0.960) total time=   4.7s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.969, test=0.962) total time=   4.8s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.970, test=0.966) total time=   4.7s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.970, test=0.959) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.969, test=0.964) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.969, test=0.965) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.971, test=0.960) total time=   0.1s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.969, test=0.963) total time=   0.1s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.969, test=0.968) total time=   0.1s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.971, test=0.959) total time=   0.4s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.970, test=0.963) total time=   0.4s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.969, test=0.965) total time=   0.4s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.971, test=0.961) total time=   4.7s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.969, test=0.962) total time=   4.8s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.970, test=0.965) total time=   4.8s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.964, test=0.961) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.961, test=0.956) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.959, test=0.966) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.965, test=0.960) total time=   0.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.967, test=0.958) total time=   0.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.963, test=0.963) total time=   0.2s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.967, test=0.957) total time=   0.4s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.965, test=0.961) total time=   0.4s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.964, test=0.965) total time=   0.4s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.966, test=0.960) total time=   4.7s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.966, test=0.960) total time=   4.7s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.963, test=0.963) total time=   4.8s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.967, test=0.955) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.963, test=0.959) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.963, test=0.961) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.967, test=0.957) total time=   0.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.965, test=0.960) total time=   0.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.962, test=0.965) total time=   0.1s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.966, test=0.958) total time=   0.4s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.965, test=0.961) total time=   0.4s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.963, test=0.965) total time=   0.4s\n",
      "[CV 1/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.967, test=0.960) total time=   4.7s\n",
      "[CV 2/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.966, test=0.959) total time=   4.7s\n",
      "[CV 3/3] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.963, test=0.963) total time=   4.7s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.968, test=0.959) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.968, test=0.962) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.967, test=0.959) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.969, test=0.959) total time=   0.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.967, test=0.961) total time=   0.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.966, test=0.966) total time=   0.2s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.970, test=0.961) total time=   0.5s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.967, test=0.961) total time=   0.5s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.967, test=0.965) total time=   0.5s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.969, test=0.960) total time=   5.5s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.968, test=0.961) total time=   5.6s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.967, test=0.964) total time=   5.5s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.965, test=0.956) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.967, test=0.961) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.963, test=0.965) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.969, test=0.962) total time=   0.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.968, test=0.962) total time=   0.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.966, test=0.964) total time=   0.2s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.970, test=0.960) total time=   0.5s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.969, test=0.962) total time=   0.5s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.967, test=0.965) total time=   0.5s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.969, test=0.960) total time=   5.6s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.969, test=0.961) total time=   5.8s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.967, test=0.965) total time=   5.4s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.970, test=0.960) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.969, test=0.961) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.967, test=0.968) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.972, test=0.961) total time=   0.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.969, test=0.961) total time=   0.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.969, test=0.965) total time=   0.2s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.971, test=0.958) total time=   0.5s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.969, test=0.962) total time=   0.5s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.969, test=0.966) total time=   0.5s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.971, test=0.961) total time=   6.1s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.969, test=0.963) total time=   6.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.969, test=0.965) total time=   6.3s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.971, test=0.961) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.969, test=0.962) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.969, test=0.965) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.970, test=0.959) total time=   0.2s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.969, test=0.962) total time=   0.2s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.968, test=0.964) total time=   0.2s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.971, test=0.959) total time=   0.5s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.970, test=0.963) total time=   0.6s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.970, test=0.965) total time=   0.5s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.971, test=0.961) total time=   6.1s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.969, test=0.963) total time=   5.9s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.970, test=0.965) total time=   6.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.967, test=0.954) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.964, test=0.960) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=10;, score=(train=0.963, test=0.961) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.966, test=0.958) total time=   0.2s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.966, test=0.962) total time=   0.2s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=50;, score=(train=0.962, test=0.962) total time=   0.2s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.965, test=0.958) total time=   0.5s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.965, test=0.959) total time=   0.4s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100;, score=(train=0.962, test=0.964) total time=   0.4s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.967, test=0.958) total time=   4.6s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.965, test=0.961) total time=   4.6s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000;, score=(train=0.963, test=0.965) total time=   4.7s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.966, test=0.953) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.964, test=0.960) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=10;, score=(train=0.963, test=0.966) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.967, test=0.958) total time=   0.1s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.967, test=0.958) total time=   0.1s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=50;, score=(train=0.961, test=0.961) total time=   0.1s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.966, test=0.958) total time=   0.4s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.966, test=0.961) total time=   0.4s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100;, score=(train=0.962, test=0.963) total time=   0.4s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.967, test=0.958) total time=   4.6s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.966, test=0.960) total time=   4.5s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000;, score=(train=0.963, test=0.965) total time=   4.6s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.968, test=0.958) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.965, test=0.960) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=10;, score=(train=0.964, test=0.968) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.970, test=0.959) total time=   0.2s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.968, test=0.962) total time=   0.2s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=50;, score=(train=0.966, test=0.965) total time=   0.2s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.968, test=0.960) total time=   0.5s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.968, test=0.961) total time=   0.5s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.967, test=0.965) total time=   0.4s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.969, test=0.958) total time=   5.4s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.969, test=0.961) total time=   5.4s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=sqrt, n_estimators=1000;, score=(train=0.967, test=0.965) total time=   6.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.969, test=0.962) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.967, test=0.958) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=10;, score=(train=0.965, test=0.966) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.969, test=0.957) total time=   0.2s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.967, test=0.963) total time=   0.2s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=50;, score=(train=0.966, test=0.965) total time=   0.2s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.969, test=0.959) total time=   0.4s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.969, test=0.961) total time=   0.4s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.966, test=0.967) total time=   0.5s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.969, test=0.960) total time=   5.5s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.968, test=0.961) total time=   5.7s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=4, max_features=log2, n_estimators=1000;, score=(train=0.967, test=0.965) total time=   5.5s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.969, test=0.957) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.968, test=0.963) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=10;, score=(train=0.968, test=0.965) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.970, test=0.960) total time=   0.2s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.969, test=0.963) total time=   0.2s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=50;, score=(train=0.969, test=0.965) total time=   0.2s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.970, test=0.961) total time=   0.6s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.970, test=0.963) total time=   0.5s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.969, test=0.965) total time=   0.5s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.971, test=0.961) total time=   6.2s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.969, test=0.963) total time=   6.3s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=sqrt, n_estimators=1000;, score=(train=0.969, test=0.965) total time=   6.3s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.972, test=0.963) total time=   0.0s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.968, test=0.962) total time=   0.0s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=10;, score=(train=0.969, test=0.958) total time=   0.0s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.971, test=0.960) total time=   0.2s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.971, test=0.964) total time=   0.2s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=50;, score=(train=0.969, test=0.965) total time=   0.2s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.971, test=0.960) total time=   0.5s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.969, test=0.963) total time=   0.5s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.969, test=0.964) total time=   0.5s\n",
      "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.971, test=0.960) total time=   6.2s\n",
      "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.970, test=0.963) total time=   6.2s\n",
      "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=log2, n_estimators=1000;, score=(train=0.970, test=0.965) total time=   6.2s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = RandomForestClassifier()\n",
    "params = {\n",
    "    'n_estimators': [10,50,100,1000],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [3,4,5],\n",
    "    'max_features':['sqrt', 'log2'],\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(X_train_meta,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(X_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9635988115680222"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAGwCAYAAADrIxwOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABW9klEQVR4nO3deVxUZfs/8M+BgRl2WYQBRUBBFJdyy60eN5Qsy36Wy6OWFpqlaaSmqaXkk5D2pJY+ablBmmmLWvktUywtU1NQc9dSRFBGXJCdWc/vD3J0BIxxzjAM83m/XudVc5/73HPNgDMX132fcwRRFEUQERERScjJ1gEQERFR/cMEg4iIiCTHBIOIiIgkxwSDiIiIJMcEg4iIiCTHBIOIiIgkxwSDiIiIJCezdQD2xmAw4PLly/Dy8oIgCLYOh4iIzCSKIoqKihASEgInJ+v8nV1eXg6NRiPJWK6urlAoFJKMVZuYYJjp8uXLCA0NtXUYRERkoezsbDRu3FjyccvLyxER5glVnl6S8ZRKJTIzM+0uyWCCYSYvLy8AQEjSTDjZ2Q/bXkVOzrB1CI6H1bla5eTuZusQHIpO1OKX0q+Mn+dS02g0UOXpkZURDm8vyyokhUUGhHW4AI1GwwSjvrs1LeKkUMDJzb5+2PZKJrjYOgTHwwSjVjkJrrYOwSFZe5rb00uAp5dlz2GA/f5bZIJBRERkBXrRAL2Fd/vSiwZpgrEBJhhERERWYIAIAyzLMCw93pZ4mioRERFJjhUMIiIiKzDAAEsnOCwfwXaYYBAREVmBXhShFy2b4rD0eFviFAkRERFJjhUMIiIiK3D0RZ5MMIiIiKzAABF6B04wOEVCREREkmMFg4iIyAo4RUJERESS41kkRERERBJjBYOIiMgKDH9vlo5hr5hgEBERWYFegrNILD3elphgEBERWYFehAR3U5UmFlvgGgwiIiKSHCsYREREVsA1GERERCQ5AwToIVg8hr3iFAkRERFJjhUMIiIiKzCIFZulY9grJhhERERWoJdgisTS422JUyREREQkOVYwiIiIrMDRKxhMMIiIiKzAIAowiBaeRWLh8bbEKRIiIiKSHCsYREREVsApEiIiIpKcHk7QWzhRoJcoFltggkFERGQFogRrMESuwSAiIiK6jQkGERGRFdxag2HpZo7w8HAIglBpmzBhAgBAFEUkJiYiJCQEbm5u6NmzJ06cOGEyhlqtxsSJExEQEAAPDw88+eSTyMnJMfv1M8EgIiKyAr3oJMlmjoMHDyI3N9e47dixAwAwePBgAMCCBQuwcOFCLF26FAcPHoRSqUTfvn1RVFRkHCMhIQGbN2/Ghg0bsGfPHhQXF2PAgAHQ681bEcI1GERERHVcYWGhyWO5XA65XF6pX8OGDU0ev/vuu2jWrBl69OgBURSxePFizJo1C4MGDQIApKamIigoCOvXr8e4ceNQUFCAVatWYe3atYiNjQUArFu3DqGhoUhLS0NcXFyNY2YFg4iIyAoMEGCAk4VbxRRJaGgofHx8jFtycvI/Pr9Go8G6devwwgsvQBAEZGZmQqVSoV+/fsY+crkcPXr0wN69ewEAGRkZ0Gq1Jn1CQkLQunVrY5+aYgWDiIjICqS8DkZ2dja8vb2N7VVVL+62ZcsW3Lx5E6NHjwYAqFQqAEBQUJBJv6CgIGRlZRn7uLq6wtfXt1KfW8fXFBMMIiKiOs7b29skwaiJVatWoX///ggJCTFpFwTTpEcUxUptd6tJn7txioSIiMgKbLHI85asrCykpaVhzJgxxjalUgkAlSoReXl5xqqGUqmERqNBfn5+tX1qigkGERGRFVSswbB8ux9r1qxBYGAgHn/8cWNbREQElEql8cwSoGKdxu7du9GtWzcAQIcOHeDi4mLSJzc3F8ePHzf2qSlOkRAREdUjBoMBa9aswahRoyCT3f6aFwQBCQkJSEpKQlRUFKKiopCUlAR3d3cMHz4cAODj44P4+HhMmTIF/v7+8PPzw9SpU9GmTRvjWSU1xQSjnvDddhkNv81Bfq8gXB0cBgDwPHwDPnvyoLhYCucSHbJmtII61MPkOJ89efA6eB3y7BI4lxvw13/bw+DOX4v7NfSVK+j+WAFCI9XQlDvhZLo7Vs0LRs45ha1Dq7dGTs7Fs1OumLTdyJPh3+1a2yii+mPIuBx073cdjZuWQaN2wslD3lj9XhguZboZ+/zwZ9VnFqycH4avVzaqrVDrJIME9yIxQDT7mLS0NFy8eBEvvPBCpX3Tpk1DWVkZxo8fj/z8fHTu3Bnbt2+Hl5eXsc+iRYsgk8kwZMgQlJWVoU+fPkhJSYGzs7NZcfCbpB6QXyhGg9/yoG7kZtIuaAwoa+aFovZ+UH52ocpjBY0BJTE+KInxQcNvzL9SG5lq27UE36UE4OwRdzjLRIyenoukz89jbI9oqMvM+8dJNXfhtAJvDGtmfGzQ2+/9G+qSNg8V4rvPgnH2qCecZSJGTb6IeWtOYFz/dsbf5+FdO5oc07FHPhKSzuG3H/1tEXKdYskaittjmJ9g9OvXD2I1xwmCgMTERCQmJlZ7vEKhwJIlS7BkyRKzn/tOdXoNxt69e+Hs7IxHH33UpP3ChQtVXgp15MiRJvuPHDlSZX9XV1dERkbinXfeqfaHYC+Ecj2CU87hyogI6O+qPBR1DsCNxxqhtIVPtcff7K1EflwIyiM8rR2qQ5g1oil2fOGHrLMKnD/phvdfa4KgxlpEtS2zdWj1ml4P5F91MW4FN/i3kxTeio9B2qZAXPzLHZmnPbDojUgENdIgqnWxsU/+NVeTrUuffBzd7wNVNqt2ll8Do2KzV3X6X+Hq1asxceJErFy5EhcvXkSTJk1M9qelpaFVq1bGx25ubncPUWV/tVqNPXv2YMyYMQgODkZ8fLxV4q8NgRsvoKR1A5S28IHfD5dtHQ7dxcO74tK6RTdZvbCmRhEarM84Dq3GCacPu2PNu8FQXfzn6wSQedw9dQCAoptVf3U08NfgoZ75eH96ZG2GRXVUnU0wSkpK8MUXX+DgwYNQqVRISUnB7NmzTfr4+/sbT7upiTv7h4WFYfXq1Th06NA9Ewy1Wg21Wm18fPflWm3JK/06FNmluDi91T93JhsQ8WLiZRz/3QNZZ+6d/NL9O33YA++96oac83L4NtTh35NUWPTNn3ixdwsU5dfZjzg7JOLFmRdw/KAXsv70qLJH7KCrKCtx5vTI3/SiAL2Ft1u39HhbqrO1l40bNyI6OhrR0dEYOXIk1qxZI+l0Rnp6Og4dOoTOnTvfs19ycrLJ5VlDQ0Mli8ESshtqNPwyC7mjm0F0qbM/Roc2IekSIlqWIXl8k3/uTPct/Wdv7Pm+AS6cdsPhX73w1nNNAQB9B9+wcWT1y/g5mYiILsX8yc2r7dPv6Tz8/G0AtBp+JgGA/u9FnpZu9qrORr5q1SrjmopHH30UxcXF2Llzp0mfbt26wdPT07gdPnz4nmPe6u/q6opOnTphyJAheO655+55zIwZM1BQUGDcsrOzLXthEpFfLIWsSIewd48j6pUDiHrlANz/LEKDXVcQ9coBwGDfa0vs3fh3ctC1XyGmPdMM13JdbR2OQ1GXOePCaQUaRaj/uTPVyMtvnUeXPjcw/dlWuKaqeuqpVcdChDYrw7YvzbsYE9VfdbJ+eObMGRw4cACbNm0CAMhkMgwdOhSrV682OQ9348aNaNmypfHxP1UXbvXXarU4duwYJk2aBF9fX7z77rvVHlPdHetsrbSFNy68aXoanvLTTGiUCtzoFww42W9Zzb6JmDDvEro9WoDXn4nEley697tT37m4GhAapcbx37lw2XIiXp6diW59b2D6yFa4klP9ws24wVdw9pgHMk9XPX3iiAyiEwwWnkVisOMTEepkgrFq1SrodDo0anT7HGpRFOHi4mJy+dLQ0FBERtZ8MdGd/Vu2bInz58/jrbfeQmJiIhQK+1rxLCqcoQlxN2kzyJ2g95AZ251KdHC5oYasQAsAcLlSDgDQebtA71PxV7VzgQayQi1crlbsk18ug0HuBK2fHAaPOvnrUae9knQJvf5fPhKfj0BZsRN8G1a89yVFztCU19mCoV0b+9Yl7N/hg7xLLmgQoMPwV6/A3VOPHV/62To0uzch8Tx6PnENc19ugbISZ/gGaAD8/fusvr1w2d1Th0cevY4V74bbKNK6SYopDv19XAejrqhz3yA6nQ6ffvop3n//fZPbxQLA008/jc8++wwDBgyQ5LmcnZ2h0+mg0WjsLsGoCc+j+VCuzTQ+Dll9DgBw/bEQXB/QGADQ4Nc8+H9/++yT0IWnAACqZyNQ2LVhLUZbPzwx+joA4L+bzpm0/zchFDu+4BeeNQQEazHjfxfg7adHwXUZTh9yR8ITzZF3iVNTlhowouICZgs+O2HS/v70SKRtCjQ+7vH4NUAAdn0XUKvxUd1W5xKMrVu3Ij8/H/Hx8fDxMb1+wzPPPINVq1bdd4Jx/fp1qFQq6HQ6HDt2DB988AF69epl9h3q6qqc11qaPC7s2vAfk4TrAxobkw2yXFzIA7YOweEkjw+3dQj1Vv+omt174oeNSvywseZn9DkKAyw/C8QgTSg2UecSjFWrViE2NrZScgFUVDCSkpJw48b9rQ6/tX7D2dkZwcHBeOyxxzBv3jyL4iUiIqqKFBfK4oW2JPTdd99Vu699+/bGU1XvdcpqeHi4yf67HxMREZF11bkEg4iIqD6Q5l4krGAQERHRHQwQYIClazDs95IDTDCIiIiswNErGPYbOREREdVZrGAQERFZgTQX2rLfOgATDCIiIiswiAIMll4Hg3dTJSIiIrqNFQwiIiIrMEgwRcILbREREZEJae6mar8Jhv1GTkRERHUWKxhERERWoIcAvYUXyrL0eFtigkFERGQFnCIhIiIikhgrGERERFagh+VTHHppQrEJJhhERERW4OhTJEwwiIiIrIA3OyMiIiKSGCsYREREViBCgMHCNRgiT1MlIiKiO3GKhIiIiEhirGAQERFZgaPfrp0JBhERkRXoJbibqqXH25L9Rk5ERER1FisYREREVsApEiIiIpKcAU4wWDhRYOnxtmS/kRMREVGdxQSDiIjICvSiIMlmrkuXLmHkyJHw9/eHu7s7HnzwQWRkZBj3i6KIxMREhISEwM3NDT179sSJEydMxlCr1Zg4cSICAgLg4eGBJ598Ejk5OWbFwQSDiIjICm6twbB0M0d+fj66d+8OFxcX/PDDDzh58iTef/99NGjQwNhnwYIFWLhwIZYuXYqDBw9CqVSib9++KCoqMvZJSEjA5s2bsWHDBuzZswfFxcUYMGAA9Pqa39+VazCIiIisQJTgbqri38cXFhaatMvlcsjl8kr958+fj9DQUKxZs8bYFh4efsd4IhYvXoxZs2Zh0KBBAIDU1FQEBQVh/fr1GDduHAoKCrBq1SqsXbsWsbGxAIB169YhNDQUaWlpiIuLq1HsrGAQERHVcaGhofDx8TFuycnJVfb79ttv0bFjRwwePBiBgYFo164dVqxYYdyfmZkJlUqFfv36Gdvkcjl69OiBvXv3AgAyMjKg1WpN+oSEhKB169bGPjXBCgYREZEV6CFAb+HNym4dn52dDW9vb2N7VdULADh//jyWLVuGyZMnY+bMmThw4AAmTZoEuVyO5557DiqVCgAQFBRkclxQUBCysrIAACqVCq6urvD19a3U59bxNcEEg4iIyAoMouXXsTCIFf/19vY2STCq7W8woGPHjkhKSgIAtGvXDidOnMCyZcvw3HPPGfsJgmlcoihWartbTfrciVMkRERE9URwcDBiYmJM2lq2bImLFy8CAJRKJQBUqkTk5eUZqxpKpRIajQb5+fnV9qkJJhhERERWYPh7kaelmzm6d++OM2fOmLSdPXsWYWFhAICIiAgolUrs2LHDuF+j0WD37t3o1q0bAKBDhw5wcXEx6ZObm4vjx48b+9QEp0iIiIiswAABBgvXYJh7/GuvvYZu3bohKSkJQ4YMwYEDB/DJJ5/gk08+AVAxNZKQkICkpCRERUUhKioKSUlJcHd3x/DhwwEAPj4+iI+Px5QpU+Dv7w8/Pz9MnToVbdq0MZ5VUhNMMIiIiOqJTp06YfPmzZgxYwbmzp2LiIgILF68GCNGjDD2mTZtGsrKyjB+/Hjk5+ejc+fO2L59O7y8vIx9Fi1aBJlMhiFDhqCsrAx9+vRBSkoKnJ2daxyLIIqiKOmrq+cKCwvh4+ODxgvnwslNYetwHELz8QdsHYLjMWMhF1nOyd3d1iE4FJ2owU8ln6OgoKBGCyfNdet7YvhPw+Hq6WrRWJpiDdb3Xm+1WK2JFQwiIiIruJ81FFWNYa+YYNynyMkZkAkutg7DIfx4+YitQ3A4cSEP2joEh2IoKbF1CA7FIGptHYJDYIJBRERkBQaYfy+RqsawV0wwiIiIrECU4CwSkQkGERER3el+7oZa1Rj2yn5XjxAREVGdxQoGERGRFfAsEiIiIpIcp0iIiIiIJMYKBhERkRXY4l4kdQkTDCIiIivgFAkRERGRxFjBICIisgJHr2AwwSAiIrICR08wOEVCREREkmMFg4iIyAocvYLBBIOIiMgKRFh+mqkoTSg2wQSDiIjIChy9gsE1GERERCQ5VjCIiIiswNErGEwwiIiIrMDREwxOkRAREZHkWMEgIiKyAkevYDDBICIisgJRFCBamCBYerwtcYqEiIiIJMcKBhERkRUYIFh8oS1Lj7clJhhERERW4OhrMDhFQkRERJJjBYOIiMgKHH2RJxMMIiIiK3D0KRImGERERFbg6BUMrsEgIiIiybGCQUREZAWiBFMk9lzBYIJBRERkBSIAUbR8DHvFKRIiIiKSHCsYREREVmCAAMGBr+TJCgYREZEV3DqLxNLNHImJiRAEwWRTKpV3xCQiMTERISEhcHNzQ8+ePXHixAmTMdRqNSZOnIiAgAB4eHjgySefRE5OjtmvnwkGERFRPdKqVSvk5uYat2PHjhn3LViwAAsXLsTSpUtx8OBBKJVK9O3bF0VFRcY+CQkJ2Lx5MzZs2IA9e/aguLgYAwYMgF6vNysOTpEQERFZgUEUINjgQlsymcykanGLKIpYvHgxZs2ahUGDBgEAUlNTERQUhPXr12PcuHEoKCjAqlWrsHbtWsTGxgIA1q1bh9DQUKSlpSEuLq7GcbCCQUREZAWiKM0GAIWFhSabWq2u9nn//PNPhISEICIiAsOGDcP58+cBAJmZmVCpVOjXr5+xr1wuR48ePbB3714AQEZGBrRarUmfkJAQtG7d2tinpphgEBER1XGhoaHw8fExbsnJyVX269y5Mz799FP8+OOPWLFiBVQqFbp164br169DpVIBAIKCgkyOCQoKMu5TqVRwdXWFr69vtX1qilMkREREViDlpcKzs7Ph7e1tbJfL5VX279+/v/H/27Rpg65du6JZs2ZITU1Fly5dAACCYBqTKIqV2irH8c997sYKBhERkRVIeRaJt7e3yVZdgnE3Dw8PtGnTBn/++adxXcbdlYi8vDxjVUOpVEKj0SA/P7/aPjXFCkY9N+C5a3j8uesICtUAALLOKPDZoiCk/+z9D0fS3Z57KAZXclwrtT8x6ipeSb6EuJAHqzxuzJuXMHj8VZM2UQTeHNkU6T97Y86qTHTrX2CNkB1C687FGDz+KqLalMJfqUPiC+HYt83H1mHVewNGXcPgl6/CL1CLrLMKLJ8dguMHPG0dVp1iq0Wed1Kr1Th16hQeeeQRREREQKlUYseOHWjXrh0AQKPRYPfu3Zg/fz4AoEOHDnBxccGOHTswZMgQAEBubi6OHz+OBQsWmPXc9aqCkZeXh3HjxqFJkyaQy+VQKpWIi4vDvn37AADh4eHG84KdnZ0REhKC+Pj4SplafXI11wWrk4IxsX9zTOzfHH/85onENRcQ1rzc1qHZnQ9/OIPPjxw3bskb/gIAPPJERXJw577PjxzH5IUXIQgiHn68cvKweUVDmFltpGoo3A04f0KB/81qZOtQHEaPJ/Px0tuX8fmHgRjfrzmO/+6Bdz7LRMNGGluH5vCmTp2K3bt3IzMzE7///jueeeYZFBYWYtSoURAEAQkJCUhKSsLmzZtx/PhxjB49Gu7u7hg+fDgAwMfHB/Hx8ZgyZQp27tyJw4cPY+TIkWjTpo3xrJKaqlcVjKeffhparRapqalo2rQprly5gp07d+LGjRvGPnPnzsXYsWOh1+tx9uxZvPjii5g0aRLWrl1rw8it5/cdpn/JpcwPxoDnrqNFhxJknVXYKCr71MDf9BzwjUt9EByuRtuuxQAAv0Cdyf59P/rgge7FCA4z/dA9d0KBrz9uiCU/nMW/H2xt3aAdQPrP3ndU5LJsGoujGPTiNfz4uR+2rfcHACyf0wgdehZhwHPXsSY52MbR1R13ngViyRjmyMnJwb///W9cu3YNDRs2RJcuXbB//36EhYUBAKZNm4aysjKMHz8e+fn56Ny5M7Zv3w4vLy/jGIsWLYJMJsOQIUNQVlaGPn36ICUlBc7OzmbFUm8SjJs3b2LPnj3YtWsXevToAQAICwvDQw89ZNLPy8vLOA/VqFEjPPfcc9iwYUOtx2sLTk4iHnniJuTuBpxK97B1OHZNqxHw09e+GDQur8pKRP5VGQ7s9MbUxaZfeOWlAt4dH44J83IqJSRE9kDmYkBU21JsXBpo0p6x2wsxHUtsFFXdVJFgWLrI07z+//R9JggCEhMTkZiYWG0fhUKBJUuWYMmSJeY9+V3qTYLh6ekJT09PbNmyBV26dKnRAphLly5h69at6Ny5c7V91Gq1yfnGhYWFksRbm8JblGHxd3/BVW5AWYkT5saH4+KfrF5YYu82HxQXOqPfkBtV7t/xhR/cPPV4+DHT6ZGPExshpmMJuj1qf79HRADg7aeHswy4ec306+PmVRl8mTTTHerNGgyZTIaUlBSkpqaiQYMG6N69O2bOnImjR4+a9Js+fTo8PT3h5uaGxo0bQxAELFy4sNpxk5OTTc49Dg0NtfZLkVzOOTnG922OVwdEYeunAZj6wUU0ieIaDEv8+LkfOvUqhL+y6g/UHzf4off/y4er4vafH/t+9MaR37zw0txLtRUmkdXc/Ze1IMC+7y1uBba4F0ldUm8SDKBiDcbly5fx7bffIi4uDrt27UL79u2RkpJi7PP666/jyJEjOHr0KHbu3AkAePzxx6u9xvqMGTNQUFBg3LKzs2vjpUhKp3XC5Qty/HnUHWuSg5F50g1Pjbn6zwdSla7kuODwr154dPj1Kvcf+90DOecUlfYf+c0LuRdcMahFG/QPfQD9Qx8AAPxnbDhefzrS6nETSaHwhjP0OsC3oWly7ROgQ/7VelMUl4Qo0Wav6t1vg0KhQN++fdG3b1/Mnj0bY8aMwZw5czB69GgAQEBAACIjKz7Mo6KisHjxYnTt2hU///xzlStk5XJ5jc83ticurvb8a2tb2zf4o0GADp1jq57m+PFzf0S1LUWzVqZVoqGvXEH/u5KOcb1bYFziJXTpxykTsg86rRP+POqO9v8qwt47Tgdu/68i7PuRpwfTbfUuwbhbTEwMtmzZUu3+W6tiy8rKaimi2vX8G7k4+JMXrl52hZunHj0H3kTbbsV4c0RTW4dmlwwGYPtGP8QOvgHnKv71lBQ54ZfvfPDinMuV9vkF6qpc2BnYSAtlE57ed78U7nqERNx+/5ShGjRtVYaim864eqnydUvIcps+CcDrH2bj7FE3nEr3wGMjryOwkRb/96m/rUOrU6S8kqc9qjcJxvXr1zF48GC88MILaNu2Lby8vJCeno4FCxZg4MCBxn5FRUVQqVQQRRHZ2dmYNm0aAgIC0K1bNxtGbz0NGurw+pKL8AvUobTIGZmnFHhzRFMc+sXrnw+mSg7/4oW8S66IG1b14s7d3/gCooBeT9Xfa6vUNc0fKMN7X58zPn7p7YrkbvtGX7z/WhNbhVWv7f7WF16+eox47Qr8AnXIOqPAmyMjkMeEzpQUcxx2XGwWRNHSs3TrBrVajcTERGzfvh3nzp2DVqtFaGgoBg8ejJkzZ8LNzQ3h4eHIyrp92mDDhg3RqVMnzJs3Dw8++GCNnqewsBA+Pj7oiYGQCS5WejV0px8vH7F1CA6nuquSEtUHOlGLXfgGBQUFJvf3kMqt74mmKbPg5G7ZGXuG0nKcHz3ParFaU72pYMjlciQnJ1d7hzkAuHDhQu0FRERE5MDqTYJBRERUl9jiSp51CRMMIiIiK3D0RZ716joYREREVDewgkFERGQNolCxWTqGnWKCQUREZAWOvgaDUyREREQkOVYwiIiIrMHBL7TFBIOIiMgKHP0skholGB9++GGNB5w0adJ9B0NERET1Q40SjEWLFtVoMEEQmGAQERHdYsdTHJaqUYKRmZlp7TiIiIjqFUefIrnvs0g0Gg3OnDkDna7y7aeJiIgcnijRZqfMTjBKS0sRHx8Pd3d3tGrVChcvXgRQsfbi3XfflTxAIiIisj9mJxgzZszAH3/8gV27dkGhuH0b2tjYWGzcuFHS4IiIiOyXINFmn8w+TXXLli3YuHEjunTpAkG4/cJjYmJw7tw5SYMjIiKyWw5+HQyzKxhXr15FYGBgpfaSkhKThIOIiIgcl9kJRqdOnfB///d/xse3kooVK1aga9eu0kVGRERkzxx8kafZUyTJycl49NFHcfLkSeh0OnzwwQc4ceIE9u3bh927d1sjRiIiIvvj4HdTNbuC0a1bN/z2228oLS1Fs2bNsH37dgQFBWHfvn3o0KGDNWIkIiIiO3Nf9yJp06YNUlNTpY6FiIio3nD027XfV4Kh1+uxefNmnDp1CoIgoGXLlhg4cCBkMt47jYiICIDDn0VidkZw/PhxDBw4ECqVCtHR0QCAs2fPomHDhvj222/Rpk0byYMkIiIi+2L2GowxY8agVatWyMnJwaFDh3Do0CFkZ2ejbdu2ePHFF60RIxERkf25tcjT0s1OmV3B+OOPP5Ceng5fX19jm6+vL+bNm4dOnTpJGhwREZG9EsSKzdIx7JXZFYzo6GhcuXKlUnteXh4iIyMlCYqIiMjuOfh1MGqUYBQWFhq3pKQkTJo0CV999RVycnKQk5ODr776CgkJCZg/f7614yUiIiI7UKMpkgYNGphcBlwURQwZMsTYJv59Hs0TTzwBvV5vhTCJiIjsjINfaKtGCcbPP/9s7TiIiIjqF56m+s969Ohh7TiIiIioHjF7kectpaWlOH36NI4ePWqyEREREWy+yDM5ORmCICAhIeF2SKKIxMREhISEwM3NDT179sSJEydMjlOr1Zg4cSICAgLg4eGBJ598Ejk5OWY//33drn3AgAHw8vJCq1at0K5dO5ONiIiIYNME4+DBg/jkk0/Qtm1bk/YFCxZg4cKFWLp0KQ4ePAilUom+ffuiqKjI2CchIQGbN2/Ghg0bsGfPHhQXF2PAgAFmr7E0O8FISEhAfn4+9u/fDzc3N2zbtg2pqamIiorCt99+a+5wREREJKHi4mKMGDECK1asMLlmlSiKWLx4MWbNmoVBgwahdevWSE1NRWlpKdavXw8AKCgowKpVq/D+++8jNjYW7dq1w7p163Ds2DGkpaWZFYfZCcZPP/2ERYsWoVOnTnByckJYWBhGjhyJBQsWIDk52dzhiIiI6icJr+R55+UiCgsLoVarq33aCRMm4PHHH0dsbKxJe2ZmJlQqFfr162dsk8vl6NGjB/bu3QsAyMjIgFarNekTEhKC1q1bG/vUlNkJRklJCQIDAwEAfn5+uHr1KoCKO6weOnTI3OGIiIjqpVtX8rR0A4DQ0FD4+PgYt+r+oN+wYQMOHTpU5X6VSgUACAoKMmkPCgoy7lOpVHB1dTWpfNzdp6bMvlR4dHQ0zpw5g/DwcDz44IP4+OOPER4ejuXLlyM4ONjc4YiIiOgfZGdnw9vb2/hYLpdX2efVV1/F9u3boVAoqh3rzutaARVTJ3e33a0mfe5mdoKRkJCA3NxcAMCcOXMQFxeHzz77DK6urkhJSTF3OCIiovpJwutgeHt7myQYVcnIyEBeXh46dOhgbNPr9fjll1+wdOlSnDlzBkBFleLOgkBeXp6xqqFUKqHRaJCfn29SxcjLy0O3bt3MCt3sKZIRI0Zg9OjRAIB27drhwoULOHjwILKzszF06FBzhyMiIiIJ9OnTB8eOHcORI0eMW8eOHTFixAgcOXIETZs2hVKpxI4dO4zHaDQa7N6925g8dOjQAS4uLiZ9cnNzcfz4cbMTDLMrGHdzd3dH+/btLR2GiIioXhEgwd1Uzejr5eWF1q1bm7R5eHjA39/f2J6QkICkpCRERUUhKioKSUlJcHd3x/DhwwEAPj4+iI+Px5QpU+Dv7w8/Pz9MnToVbdq0qbRo9J/UKMGYPHlyjQdcuHChWQEQERFR7Zg2bRrKysowfvx45Ofno3Pnzti+fTu8vLyMfRYtWgSZTIYhQ4agrKwMffr0QUpKCpydnc16LkG8daeye+jVq1fNBhME/PTTT2YFYG8KCwvh4+ODnsJTkAkutg6HyCrOruzwz51IMs3j020dgkPRiVrswjcoKCj4x3UN9+PW90TYu/PgdI/FljVhKC9H1huzrBarNfFmZ0RERNbg4Dc7u+97kRARERFVx+JFnkRERFQFB69gMMEgIiKygjuvxGnJGPaKUyREREQkOVYwiIiIrMHBp0juq4Kxdu1adO/eHSEhIcjKygIALF68GN98842kwREREdktUaLNTpmdYCxbtgyTJ0/GY489hps3b0Kv1wMAGjRogMWLF0sdHxEREdkhsxOMJUuWYMWKFZg1a5bJVb06duyIY8eOSRocERGRvZLydu32yOw1GJmZmWjXrl2ldrlcjpKSEkmCIiIisnuiULFZOoadMruCERERgSNHjlRq/+GHHxATEyNFTERERPbPwddgmF3BeP311zFhwgSUl5dDFEUcOHAAn3/+OZKTk7Fy5UprxEhERER2xuwE4/nnn4dOp8O0adNQWlqK4cOHo1GjRvjggw8wbNgwa8RIRERkdxz9Qlv3dR2MsWPHYuzYsbh27RoMBgMCAwOljouIiMi+Ofh1MCy60FZAQIBUcRAREVE9YnaCERERAUGoflXr+fPnLQqIiIioXpDiNFNHqmAkJCSYPNZqtTh8+DC2bduG119/Xaq4iIiI7BunSMzz6quvVtn+v//9D+np6RYHRERERPZPsrup9u/fH19//bVUwxEREdk3XgdDGl999RX8/PykGo6IiMiu8TRVM7Vr185kkacoilCpVLh69So++ugjSYMjIiIi+2R2gvHUU0+ZPHZyckLDhg3Rs2dPtGjRQqq4iIiIyI6ZlWDodDqEh4cjLi4OSqXSWjERERHZPwc/i8SsRZ4ymQwvv/wy1Gq1teIhIiKqFxz9du1mn0XSuXNnHD582BqxEBERUT1h9hqM8ePHY8qUKcjJyUGHDh3g4eFhsr9t27aSBUdERGTX7LgCYakaJxgvvPACFi9ejKFDhwIAJk2aZNwnCAJEUYQgCNDr9dJHSUREZG8cfA1GjROM1NRUvPvuu8jMzLRmPERERFQP1DjBEMWKNCosLMxqwRAREdUXvNCWGe51F1UiIiK6A6dIaq558+b/mGTcuHHDooCIiIjI/pmVYLz99tvw8fGxVixERET1BqdIzDBs2DAEBgZaKxYiIqL6w8GnSGp8oS2uvyAiIqKaMvssEiIiIqoBB69g1DjBMBgM1oyDiIioXuEaDCIiIpKeg1cwzL7ZGREREdVNy5YtQ9u2beHt7Q1vb2907doVP/zwg3G/KIpITExESEgI3Nzc0LNnT5w4ccJkDLVajYkTJyIgIAAeHh548sknkZOTY3YsTDCIiIisQZRoM0Pjxo3x7rvvIj09Henp6ejduzcGDhxoTCIWLFiAhQsXYunSpTh48CCUSiX69u2LoqIi4xgJCQnYvHkzNmzYgD179qC4uBgDBgww+15jnCIhIiKyAinXYBQWFpq0y+VyyOXySv2feOIJk8fz5s3DsmXLsH//fsTExGDx4sWYNWsWBg0aBKDiPmNBQUFYv349xo0bh4KCAqxatQpr165FbGwsAGDdunUIDQ1FWloa4uLiahw7EwwH4K/UIH5mLjr1LoSrwoBL5+VYOKUJ/jrmbuvQ6p2Rk3Px7JQrJm038mT4d7vWNoqo/vD9v1w03HQJ+bGBuPrvJgAA/28uwetAPmQ3NBBlAsrD3HF9UCOUN/U0Hhf46QW4nyyC7KYGBrkzyiM9cfWZRtAGu9nqpdi11p2LMXj8VUS1KYW/UofEF8KxbxsvwGhtoaGhJo/nzJmDxMTEex6j1+vx5ZdfoqSkBF27dkVmZiZUKhX69etn7COXy9GjRw/s3bsX48aNQ0ZGBrRarUmfkJAQtG7dGnv37mWCQbd5+uiwcMufOLrXC2+ObIqb12QIDtegpNDZ1qHVWxdOK/DGsGbGxwY9ryFjKXlmCRr8chXqxqZJgSZIgbwRTaBtKIegMcB3xxU0WvgnLiS3ht7LBQCgDvNAUWd/aP1d4Vyig/83l9F44Z/InN8GcOLPxlwKdwPOn1Bg+wZfzF6VZetw6jYJF3lmZ2fD29vb2FxV9eKWY8eOoWvXrigvL4enpyc2b96MmJgY7N27FwAQFBRk0j8oKAhZWRU/S5VKBVdXV/j6+lbqo1KpzAq9Xq3ByMvLw7hx49CkSRPI5XIolUrExcVh3759AIDw8HAIggBBEODm5oYWLVrgvffeq9fX+BgyPg/XLrvi/clNcOaIB67kyHFkjxdys6r/5STL6PVA/lUX41Zwg3m8JYRyPYJXnMeVUeHQe5gmxkVd/FEa4w1tQzk0jdxwdWgonMv0cM0uM/Yp6NEQZdFe0AXIoQ7zwLX/1wguNzRwuaau7ZdSL6T/7I3UBcH47YcGtg6lzrs1RWLpBsC4aPPWdq8EIzo6GkeOHMH+/fvx8ssvY9SoUTh58uTtuO66cKYoiv94Mc2a9Llbvfrke/rpp6HVapGamoqmTZviypUr2Llzp8kN2ObOnYuxY8eivLwcaWlpePnll+Ht7Y1x48bZMHLr6dKvABm7vTHr40y07VKCayoXbE0NwA/r/W0dWr3VKEKD9RnHodU44fRhd6x5Nxiqi0zo7lfgZxdR0tYHpTHe8Nt6ufqOOgN8dl+F3s0Z6tCqpz8EtR4+v12DJsAVWj9XK0VMZFuurq6IjIwEAHTs2BEHDx7EBx98gOnTpwOoqFIEBwcb++fl5RmrGkqlEhqNBvn5+SZVjLy8PHTr1s2sOOpNgnHz5k3s2bMHu3btQo8ePQAAYWFheOihh0z6eXl5QalUAgDGjBmDZcuWYfv27dUmGGq1Gmr17b907l5oU9cFN9FgwLPXsGlFQ2z4MAjR7Urx8twcaDUC0r7ys3V49c7pwx5471U35JyXw7ehDv+epMKib/7Ei71boCi/3vxzqzVev9+AIqsUF99qWW0fjz9uIvjj8xA0Buh9XJAzpTkMf0+P3OLzUx4afpUDJ7UB6mAFLk1pDsjqVQGX6qI6ch0MURShVqsREREBpVKJHTt2oF27dgAAjUaD3bt3Y/78+QCADh06wMXFBTt27MCQIUMAALm5uTh+/DgWLFhg1vPWm088T09PeHp6YsuWLejSpcs9y0dAxRu+e/dunDp1ClFRUdX2S05Oxttvvy11uLVGcAL+POqGNe+GAADOnXBHWPNyPP7cNSYYVpD+8+050gungZPp7kjZewp9B9/Apk94o0BzyG5o0HDDReRMbg7RpfpkoLSFF7LmxMC5WAefX64hZPk5XJzVEnrv20lGURc/lLbyhuymFr4/qhC8/DyyZ7S457hEFrNBgjFz5kz0798foaGhKCoqwoYNG7Br1y5s27YNgiAgISEBSUlJiIqKQlRUFJKSkuDu7o7hw4cDAHx8fBAfH48pU6bA398ffn5+mDp1Ktq0aWM8q6Sm6s2/LplMhpSUFKSmpqJBgwbo3r07Zs6ciaNHj5r0mz59Ojw9PSGXy9GrVy+IoohJkyZVO+6MGTNQUFBg3LKzs639UiR1I0+GrLMKk7bsvxQIDNHaKCLHoi5zxoXTCjSK4Hy/ueQXSiAr1CFs7klEjU1H1Nh0uJ8pRoOdeYgamw4YKj55RbkztEEKlDfzxJXnwyE6CfD+9ZrJWAZ3GbRBCpRFe+Hy+GZwzS2H56F8W7wsIqu6cuUKnn32WURHR6NPnz74/fffsW3bNvTt2xcAMG3aNCQkJGD8+PHo2LEjLl26hO3bt8PLy8s4xqJFi/DUU09hyJAh6N69O9zd3fHdd9/B2dm8kwPqTQUDqFiD8fjjj+PXX3/Fvn37sG3bNixYsAArV67E6NGjAQCvv/46Ro8ejatXr2LWrFno3bv3PeeVqjvX2F6cPOiB0GamX26NmqqRd8mlmiNISi6uBoRGqXH8d89/7kwmSlt648LbrUzalGsyoVEqcKN/8D3PAHHS/fO9kwRt/V3cTXWD8Pdm6RjmWLVq1b3HEwQkJibe8xRXhUKBJUuWYMmSJWY+u6l6lWAAFW9M37590bdvX8yePRtjxozBnDlzjAlGQEAAIiMjERkZia+//hqRkZHo0qWL2aUfe7FpRSAWfXMWwyZewS/fNUD0g6V4bMR1LJ7W2Nah1Utj37qE/Tt8kHfJBQ0CdBj+6hW4e+qx40tOR5lLdHOG5q7TUg1yJ+g9ZdA0doOg1sNvay5KHmwAnY8LnEt0aPDzVchuaFDUseL9drmqhueBGyht5Q29lwyyfC38flBBdBFQ0pbXbrgfCnc9QiI0xsfKUA2atipD0U1nXL3EhbMm6sgaDFupdwnG3WJiYrBly5Yq9/n6+mLixImYOnUqDh8+bPYpOPbg7B/umDsmAs+/kYsRCSqosl2xfE4j/LyZX3jWEBCsxYz/XYC3nx4F12U4fcgdCU80Rx4/eKXnJMBVVQ6fj87BqVgHg4cM5REeyH6jBTSNKhITg0yA+59F8E27AucSPXTeMpQ198LFmaZrNKjmmj9Qhve+Pmd8/NLbFWf2bN/oi/dfa2KrsOok3k21nrh+/ToGDx6MF154AW3btoWXlxfS09OxYMECDBw4sNrjJkyYgPnz5+Prr7/GM888U4sR157f03zwexr/WqsNyePDbR1CvZYzrYXx/0UXJ+ROiLxnf72vKy4lNLd2WA7l6D5PxIU8YOswyA7UmwTD09MTnTt3xqJFi3Du3DlotVqEhoZi7NixmDlzZrXHNWzYEM8++ywSExMxaNAgODnVm3WvRERkS5wiqR/kcjmSk5ORnJxcbZ8LFy5U2f7JJ59YKSoiInJodpwgWIp/rhMREZHk6k0Fg4iIqC7hIk8iIiKSnoOvweAUCREREUmOFQwiIiIr4BQJERERSY9TJERERETSYgWDiIjICjhFQkRERNJz8CkSJhhERETW4OAJBtdgEBERkeRYwSAiIrICrsEgIiIi6XGKhIiIiEharGAQERFZgSCKEETLShCWHm9LTDCIiIisgVMkRERERNJiBYOIiMgKeBYJERERSY9TJERERETSYgWDiIjICjhFQkRERNJz8CkSJhhERERW4OgVDK7BICIiIsmxgkFERGQNnCIhIiIia7DnKQ5LcYqEiIiIJMcKBhERkTWIYsVm6Rh2igkGERGRFfAsEiIiIiKJsYJBRERkDTyLhIiIiKQmGCo2S8ewV5wiISIiqieSk5PRqVMneHl5ITAwEE899RTOnDlj0kcURSQmJiIkJARubm7o2bMnTpw4YdJHrVZj4sSJCAgIgIeHB5588knk5OSYFQsTDCIiImsQJdrMsHv3bkyYMAH79+/Hjh07oNPp0K9fP5SUlBj7LFiwAAsXLsTSpUtx8OBBKJVK9O3bF0VFRcY+CQkJ2Lx5MzZs2IA9e/aguLgYAwYMgF6vr3EsnCIhIiKyAinPIiksLDRpl8vlkMvllfpv27bN5PGaNWsQGBiIjIwM/Otf/4Ioili8eDFmzZqFQYMGAQBSU1MRFBSE9evXY9y4cSgoKMCqVauwdu1axMbGAgDWrVuH0NBQpKWlIS4urkaxs4JBRERkDbeug2HpBiA0NBQ+Pj7GLTk5uUYhFBQUAAD8/PwAAJmZmVCpVOjXr5+xj1wuR48ePbB3714AQEZGBrRarUmfkJAQtG7d2tinJljBICIiquOys7Ph7e1tfFxV9eJuoihi8uTJePjhh9G6dWsAgEqlAgAEBQWZ9A0KCkJWVpaxj6urK3x9fSv1uXV8TTDBICIisgIpp0i8vb1NEoyaeOWVV3D06FHs2bOn8riCYPJYFMVKbXerSZ87McG4T07ubnASXG0dhkMw3LE4iWpH87GHbR2CQzm7opOtQ3AohrJyYOI31n8iG14HY+LEifj222/xyy+/oHHjxsZ2pVIJoKJKERwcbGzPy8szVjWUSiU0Gg3y8/NNqhh5eXno1q1bjWPgGgwiIqJ6QhRFvPLKK9i0aRN++uknREREmOyPiIiAUqnEjh07jG0ajQa7d+82Jg8dOnSAi4uLSZ/c3FwcP37crASDFQwiIiIrsMW9SCZMmID169fjm2++gZeXl3HNhI+PD9zc3CAIAhISEpCUlISoqChERUUhKSkJ7u7uGD58uLFvfHw8pkyZAn9/f/j5+WHq1Klo06aN8aySmmCCQUREZA02uJvqsmXLAAA9e/Y0aV+zZg1Gjx4NAJg2bRrKysowfvx45Ofno3Pnzti+fTu8vLyM/RctWgSZTIYhQ4agrKwMffr0QUpKCpydnWscCxMMIiKiekKsQUIiCAISExORmJhYbR+FQoElS5ZgyZIl9x0LEwwiIiIrcPTbtTPBICIisgYHv5sqzyIhIiIiybGCQUREZAWcIiEiIiLpGcSKzdIx7BQTDCIiImvgGgwiIiIiabGCQUREZAUCJFiDIUkktsEEg4iIyBpscCXPuoRTJERERCQ5VjCIiIisgKepEhERkfR4FgkRERGRtFjBICIisgJBFCFYuEjT0uNtiQkGERGRNRj+3iwdw05xioSIiIgkxwoGERGRFXCKhIiIiKTn4GeRMMEgIiKyBl7Jk4iIiEharGAQERFZAa/kSURERNLjFAkRERGRtFjBICIisgLBULFZOoa9YoJBRERkDZwiISIiIpIWKxhERETWwAttERERkdQc/VLhnCIhIiIiybGCQUREZA0OvsiTCQYREZE1iAAsPc3UfvMLJhhERETWwDUYRERERBJjBYOIiMgaREiwBkOSSGyCCQYREZE1OPgiT06REBERkeRYwahHhozLQfd+19G4aRk0aiecPOSN1e+F4VKmm0m/0GaleOH1LLR5qBCCIOLiX+5ImhSNq7lyG0Ve/wwYdQ2DX74Kv0Atss4qsHx2CI4f8LR1WPVS6r7jUIZqKrV/mxKA/73ZxAYR1R++319Gw82XkN8nCFeHNQF0BgRsuQSP4wVwuaqGwc0ZpS29cfXpxtA3cDUe55JXjoZfZkPxVzEEnQGlrXyQNzwMem8XG74aGzAAECQYwwy//PIL3nvvPWRkZCA3NxebN2/GU089ZdwviiLefvttfPLJJ8jPz0fnzp3xv//9D61atTL2UavVmDp1Kj7//HOUlZWhT58++Oijj9C4cWOzYmEFox5p81AhvvssGK8NbouZo1vBWSZi3poTkLvpjX2Cm5Tjv58fR/Z5N0wf2QoTnnwQ6//XGBq1pf8K6JYeT+bjpbcv4/MPAzG+X3Mc/90D73yWiYaNKn8JkuUmPR6NYe3aGLc3hkUCAH79P18bR2bf5JnFaPDLVagb3/4DxUljgPxiKa4/HoKst2Jw+eVIuFwpR6Olfxr7CGo9Gi0+C1EAcqZEI3t6Swh6EY2W/AkY7Lfcfz9unUVi6WaOkpISPPDAA1i6dGmV+xcsWICFCxdi6dKlOHjwIJRKJfr27YuioiJjn4SEBGzevBkbNmzAnj17UFxcjAEDBkCv11c5ZnVsnmCoVCq8+uqriIyMhEKhQFBQEB5++GEsX74cpaWlAIDDhw9jwIABCAwMhEKhQHh4OIYOHYpr164hIyMDgiBgz549VY4fFxeHJ598EoIg3HMbPXp0Lb5q63grPgZpmwJx8S93ZJ72wKI3IhHUSIOo1sXGPqNey8LB3b5YvSAc5056QpWtwMFdfii44XqPkckcg168hh8/98O29f7I/kuB5XMa4eplFwx47rqtQ6uXCm64IP/q7a1zbAEuX5Dj6D5WjO6XUK5H8MrzuPJcOPTutwvdBncZLk2ORnEnP2iVbihv5om8fzeBIqsUsutqAIDbX8VwuabGleebQtPYHZrG7lCNjoDiQgncTxfa6iU5jP79++Odd97BoEGDKu0TRRGLFy/GrFmzMGjQILRu3RqpqakoLS3F+vXrAQAFBQVYtWoV3n//fcTGxqJdu3ZYt24djh07hrS0NLNisWmCcf78ebRr1w7bt29HUlISDh8+jLS0NLz22mv47rvvkJaWhry8PMTGxiIgIAA//vgjTp06hdWrVyM4OBilpaXo0KEDHnjgAaxZs6bS+NnZ2UhLS0N8fDxyc3ON2+LFi+Ht7W3S9sEHH9jgHbAud08dAKDoZsUHhCCI6NQzH5cuKPDO6pP4fP8BLPrqKLrG8otPKjIXA6LaliJjt5dJe8ZuL8R0LLFRVI5D5mJA70E38OMGf1hem3ZcgeuzUNK2AUpjfP6xr3OZHqJQkXwAgKATAQEQZbfff9HFCaJQkXw4lFuLPC3dABQWFppsarXa7HAyMzOhUqnQr18/Y5tcLkePHj2wd+9eAEBGRga0Wq1Jn5CQELRu3drYp6ZsugZj/PjxkMlkSE9Ph4eHh7G9TZs2ePrppyGKIr755hsUFhZi5cqVkMkqwo2IiEDv3r2N/ePj4zFz5kx8+OGHJuOkpKSgYcOGePzxx43HAoCPjw8EQYBSqayFV2krIl6ceQHHD3oh68+K96SBvxbungYMefESUhc1wer3wtDhkXy8+b8zeOPZVjh24J8/TOjevP30cJYBN6+Z/tO6eVUG30CdjaJyHN3iCuDprcf2L/1sHYrd8jpwHYqLpbg4K+Yf+wpaAwI25aDoIT8Y3JwBAOVNPWCQOyPg6xxc+3+NAAANv86BIALOBVqrxl7nSHgWSWhoqEnznDlzkJiYaNZQKpUKABAUFGTSHhQUhKysLGMfV1dX+Pr6Vupz6/iaslkF4/r169i+fTsmTJhgkhTc6VYSoNPpsHnzZojV/KBGjBgBrVaLL7/80tgmiiJSUlIwatQok+TCXGq1ulLmaA/Gz8lERHQp5k9ubmwT/v5p79vphy0pITh/ygNfftIYB372xWP/vmKjSOunu39VBQF2fT67vYgbdg0Hf/bGjSuc8rsfshtqNNxwEbnxTSG6/MPXg86A4E/OASKQNyLc2Kz3ckHuuGbwOHoTkRMPIXLSITiV6VHexL0OTMrbr+zsbBQUFBi3GTNm3PdYgmBa3RNFsVLb3WrS5242+3H/9ddfEEUR0dHRJu0BAQHw9PSEp6cnpk+fji5dumDmzJkYPnw4AgIC0L9/f7z33nu4cuX2F6Kfnx+eeuopk2mSXbt24fz583jhhRcsijM5ORk+Pj7G7e4ssi56+a3z6NLnBqY/2wrXVLfPDCnMl0GnFXDxL9OzSrLPuaFhsPnlNqqs8IYz9DrAt6FptcInQIf8qzxpy5oCG6nR7pEibPs8wNah2C15VilkRTqEvXMCUeMOImrcQbifLUKDn64gatzB24s0dQaEfHwOLtfUyHkt2li9uKW0lQ8uJLXFufcfxLlF7aCKbwrZTQ20AQ52ppqEUyTe3t4mm1xu/nt5q2p/dyUiLy/PWNVQKpXQaDTIz8+vtk9N2TyfvDsjOnDgAI4cOYJWrVoZ55jmzZsHlUqF5cuXIyYmBsuXL0eLFi1w7Ngx43Hx8fH45Zdf8NdffwEAVq9eje7du1dKYMw1Y8YMk6wxOzvbovGsS8TLs8+jW78beOPZVriSozDZq9M64ewxTzSOKDdpbxRejrzLDvYP30p0Wif8edQd7f9VZNLe/l9FOJledaWOpNFv6HXcvCbD7zs51Xe/Slt640JiK2TNvr2Vh7mjqLM/sma3ApyE28lFnho5k6Nh8Kw+cTZ4ucDgLoPbqUI4F+lQ/ECD2nsxdYFBok0iERERUCqV2LFjh7FNo9Fg9+7d6NatGwCgQ4cOcHFxMemTm5uL48ePG/vUlM3+pIqMjIQgCDh9+rRJe9OmTQEAbm6mf2X7+/tj8ODBGDx4MJKTk9GuXTv897//RWpqKgAgNjYWYWFhSElJwbRp07Bp06ZqT9Mxh1wuv69M0RYmJJ5HzyeuYe7LLVBW4gzfgIrTIkuKnKFRV/yF8fXKELyx+CyOH/TGH/u90fFfN9G59w1MH9nalqHXK5s+CcDrH2bj7FE3nEr3wGMjryOwkRb/96m/rUOrtwRBRL8hN5D2lT8Mei7uvF+iwhmaRu4mbQa5M/Qesop2vYiQ5ecgv1iCSxObA4bb6yr0Hs6ArOJvVu/frkKjdIPeSwbF+WIEbriI/NggaJVulZ6zPrPFzc6Ki4uNf2gDFQs7jxw5Aj8/PzRp0gQJCQlISkpCVFQUoqKikJSUBHd3dwwfPhxAxRrF+Ph4TJkyBf7+/vDz88PUqVPRpk0bxMbGmhWLzRIMf39/9O3bF0uXLsXEiROrXYdRFVdXVzRr1gwlJbdX5QuCgOeffx4rV65E48aN4eTkhCFDhlgj9DprwIiKaaMFn50waX9/eiTSNgUCAPbu8MfSOU0xZNwlvPRWJnIyFXjnlRY4keFd6/HWV7u/9YWXrx4jXrsCv0Adss4o8ObICORd4roAa2n3SBGCGmv+PnuErEWWr4HnHzcBAOFzTT9nsqdGoyy64nPEVVWOgE05cC7RQ+vviuuPheBmX/PK63R/0tPT0atXL+PjyZMnAwBGjRpl/AO8rKwM48ePN15oa/v27fDyun3m26JFiyCTyTBkyBDjhbZSUlLg7Oxc6fnuRRCrWzlZC86dO4fu3bvD19cXiYmJaNu2LZycnHDw4EFMnToVI0aMQK9evbBhwwYMGzYMzZs3hyiK+O677/DGG29gzZo1ePbZZ43jXbx4EREREfDx8cHTTz+NFStWVPm8KSkpSEhIwM2bN82OubCwED4+Pujt8W/IBH5h1AZDCU/vrHVO5n2QkGXOftze1iE4FENZOXImzkFBQQG8vaX/4+rW90Rs1GuQOVtWAdfp1Uj7c5HVYrUmm646a9asGQ4fPoykpCTMmDEDOTk5kMvliImJwdSpUzF+/HioVCq4u7tjypQpyM7OhlwuR1RUFFauXGmSXABAkyZNEBsbi+3bt1u8uJOIiMgiBhEQLPwb3o6vfmrTCoY9YgWj9rGCYQOsYNQqVjBqV61VMJolSFPBOLeYFQwiIiL6m4Pfrp0JBhERkVVIkGDY8RX6bH4dDCIiIqp/WMEgIiKyBk6REBERkeQMIiye4rDjs0g4RUJERESSYwWDiIjIGkRDxWbpGHaKCQYREZE1cA0GERERSY5rMIiIiIikxQoGERGRNXCKhIiIiCQnQoIEQ5JIbIJTJERERCQ5VjCIiIisgVMkREREJDmDAYCF17Ew2O91MDhFQkRERJJjBYOIiMgaOEVCREREknPwBINTJERERCQ5VjCIiIiswcEvFc4Eg4iIyApE0QDRwruhWnq8LTHBICIisgZRtLwCwTUYRERERLexgkFERGQNogRrMOy4gsEEg4iIyBoMBkCwcA2FHa/B4BQJERERSY4VDCIiImvgFAkRERFJTTQYIFo4RWLPp6lyioSIiIgkxwoGERGRNXCKhIiIiCRnEAHBcRMMTpEQERGR5FjBICIisgZRBGDpdTDst4LBBIOIiMgKRIMI0cIpEpEJBhEREZkQDbC8gsHTVImIiKgO+OijjxAREQGFQoEOHTrg119/tUkcTDCIiIisQDSIkmzm2LhxIxISEjBr1iwcPnwYjzzyCPr374+LFy9a6VVWjwkGERGRNYgGaTYzLFy4EPHx8RgzZgxatmyJxYsXIzQ0FMuWLbPSi6we12CY6daCG52otXEkjsPA97r22fG8rz0ylJXbOgSHcuv9tvYCSh20Fl9nS4eKz7/CwkKTdrlcDrlcbtKm0WiQkZGBN954w6S9X79+2Lt3r2WB3AcmGGYqKioCAPxS+pWNIyGyIuYXtWviJltH4JCKiorg4+Mj+biurq5QKpXYo/pekvE8PT0RGhpq0jZnzhwkJiaatF27dg16vR5BQUEm7UFBQVCpVJLEYg4mGGYKCQlBdnY2vLy8IAiCrcOpscLCQoSGhiI7Oxve3t62Dsch8D2vXXy/a5c9v9+iKKKoqAghISFWGV+hUCAzMxMajUaS8URRrPR9c3f14k53963q+NrABMNMTk5OaNy4sa3DuG/e3t5292Fg7/ie1y6+37XLXt9va1Qu7qRQKKBQKKz6HHcLCAiAs7NzpWpFXl5epapGbeAiTyIionrA1dUVHTp0wI4dO0zad+zYgW7dutV6PKxgEBER1ROTJ0/Gs88+i44dO6Jr16745JNPcPHiRbz00ku1HgsTDAchl8sxZ86ce87bkbT4ntcuvt+1i+933TR06FBcv34dc+fORW5uLlq3bo3vv/8eYWFhtR6LINrzhc6JiIioTuIaDCIiIpIcEwwiIiKSHBMMIiIikhwTDCIiIpIcEww7tnfvXjg7O+PRRx81ab9w4QIEQai0jRw50mT/kSNHquzv6uqKyMhIvPPOO1a/Vr+9y8vLw7hx49CkSRPI5XIolUrExcVh3759AIDw8HDj++rs7IyQkBDEx8cjPz/fxpHbL3Peczc3N7Ro0QLvvfcef5eroFKp8OqrryIyMhIKhQJBQUF4+OGHsXz5cpSWlgIADh8+jAEDBiAwMBAKhQLh4eEYOnQorl27hoyMDAiCgD179lQ5flxcHJ588skqP4/u3EaPHl2Lr5pqC09TtWOrV6/GxIkTsXLlSly8eBFNmjQx2Z+WloZWrVoZH7u5ud1zvFv91Wo19uzZgzFjxiA4OBjx8fFWib8+ePrpp6HVapGamoqmTZviypUr2LlzJ27cuGHsM3fuXIwdOxZ6vR5nz57Fiy++iEmTJmHt2rU2jNx+mfOel5eXIy0tDS+//DK8vb0xbtw4G0Zet5w/fx7du3dHgwYNkJSUhDZt2kCn0+Hs2bNYvXo1QkJC0KVLF8TGxuKJJ57Ajz/+iAYNGiAzMxPffvstSktL0aFDBzzwwANYs2YNHn74YZPxs7OzkZaWhk2bNuGTTz4xtm/cuBGzZ8/GmTNnjG3/9NlEdkoku1RcXCx6eXmJp0+fFocOHSq+/fbbxn2ZmZkiAPHw4cNVHnv3/ur69+7dWxw/fryVXoH9y8/PFwGIu3btqrZPWFiYuGjRIpO2uXPnijExMVaOrn663/e8ffv24qBBg6wcnX2Ji4sTGzduLBYXF1e532AwiJs3bxZlMpmo1WqrHefDDz8UPT09K40zd+5cMSgoqNKxa9asEX18fCyOn+o+TpHYqY0bNyI6OhrR0dEYOXIk1qxZI2kJOD09HYcOHULnzp0lG7O+8fT0hKenJ7Zs2QK1Wl2jYy5duoStW7fyfb1P5r7noihi165dOHXqFFxcXGohQvtw/fp1bN++HRMmTICHh0eVfQRBgFKphE6nw+bNm6v9fBkxYgS0Wi2+/PJLY5soikhJScGoUaMgk7FQ7rBsm9/Q/erWrZu4ePFiURRFUavVigEBAeKOHTtEUbxdkXBzcxM9PDyM26FDh0z2313BuNXfxcVFBCC++OKLNnlt9uSrr74SfX19RYVCIXbr1k2cMWOG+Mcffxj3h4WFia6urqKHh4eoUChEAGLnzp3F/Px82wVt58x5z2/9LisUCvG3336zYdR1y/79+0UA4qZNm0za/f39jZ8X06ZNE0VRFGfOnCnKZDLRz89PfPTRR8UFCxaIKpXK5LihQ4eK//rXv4yPf/rpJxGAePr06UrPzQqG42AFww6dOXMGBw4cwLBhwwAAMpkMQ4cOxerVq036bdy4EUeOHDFuMTEx9xz3Vv8//vgDGzduxDfffIM33njDaq+jPnj66adx+fJlfPvtt4iLi8OuXbvQvn17pKSkGPu8/vrrOHLkCI4ePYqdO3cCAB5//HHo9XobRW3fzHnPd+/ejV69emHWrFk2udlTXXf3LbwPHDiAI0eOGNdiAcC8efOgUqmwfPlyxMTEYPny5WjRogWOHTtmPC4+Ph6//PIL/vrrLwAV68O6d++O6Ojo2nsxVPfYOsMh873++usiANHZ2dm4OTk5iXK5XLxx44ZkazCSk5NFmUwmlpWVWfcF1TPx8fFikyZNRFGsej3Avn37RADGihNZ7l7v+Y0bN0Q/Pz++33e4du2aKAiCmJycXOX+Hj16iK+++mqV+9RqtRgTEyM+99xzxjaDwSCGhYWJs2bNEgsKCkR3d3dx9erVVR7PCobjYAXDzuh0Onz66ad4//33TaoTf/zxB8LCwvDZZ59J9lzOzs7Q6XTQaDSSjekIYmJiUFJSUu1+Z2dnAEBZWVlthVTv3es99/X1xcSJEzF16lSeqvo3f39/9O3bF0uXLr3n72pVXF1d0axZM5PjBEHA888/j9TUVKxfvx5OTk4YMmSI1GGTnWGCYWe2bt2K/Px8xMfHo3Xr1ibbM888g1WrVt332NevX4dKpUJOTg5++OEHfPDBB+jVqxe8vb0lfAX1x/Xr19G7d2+sW7cOR48eRWZmJr788kssWLAAAwcONPYrKiqCSqVCbm4uDhw4gNdffx0BAQEs2d+Hmr7nd5swYQLOnDmDr7/+uhajrds++ugj6HQ6dOzYERs3bsSpU6dw5swZrFu3DqdPn4azszO2bt2KkSNHYuvWrTh79izOnDmD//73v/j+++8rvd/PP/88Ll++jJkzZ2LYsGHVLh4lB2LrEgqZZ8CAAeJjjz1W5b6MjAwRgPG/5k6R3NqcnZ3Fxo0bi2PHjhXz8vKs9ErsX3l5ufjGG2+I7du3F318fER3d3cxOjpafPPNN8XS0lJRFCvK9Xe+tw0bNhQfe+yxan82dG81fc/vnpYSRVEcO3as2KpVK1Gv19dy1HXX5cuXxVdeeUWMiIgQXVxcRE9PT/Ghhx4S33vvPbGkpEQ8d+6cOHbsWLF58+aim5ub2KBBA7FTp07imjVrqhyvX79+IgBx79691T4np0gcB2/XTkRERJLjFAkRERFJjgkGERERSY4JBhEREUmOCQYRERFJjgkGERERSY4JBhEREUmOCQYRERFJjgkGERERSY4JBpEdSkxMxIMPPmh8PHr0aDz11FO1HseFCxcgCAKOHDlSbZ/w8HAsXry4xmOmpKSgQYMGFscmCAK2bNli8ThEdH+YYBBJZPTo0RAEAYIgwMXFBU2bNsXUqVPNvpnU/fjggw9Mbld+LzVJCoiILCWzdQBE9cmjjz6KNWvWQKvV4tdff8WYMWNQUlKCZcuWVeqr1Wrh4uIiyfP6+PhIMg4RkVRYwSCSkFwuh1KpRGhoKIYPH44RI0YYy/S3pjVWr16Npk2bQi6XQxRFFBQU4MUXX0RgYCC8vb3Ru3dv/PHHHybjvvvuuwgKCoKXlxfi4+NRXl5usv/uKRKDwYD58+cjMjIScrkcTZo0wbx58wAAERERAIB27dpBEAT07NnTeNyaNWvQsmVLKBQKtGjRAh999JHJ8xw4cADt2rWDQqFAx44dcfjwYbPfo4ULF6JNmzbw8PBAaGgoxo8fj+Li4kr9tmzZgubNm0OhUKBv377Izs422f/dd9+hQ4cOUCgUaNq0Kd5++23odDqz4yEi62CCQWRFbm5u0Gq1xsd//fUXvvjiC3z99dfGKYrHH38cKpUK33//PTIyMtC+fXv06dMHN27cAAB88cUXmDNnDubNm4f09HQEBwdX+uK/24wZMzB//ny89dZbOHnyJNavX4+goCAAFUkCAKSlpSE3NxebNm0CAKxYsQKzZs3CvHnzcOrUKSQlJeGtt95CamoqAKCkpAQDBgxAdHQ0MjIykJiYiKlTp5r9njg5OeHDDz/E8ePHkZqaip9++gnTpk0z6VNaWop58+YhNTUVv/32GwoLCzFs2DDj/h9//BEjR47EpEmTcPLkSXz88cdISUkxJlFEVAfY+G6uRPXGqFGjxIEDBxof//7776K/v784ZMgQURRFcc6cOaKLi4uYl5dn7LNz507R29tbLC8vNxmrWbNm4scffyyKoih27dpVfOmll0z2d+7cWXzggQeqfO7CwkJRLpeLK1asqDLOzMxMEUClW8aHhoaK69evN2n7z3/+I3bt2lUURVH8+OOPRT8/P7GkpMS4f9myZVWOdafqbp9+yxdffCH6+/sbH69Zs0YEIO7fv9/YdurUKRGA+Pvvv4uiKIqPPPKImJSUZDLO2rVrxeDgYONjAOLmzZurfV4isi6uwSCS0NatW+Hp6QmdTgetVouBAwdiyZIlxv1hYWFo2LCh8XFGRgaKi4vh7+9vMk5ZWRnOnTsHADh16hReeuklk/1du3bFzz//XGUMp06dglqtRp8+fWoc99WrV5GdnY34+HiMHTvW2K7T6YzrO06dOoUHHngA7u7uJnGY6+eff0ZSUhJOnjyJwsJC6HQ6lJeXo6SkBB4eHgAAmUyGjh07Go9p0aIFGjRogFOnTuGhhx5CRkYGDh48aFKx0Ov1KC8vR2lpqUmMRGQbTDCIJNSrVy8sW7YMLi4uCAkJqbSI89YX6C0GgwHBwcHYtWtXpbHu91RNNzc3s48xGAwAKqZJOnfubLLP2dkZACCK4n3Fc6esrCw89thjeOmll/Cf//wHfn5+2LNnD+Lj402mkoCK00zvdqvNYDDg7bffxqBBgyr1USgUFsdJRJZjgkEkIQ8PD0RGRta4f/v27aFSqSCTyRAeHl5ln5YtW2L//v147rnnjG379++vdsyoqCi4ublh586dGDNmTKX9rq6uACr+4r8lKCgIjRo1wvnz5zFixIgqx42JicHatWtRVlZmTGLuFUdV0tPTodPp8P7778PJqWIJ2BdffFGpn06nQ3p6Oh566CEAwJkzZ3Dz5k20aNECQMX7dubMGbPeayKqXUwwiGwoNjYWXbt2xVNPPYX58+cjOjoaly9fxvfff4+nnnoKHTt2xKuvvopRo0ahY8eOePjhh/HZZ5/hxIkTaNq0aZVjKhQKTJ8+HdOmTYOrqyu6d++Oq1ev4sSJE4iPj0dgYCDc3Nywbds2NG7cGAqFAj4+PkhMTMSkSZPg7e2N/v37Q61WIz09Hfn5+Zg8eTKGDx+OWbNmIT4+Hm+++SYuXLiA//73v2a93mbNmkGn02HJkiV44okn8Ntvv2H58uWV+rm4uGDixIn48MMP4eLigldeeQVdunQxJhyzZ8/GgAEDEBoaisGDB8PJyQlHjx7FsWPH8M4775j/gyAiyfEsEiIbEgQB33//Pf71r3/hhRdeQPPmzTFs2DBcuHDBeNbH0KFDMXv2bEyfPh0dOnRAVlYWXn755XuO+9Zbb2HKlCmYPXs2WrZsiaFDhyIvLw9AxfqGDz/8EB9//DFCQkIwcOBAAMCYMWOwcuVKpKSkoE2bNujRowdSUlKMp7V6enriu+++w8mTJ9GuXTvMmjUL8+fPN+v1Pvjgg1i4cCHmz5+P1q1b47PPPkNycnKlfu7u7pg+fTqGDx+Orl27ws3NDRs2bDDuj4uLw9atW7Fjxw506tQJXbp0wcKFCxEWFmZWPERkPYIoxcQqERER0R1YwSAiIiLJMcEgIiIiyTHBICIiIskxwSAiIiLJMcEgIiIiyTHBICIiIskxwSAiIiLJMcEgIiIiyTHBICIiIskxwSAiIiLJMcEgIiIiyf1/HbJgo4MsIcQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.967606</td>\n",
       "      <td>0.923596</td>\n",
       "      <td>0.921525</td>\n",
       "      <td>0.922559</td>\n",
       "      <td>0.979228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.994836</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>0.991037</td>\n",
       "      <td>0.992944</td>\n",
       "      <td>0.994822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.988263</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.970852</td>\n",
       "      <td>0.971942</td>\n",
       "      <td>0.992285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.971362</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.938731</td>\n",
       "      <td>0.933624</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955267</td>\n",
       "      <td>0.955536</td>\n",
       "      <td>0.955015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961033</td>\n",
       "      <td>0.961033</td>\n",
       "      <td>0.961033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960985</td>\n",
       "      <td>0.960952</td>\n",
       "      <td>0.961033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.967606  0.923596   0.921525  0.922559     0.979228\n",
       "1            SB  0.994836  0.994859   0.991037  0.992944     0.994822\n",
       "2            SR  0.988263  0.973034   0.970852  0.971942     0.992285\n",
       "3          GSVT  0.971362  0.928571   0.938731  0.933624     0.983213\n",
       "4     macro avg       NaN  0.955267   0.955536  0.955015          NaN\n",
       "5     micro avg       NaN  0.961033   0.961033  0.961033          NaN\n",
       "6  weighted avg       NaN  0.960985   0.960952  0.961033          NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"./Result/Blending_RF.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
