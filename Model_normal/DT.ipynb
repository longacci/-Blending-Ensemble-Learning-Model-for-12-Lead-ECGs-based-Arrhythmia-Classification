{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>782.0</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>252.222222</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>87.777778</td>\n",
       "      <td>10339.061728</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>4315.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6555.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>697.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>594.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>1360.782222</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>420.090909</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1504.888889</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>569.437500</td>\n",
       "      <td>136.444444</td>\n",
       "      <td>43.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>615.733333</td>\n",
       "      <td>596.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.500000</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1746.285714</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>4722.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>654.428571</td>\n",
       "      <td>648.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>2686.204082</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3602.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>101.142857</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>-10.750000</td>\n",
       "      <td>7259.937500</td>\n",
       "      <td>88.222222</td>\n",
       "      <td>202.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1041.250000</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2            3       4           5      6         7         8  \\\n",
       "0     0.0  10.0   950.000000  1074.0  274.986868  782.0 -0.319753 -1.432466   \n",
       "1     0.0  17.0   574.500000   582.0  104.913059  378.0  0.158313 -0.696295   \n",
       "2     3.0  16.0   593.600000   594.0    4.687572   18.0  0.396421 -0.312612   \n",
       "3     3.0  23.0   420.090909   420.0    3.591772   12.0 -0.021014 -0.856142   \n",
       "4     1.0   9.0  1068.750000  1075.0   25.118469   76.0 -0.276816 -1.271399   \n",
       "...   ...   ...          ...     ...         ...    ...       ...       ...   \n",
       "8511  3.0  16.0   615.733333   596.0   51.114860  152.0  2.153820  2.645687   \n",
       "8512  1.0   9.0  1091.500000  1093.0    5.894913   18.0 -0.311206 -1.184514   \n",
       "8513  2.0  15.0   654.428571   648.0  107.653355  458.0  0.475616  0.784000   \n",
       "8514  1.0   9.0  1075.000000  1083.0   24.535688   66.0 -0.263431 -1.567800   \n",
       "8515  1.0   9.0  1041.250000  1040.0    8.242421   22.0  0.214800 -1.575835   \n",
       "\n",
       "               9        10  ...       204         205        206        207  \\\n",
       "0     325.821586  1.000000  ...  1.000000  172.000000  10.000000   9.000000   \n",
       "1     336.569414  1.000000  ...  0.882353  -15.000000  15.000000   4.000000   \n",
       "2      94.909877  1.000000  ...  1.000000   -4.000000  16.000000  15.000000   \n",
       "3     254.059787  0.826087  ...  0.739130   -9.000000   6.000000   4.000000   \n",
       "4     461.130814  1.000000  ...  1.000000    2.000000   9.000000   8.000000   \n",
       "...          ...       ...  ...       ...         ...        ...        ...   \n",
       "8511  365.256750  1.000000  ...  0.003757    0.022262   0.003757   0.003757   \n",
       "8512  358.414529  1.000000  ...  0.888889   -3.000000   9.000000   8.000000   \n",
       "8513  180.045117  1.000000  ...  1.000000   -4.000000  15.000000  14.000000   \n",
       "8514  251.455499  1.000000  ...  1.000000   14.000000   9.000000   8.000000   \n",
       "8515  505.203302  1.000000  ...  1.000000    0.000000   9.000000   8.000000   \n",
       "\n",
       "             208           209        210           211         212  \\\n",
       "0     252.222222  10656.395062  87.777778  10339.061728  135.800000   \n",
       "1     158.000000   3944.000000  73.000000   6555.000000   -1.066667   \n",
       "2     122.400000   2058.773333  12.533333   1360.782222   95.500000   \n",
       "3      40.666667   1120.888889   5.333333   1504.888889   12.000000   \n",
       "4     122.000000    671.000000  19.750000    569.437500  136.444444   \n",
       "...          ...           ...        ...           ...         ...   \n",
       "8511    0.044242      0.044242   0.043021      0.043021    0.037385   \n",
       "8512   81.428571   1294.530612 -40.000000   1746.285714  155.333333   \n",
       "8513   77.142857   2213.551020  -1.714286   2686.204082  104.000000   \n",
       "8514  101.142857   4933.551020 -10.750000   7259.937500   88.222222   \n",
       "8515  102.000000    350.000000 -20.000000    588.000000  150.000000   \n",
       "\n",
       "              213  \n",
       "0     4315.560000  \n",
       "1      697.528889  \n",
       "2       68.750000  \n",
       "3     1464.000000  \n",
       "4       43.358025  \n",
       "...           ...  \n",
       "8511     0.037385  \n",
       "8512  4722.666667  \n",
       "8513  3602.666667  \n",
       "8514   202.172840  \n",
       "8515     0.000000  \n",
       "\n",
       "[8516 rows x 213 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_frequency.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>710.769231</td>\n",
       "      <td>628.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3140.437500</td>\n",
       "      <td>127.600000</td>\n",
       "      <td>1041.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>968.666667</td>\n",
       "      <td>894.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>5249.000000</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>8081.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>8070.530612</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1078.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>757.500000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>7081.416667</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>264.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>413.909091</td>\n",
       "      <td>409.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>832.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>342.857143</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>205.142857</td>\n",
       "      <td>11207.836735</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2281.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>14282.775510</td>\n",
       "      <td>169.142857</td>\n",
       "      <td>46.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>361.489796</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>2186.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.285714</td>\n",
       "      <td>996.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>-45.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2       3           4      5         6          7  \\\n",
       "0     0.0  14.0   710.769231   628.0  153.204817  556.0  0.996355   0.207174   \n",
       "1     0.0  10.0   968.666667   894.0  266.399867  932.0  0.979352   0.388359   \n",
       "2     0.0  11.0   797.000000   780.0  251.329664  794.0  0.260470  -1.002325   \n",
       "3     2.0  13.0   757.500000   755.0    8.986100   26.0  0.048579  -1.449012   \n",
       "4     0.0  23.0   413.909091   409.0   82.344017  426.0  3.023659  10.404884   \n",
       "...   ...   ...          ...     ...         ...    ...       ...        ...   \n",
       "2125  1.0   9.0  1071.250000  1062.0   36.509417  118.0  1.263183   0.543003   \n",
       "2126  1.0   8.0  1196.000000  1202.0   33.839959  102.0 -0.454057  -1.036905   \n",
       "2127  3.0  16.0   595.600000   590.0   23.734082   82.0  0.371174  -0.657132   \n",
       "2128  1.0   8.0  1080.285714   996.0  180.470587  448.0  0.587475  -1.363827   \n",
       "2129  3.0  25.0   391.250000   390.0    2.569857    8.0  0.605786  -0.869886   \n",
       "\n",
       "               8         9  ...       203        204   205   206         207  \\\n",
       "0     459.037295  1.000000  ...  0.928571 -10.000000  10.0   9.0  146.000000   \n",
       "1     398.464564  1.000000  ...  0.600000  64.000000   7.0   7.0  140.500000   \n",
       "2     340.802438  1.000000  ...  1.000000  26.000000   9.0   7.0  154.285714   \n",
       "3     412.324324  1.000000  ...  1.000000  -4.000000  12.0  12.0  108.500000   \n",
       "4     168.041577  0.956522  ...  0.083333   0.022262  11.0  12.0    0.044242   \n",
       "...          ...       ...  ...       ...        ...   ...   ...         ...   \n",
       "2125  364.303573  0.888889  ...  0.777778   0.000000   9.0   8.0  342.857143   \n",
       "2126  181.876516  1.000000  ...  1.000000 -26.000000   8.0   7.0  137.666667   \n",
       "2127  137.696567  1.000000  ...  1.000000  -8.000000  16.0  14.0  102.714286   \n",
       "2128  561.988537  1.000000  ...  1.000000  18.000000   8.0   5.0   62.400000   \n",
       "2129  654.123072  0.400000  ...  0.240000   4.000000   0.0   0.0    0.044242   \n",
       "\n",
       "               208         209           210         211          212  \n",
       "0       729.000000   78.250000   3140.437500  127.600000  1041.440000  \n",
       "1     15314.750000  -27.000000   5249.000000  112.285714  8081.632653  \n",
       "2      1944.489796   18.571429   8070.530612  131.111111  1078.320988  \n",
       "3      6122.750000   46.500000   7081.416667  121.833333   264.305556  \n",
       "4         0.044242  -50.000000      0.000000   45.818182   832.330579  \n",
       "...            ...         ...           ...         ...          ...  \n",
       "2125   2843.265306  205.142857  11207.836735   96.000000  2281.142857  \n",
       "2126    228.555556   87.714286  14282.775510  169.142857    46.693878  \n",
       "2127   1270.061224    7.285714    361.489796   90.400000  2186.240000  \n",
       "2128     51.840000  -45.200000      0.960000  101.000000  5002.000000  \n",
       "2129      0.044242    0.043021      0.043021    0.037385     0.037385  \n",
       "\n",
       "[2130 rows x 213 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_frequency.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.915, test=0.912) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.902, test=0.903) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.926, test=0.905) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.778, test=0.771) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.822, test=0.818) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.753, test=0.750) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=(train=0.885, test=0.884) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=(train=0.901, test=0.901) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=(train=0.891, test=0.872) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=(train=0.617, test=0.616) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=(train=0.699, test=0.688) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=(train=0.628, test=0.628) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.925, test=0.918) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.918, test=0.908) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.923, test=0.896) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.625, test=0.628) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.772, test=0.767) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.810, test=0.805) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=(train=0.914, test=0.909) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=(train=0.851, test=0.840) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=(train=0.928, test=0.910) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=(train=0.705, test=0.698) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=(train=0.623, test=0.610) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=(train=0.677, test=0.662) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=6, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=6, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=6, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=6, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=6, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=6, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.930, test=0.912) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.935, test=0.918) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.936, test=0.900) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.751, test=0.744) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.853, test=0.850) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.899, test=0.881) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=6, max_features=log2, splitter=best;, score=(train=0.915, test=0.907) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=6, max_features=log2, splitter=best;, score=(train=0.930, test=0.911) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=6, max_features=log2, splitter=best;, score=(train=0.935, test=0.907) total time=   0.0s\n",
      "[CV 1/3] END criterion=gini, max_depth=6, max_features=log2, splitter=random;, score=(train=0.744, test=0.748) total time=   0.0s\n",
      "[CV 2/3] END criterion=gini, max_depth=6, max_features=log2, splitter=random;, score=(train=0.796, test=0.784) total time=   0.0s\n",
      "[CV 3/3] END criterion=gini, max_depth=6, max_features=log2, splitter=random;, score=(train=0.735, test=0.719) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.916, test=0.910) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.888, test=0.876) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.914, test=0.896) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.696, test=0.698) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.791, test=0.777) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.731, test=0.727) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=(train=0.905, test=0.903) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=(train=0.868, test=0.865) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=(train=0.883, test=0.871) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=(train=0.574, test=0.571) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=(train=0.664, test=0.655) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=(train=0.744, test=0.761) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.920, test=0.915) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.921, test=0.915) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.933, test=0.905) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.863, test=0.864) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.762, test=0.755) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.821, test=0.816) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=(train=0.913, test=0.903) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=(train=0.919, test=0.913) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=(train=0.923, test=0.903) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=(train=0.665, test=0.668) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=(train=0.799, test=0.804) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=(train=0.656, test=0.653) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=6, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=6, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=6, max_features=auto, splitter=best;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=6, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=6, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=6, max_features=auto, splitter=random;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.935, test=0.923) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.936, test=0.920) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.943, test=0.909) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.842, test=0.836) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.826, test=0.814) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.831, test=0.810) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=6, max_features=log2, splitter=best;, score=(train=0.910, test=0.901) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=6, max_features=log2, splitter=best;, score=(train=0.931, test=0.918) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=6, max_features=log2, splitter=best;, score=(train=0.937, test=0.907) total time=   0.0s\n",
      "[CV 1/3] END criterion=entropy, max_depth=6, max_features=log2, splitter=random;, score=(train=0.655, test=0.666) total time=   0.0s\n",
      "[CV 2/3] END criterion=entropy, max_depth=6, max_features=log2, splitter=random;, score=(train=0.787, test=0.789) total time=   0.0s\n",
      "[CV 3/3] END criterion=entropy, max_depth=6, max_features=log2, splitter=random;, score=(train=0.758, test=0.748) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:542: FitFailedWarning: \n",
      "36 fits failed out of a total of 108.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.9066461  0.7795879  0.88574288 0.64396242\n",
      "        nan        nan 0.90734954 0.73333394 0.88633437 0.65641209\n",
      "        nan        nan 0.91016793 0.82515924 0.90840758 0.75046603\n",
      "        nan        nan 0.89372968 0.73414668 0.87940245 0.66217691\n",
      "        nan        nan 0.9119297  0.81164922 0.90676335 0.7083073\n",
      "        nan        nan 0.91756594 0.82010216 0.90887723 0.7345014 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.91416087 0.78429023 0.89267269 0.64778183\n",
      "        nan        nan 0.92191165 0.73590452 0.89777887 0.66821227\n",
      "        nan        nan 0.93365416 0.83413194 0.92643211 0.75804505\n",
      "        nan        nan 0.9060587  0.73949086 0.88521622 0.6605752\n",
      "        nan        nan 0.92478815 0.81540595 0.91838862 0.70661406\n",
      "        nan        nan 0.93770521 0.83296157 0.92607967 0.73338275]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = DecisionTreeClassifier()\n",
    "params = {\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_depth': [4,5,6],\n",
    "    'splitter':['best', 'random'],\n",
    "    'max_features':['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(x_test)\n",
    "result_train = grid_model.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result_train).to_csv(\"./Result/proba_dt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 6,\n",
       " 'max_features': 'sqrt',\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9175659376434298"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    accuracy_overall = accuracy_score(y, y_pred)\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    result.append(['overall',accuracy_overall,None,None,None,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.940376</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.885922</td>\n",
       "      <td>0.851809</td>\n",
       "      <td>0.972107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.986854</td>\n",
       "      <td>0.974293</td>\n",
       "      <td>0.989556</td>\n",
       "      <td>0.981865</td>\n",
       "      <td>0.994083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.970423</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>0.906383</td>\n",
       "      <td>0.931148</td>\n",
       "      <td>0.973887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.959624</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.890041</td>\n",
       "      <td>0.908898</td>\n",
       "      <td>0.968225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.918430</td>\n",
       "      <td>0.917976</td>\n",
       "      <td>0.920098</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928638</td>\n",
       "      <td>0.928638</td>\n",
       "      <td>0.928638</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928271</td>\n",
       "      <td>0.928944</td>\n",
       "      <td>0.928638</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>overall</td>\n",
       "      <td>0.928638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.940376  0.820225   0.885922  0.851809     0.972107\n",
       "1            SB  0.986854  0.974293   0.989556  0.981865     0.994083\n",
       "2            SR  0.970423  0.957303   0.906383  0.931148     0.973887\n",
       "3          GSVT  0.959624  0.928571   0.890041  0.908898     0.968225\n",
       "4     macro avg       NaN  0.918430   0.917976  0.920098          NaN\n",
       "5     micro avg       NaN  0.928638   0.928638  0.928638          NaN\n",
       "6  weighted avg       NaN  0.928271   0.928944  0.928638          NaN\n",
       "7       overall  0.928638       NaN        NaN       NaN          NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"./Result/DT.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testdatasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
