{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>274.986868</td>\n",
       "      <td>782.0</td>\n",
       "      <td>-0.319753</td>\n",
       "      <td>-1.432466</td>\n",
       "      <td>325.821586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>252.222222</td>\n",
       "      <td>10656.395062</td>\n",
       "      <td>87.777778</td>\n",
       "      <td>10339.061728</td>\n",
       "      <td>135.800000</td>\n",
       "      <td>4315.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>574.500000</td>\n",
       "      <td>582.0</td>\n",
       "      <td>104.913059</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>-0.696295</td>\n",
       "      <td>336.569414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>3944.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>6555.000000</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>697.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>593.600000</td>\n",
       "      <td>594.0</td>\n",
       "      <td>4.687572</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.396421</td>\n",
       "      <td>-0.312612</td>\n",
       "      <td>94.909877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>122.400000</td>\n",
       "      <td>2058.773333</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>1360.782222</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>420.090909</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.591772</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.856142</td>\n",
       "      <td>254.059787</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>1120.888889</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1504.888889</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1068.750000</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>25.118469</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.276816</td>\n",
       "      <td>-1.271399</td>\n",
       "      <td>461.130814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>671.000000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>569.437500</td>\n",
       "      <td>136.444444</td>\n",
       "      <td>43.358025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>615.733333</td>\n",
       "      <td>596.0</td>\n",
       "      <td>51.114860</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.153820</td>\n",
       "      <td>2.645687</td>\n",
       "      <td>365.256750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1091.500000</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>5.894913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>-1.184514</td>\n",
       "      <td>358.414529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>1294.530612</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>1746.285714</td>\n",
       "      <td>155.333333</td>\n",
       "      <td>4722.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>654.428571</td>\n",
       "      <td>648.0</td>\n",
       "      <td>107.653355</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>180.045117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>2213.551020</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>2686.204082</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3602.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>24.535688</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.263431</td>\n",
       "      <td>-1.567800</td>\n",
       "      <td>251.455499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>101.142857</td>\n",
       "      <td>4933.551020</td>\n",
       "      <td>-10.750000</td>\n",
       "      <td>7259.937500</td>\n",
       "      <td>88.222222</td>\n",
       "      <td>202.172840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1041.250000</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>8.242421</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>-1.575835</td>\n",
       "      <td>505.203302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1     2            3       4           5      6         7         8  \\\n",
       "0     0.0  10.0   950.000000  1074.0  274.986868  782.0 -0.319753 -1.432466   \n",
       "1     0.0  17.0   574.500000   582.0  104.913059  378.0  0.158313 -0.696295   \n",
       "2     3.0  16.0   593.600000   594.0    4.687572   18.0  0.396421 -0.312612   \n",
       "3     3.0  23.0   420.090909   420.0    3.591772   12.0 -0.021014 -0.856142   \n",
       "4     1.0   9.0  1068.750000  1075.0   25.118469   76.0 -0.276816 -1.271399   \n",
       "...   ...   ...          ...     ...         ...    ...       ...       ...   \n",
       "8511  3.0  16.0   615.733333   596.0   51.114860  152.0  2.153820  2.645687   \n",
       "8512  1.0   9.0  1091.500000  1093.0    5.894913   18.0 -0.311206 -1.184514   \n",
       "8513  2.0  15.0   654.428571   648.0  107.653355  458.0  0.475616  0.784000   \n",
       "8514  1.0   9.0  1075.000000  1083.0   24.535688   66.0 -0.263431 -1.567800   \n",
       "8515  1.0   9.0  1041.250000  1040.0    8.242421   22.0  0.214800 -1.575835   \n",
       "\n",
       "               9        10  ...       204         205        206        207  \\\n",
       "0     325.821586  1.000000  ...  1.000000  172.000000  10.000000   9.000000   \n",
       "1     336.569414  1.000000  ...  0.882353  -15.000000  15.000000   4.000000   \n",
       "2      94.909877  1.000000  ...  1.000000   -4.000000  16.000000  15.000000   \n",
       "3     254.059787  0.826087  ...  0.739130   -9.000000   6.000000   4.000000   \n",
       "4     461.130814  1.000000  ...  1.000000    2.000000   9.000000   8.000000   \n",
       "...          ...       ...  ...       ...         ...        ...        ...   \n",
       "8511  365.256750  1.000000  ...  0.003757    0.022262   0.003757   0.003757   \n",
       "8512  358.414529  1.000000  ...  0.888889   -3.000000   9.000000   8.000000   \n",
       "8513  180.045117  1.000000  ...  1.000000   -4.000000  15.000000  14.000000   \n",
       "8514  251.455499  1.000000  ...  1.000000   14.000000   9.000000   8.000000   \n",
       "8515  505.203302  1.000000  ...  1.000000    0.000000   9.000000   8.000000   \n",
       "\n",
       "             208           209        210           211         212  \\\n",
       "0     252.222222  10656.395062  87.777778  10339.061728  135.800000   \n",
       "1     158.000000   3944.000000  73.000000   6555.000000   -1.066667   \n",
       "2     122.400000   2058.773333  12.533333   1360.782222   95.500000   \n",
       "3      40.666667   1120.888889   5.333333   1504.888889   12.000000   \n",
       "4     122.000000    671.000000  19.750000    569.437500  136.444444   \n",
       "...          ...           ...        ...           ...         ...   \n",
       "8511    0.044242      0.044242   0.043021      0.043021    0.037385   \n",
       "8512   81.428571   1294.530612 -40.000000   1746.285714  155.333333   \n",
       "8513   77.142857   2213.551020  -1.714286   2686.204082  104.000000   \n",
       "8514  101.142857   4933.551020 -10.750000   7259.937500   88.222222   \n",
       "8515  102.000000    350.000000 -20.000000    588.000000  150.000000   \n",
       "\n",
       "              213  \n",
       "0     4315.560000  \n",
       "1      697.528889  \n",
       "2       68.750000  \n",
       "3     1464.000000  \n",
       "4       43.358025  \n",
       "...           ...  \n",
       "8511     0.037385  \n",
       "8512  4722.666667  \n",
       "8513  3602.666667  \n",
       "8514   202.172840  \n",
       "8515     0.000000  \n",
       "\n",
       "[8516 rows x 213 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data_train_frequency.csv\")\n",
    "df_train.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:].values\n",
    "y_train = df_train.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "x_train = scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>710.769231</td>\n",
       "      <td>628.0</td>\n",
       "      <td>153.204817</td>\n",
       "      <td>556.0</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.207174</td>\n",
       "      <td>459.037295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3140.437500</td>\n",
       "      <td>127.600000</td>\n",
       "      <td>1041.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>968.666667</td>\n",
       "      <td>894.0</td>\n",
       "      <td>266.399867</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.979352</td>\n",
       "      <td>0.388359</td>\n",
       "      <td>398.464564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>15314.750000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>5249.000000</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>8081.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>780.0</td>\n",
       "      <td>251.329664</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.260470</td>\n",
       "      <td>-1.002325</td>\n",
       "      <td>340.802438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>1944.489796</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>8070.530612</td>\n",
       "      <td>131.111111</td>\n",
       "      <td>1078.320988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>757.500000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>8.986100</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.048579</td>\n",
       "      <td>-1.449012</td>\n",
       "      <td>412.324324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>7081.416667</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>264.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>413.909091</td>\n",
       "      <td>409.0</td>\n",
       "      <td>82.344017</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.023659</td>\n",
       "      <td>10.404884</td>\n",
       "      <td>168.041577</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>832.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1071.250000</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>36.509417</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.263183</td>\n",
       "      <td>0.543003</td>\n",
       "      <td>364.303573</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>342.857143</td>\n",
       "      <td>2843.265306</td>\n",
       "      <td>205.142857</td>\n",
       "      <td>11207.836735</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2281.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>33.839959</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.454057</td>\n",
       "      <td>-1.036905</td>\n",
       "      <td>181.876516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.666667</td>\n",
       "      <td>228.555556</td>\n",
       "      <td>87.714286</td>\n",
       "      <td>14282.775510</td>\n",
       "      <td>169.142857</td>\n",
       "      <td>46.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>595.600000</td>\n",
       "      <td>590.0</td>\n",
       "      <td>23.734082</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.371174</td>\n",
       "      <td>-0.657132</td>\n",
       "      <td>137.696567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>102.714286</td>\n",
       "      <td>1270.061224</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>361.489796</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>2186.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1080.285714</td>\n",
       "      <td>996.0</td>\n",
       "      <td>180.470587</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.587475</td>\n",
       "      <td>-1.363827</td>\n",
       "      <td>561.988537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>51.840000</td>\n",
       "      <td>-45.200000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>390.0</td>\n",
       "      <td>2.569857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.605786</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>654.123072</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2130 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1            2       3           4      5         6          7  \\\n",
       "0     0.0  14.0   710.769231   628.0  153.204817  556.0  0.996355   0.207174   \n",
       "1     0.0  10.0   968.666667   894.0  266.399867  932.0  0.979352   0.388359   \n",
       "2     0.0  11.0   797.000000   780.0  251.329664  794.0  0.260470  -1.002325   \n",
       "3     2.0  13.0   757.500000   755.0    8.986100   26.0  0.048579  -1.449012   \n",
       "4     0.0  23.0   413.909091   409.0   82.344017  426.0  3.023659  10.404884   \n",
       "...   ...   ...          ...     ...         ...    ...       ...        ...   \n",
       "2125  1.0   9.0  1071.250000  1062.0   36.509417  118.0  1.263183   0.543003   \n",
       "2126  1.0   8.0  1196.000000  1202.0   33.839959  102.0 -0.454057  -1.036905   \n",
       "2127  3.0  16.0   595.600000   590.0   23.734082   82.0  0.371174  -0.657132   \n",
       "2128  1.0   8.0  1080.285714   996.0  180.470587  448.0  0.587475  -1.363827   \n",
       "2129  3.0  25.0   391.250000   390.0    2.569857    8.0  0.605786  -0.869886   \n",
       "\n",
       "               8         9  ...       203        204   205   206         207  \\\n",
       "0     459.037295  1.000000  ...  0.928571 -10.000000  10.0   9.0  146.000000   \n",
       "1     398.464564  1.000000  ...  0.600000  64.000000   7.0   7.0  140.500000   \n",
       "2     340.802438  1.000000  ...  1.000000  26.000000   9.0   7.0  154.285714   \n",
       "3     412.324324  1.000000  ...  1.000000  -4.000000  12.0  12.0  108.500000   \n",
       "4     168.041577  0.956522  ...  0.083333   0.022262  11.0  12.0    0.044242   \n",
       "...          ...       ...  ...       ...        ...   ...   ...         ...   \n",
       "2125  364.303573  0.888889  ...  0.777778   0.000000   9.0   8.0  342.857143   \n",
       "2126  181.876516  1.000000  ...  1.000000 -26.000000   8.0   7.0  137.666667   \n",
       "2127  137.696567  1.000000  ...  1.000000  -8.000000  16.0  14.0  102.714286   \n",
       "2128  561.988537  1.000000  ...  1.000000  18.000000   8.0   5.0   62.400000   \n",
       "2129  654.123072  0.400000  ...  0.240000   4.000000   0.0   0.0    0.044242   \n",
       "\n",
       "               208         209           210         211          212  \n",
       "0       729.000000   78.250000   3140.437500  127.600000  1041.440000  \n",
       "1     15314.750000  -27.000000   5249.000000  112.285714  8081.632653  \n",
       "2      1944.489796   18.571429   8070.530612  131.111111  1078.320988  \n",
       "3      6122.750000   46.500000   7081.416667  121.833333   264.305556  \n",
       "4         0.044242  -50.000000      0.000000   45.818182   832.330579  \n",
       "...            ...         ...           ...         ...          ...  \n",
       "2125   2843.265306  205.142857  11207.836735   96.000000  2281.142857  \n",
       "2126    228.555556   87.714286  14282.775510  169.142857    46.693878  \n",
       "2127   1270.061224    7.285714    361.489796   90.400000  2186.240000  \n",
       "2128     51.840000  -45.200000      0.960000  101.000000  5002.000000  \n",
       "2129      0.044242    0.043021      0.043021    0.037385     0.037385  \n",
       "\n",
       "[2130 rows x 213 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data_test_frequency.csv\")\n",
    "df_test.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:,1:].values\n",
    "y_test = df_test.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.965) total time=   8.6s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.958) total time=   7.2s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.944) total time=   6.7s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.966) total time=   9.6s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.959) total time=   8.6s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.945) total time=   8.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.966) total time=   9.5s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.959) total time=   9.6s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.944) total time=   9.5s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.966) total time=  10.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.959) total time=  10.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.945) total time=   9.6s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.965) total time=   8.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.961) total time=   8.3s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.945) total time=   7.7s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.965) total time=  11.8s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.961) total time=  11.4s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.946) total time=  11.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.966) total time=  12.4s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.960) total time=  12.9s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.945) total time=  12.9s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.966) total time=  13.3s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.960) total time=  13.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.945) total time=  12.4s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.966) total time=  10.3s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.959) total time=   9.9s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.948) total time=   9.5s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.967) total time=  13.7s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.958) total time=  15.2s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.948) total time=  13.3s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.966) total time=  15.6s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.959) total time=  14.7s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.948) total time=  14.1s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.966) total time=  17.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.958) total time=  18.6s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.949) total time=  19.5s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.967) total time=   7.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.959) total time=   6.9s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.943) total time=   6.7s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.966) total time=  10.9s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.960) total time=   9.8s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.943) total time=   8.2s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.967) total time=  12.7s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.961) total time=  12.3s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.944) total time=  13.5s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.967) total time=  10.8s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.961) total time=  11.7s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.944) total time=  13.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.966) total time=   7.2s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.958) total time=   6.9s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.945) total time=   6.6s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.966) total time=   9.2s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.959) total time=   9.3s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.946) total time=   8.9s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.966) total time=  10.2s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.960) total time=  10.0s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.946) total time=  12.4s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.966) total time=  15.5s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.960) total time=  15.9s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.946) total time=  11.2s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.966) total time=   7.6s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.958) total time=  11.4s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.948) total time=  11.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.966) total time=  12.9s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.958) total time=  12.2s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.949) total time=  10.8s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.966) total time=  13.0s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.958) total time=  11.9s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.948) total time=  10.8s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.966) total time=  12.8s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.958) total time=  11.2s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.948) total time=  10.0s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.966) total time=   3.8s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.958) total time=   3.7s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.945) total time=   3.6s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.966) total time=   5.2s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.958) total time=   5.3s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.945) total time=   4.9s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.966) total time=   5.8s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.958) total time=   5.6s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.944) total time=   5.6s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.966) total time=   6.1s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.958) total time=   5.9s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.944) total time=   5.8s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.964) total time=   3.8s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.960) total time=   4.5s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.945) total time=   4.6s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.965) total time=   5.5s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.959) total time=   6.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.945) total time=   6.4s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.965) total time=   7.3s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.959) total time=   9.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.945) total time=   8.2s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.964) total time=   7.3s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.959) total time=   6.7s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.944) total time=   7.9s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.965) total time=   3.9s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.961) total time=   3.7s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.945) total time=   3.5s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.966) total time=   5.2s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.961) total time=   5.1s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.945) total time=   4.9s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.965) total time=   5.7s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.961) total time=   5.6s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.945) total time=   5.3s\n",
      "[CV 1/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.965) total time=   5.9s\n",
      "[CV 2/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.962) total time=   5.9s\n",
      "[CV 3/3] END gamma=0, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.945) total time=   6.0s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.966) total time=   5.4s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.957) total time=   5.3s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.943) total time=   5.2s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.967) total time=   7.9s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.959) total time=   7.9s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.943) total time=   7.8s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.967) total time=   8.7s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.959) total time=   8.4s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.943) total time=   8.0s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.967) total time=   8.9s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.959) total time=   8.7s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.943) total time=   8.3s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.965) total time=   7.7s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.959) total time=   7.6s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.944) total time=   7.5s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.965) total time=   9.1s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.960) total time=  10.4s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.944) total time=  20.2s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.965) total time=  18.1s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.960) total time=  18.3s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.944) total time=  13.1s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.965) total time=  14.5s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.960) total time=  14.0s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.944) total time=  13.1s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.966) total time=  11.4s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.958) total time=  11.5s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.946) total time=  11.7s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.966) total time=  13.0s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.958) total time=  13.0s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.946) total time=  13.6s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.966) total time=  14.6s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.958) total time=  14.8s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.946) total time=  13.9s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.966) total time=  15.0s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.958) total time=  15.7s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.946) total time=  14.0s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.966) total time=   7.5s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.958) total time=   9.1s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.944) total time=   6.9s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.966) total time=   9.9s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.958) total time=   6.7s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.944) total time=   6.1s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.966) total time=   6.5s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.958) total time=   6.3s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.944) total time=   7.3s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.966) total time=   7.2s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.958) total time=   7.5s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.944) total time=   6.6s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.965) total time=   5.1s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.959) total time=   5.7s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.945) total time=   5.0s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.965) total time=   6.9s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.959) total time=   6.5s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.945) total time=   6.1s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.965) total time=   7.0s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.959) total time=   7.3s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.945) total time=   7.0s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.965) total time=   7.4s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.959) total time=   7.1s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.945) total time=   6.6s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.966) total time=   5.5s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.957) total time=   5.6s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.947) total time=   5.3s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.966) total time=   7.2s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.957) total time=   6.6s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.947) total time=   6.6s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.966) total time=   7.1s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.957) total time=   6.6s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.947) total time=   7.4s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.966) total time=   7.5s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.957) total time=   7.5s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.947) total time=   9.2s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.964) total time=   2.7s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.958) total time=   2.5s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.943) total time=   2.4s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.964) total time=   4.0s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.958) total time=   3.7s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.943) total time=   4.4s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.964) total time=   4.2s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.958) total time=   4.6s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.943) total time=   4.5s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.964) total time=   4.6s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.958) total time=   4.2s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.943) total time=   4.4s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.963) total time=   2.8s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.961) total time=   2.5s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.944) total time=   2.9s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.963) total time=   3.8s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.961) total time=   6.1s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.944) total time=   4.5s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.963) total time=   5.0s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.961) total time=   5.4s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.944) total time=   5.0s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.963) total time=   5.5s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.961) total time=   5.4s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.944) total time=   5.4s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.964) total time=   3.3s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.957) total time=   3.3s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.946) total time=   3.6s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.964) total time=   5.5s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.957) total time=   5.0s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.946) total time=   4.0s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.964) total time=   5.1s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.957) total time=   4.7s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.946) total time=   3.9s\n",
      "[CV 1/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.964) total time=   4.2s\n",
      "[CV 2/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.957) total time=   4.1s\n",
      "[CV 3/3] END gamma=0.05, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.946) total time=   4.1s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.965) total time=   5.4s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.958) total time=   5.3s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.943) total time=   5.2s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.967) total time=   7.7s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.958) total time=   7.7s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.944) total time=   8.1s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.967) total time=   8.2s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.958) total time=   8.2s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.944) total time=   7.6s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.967) total time=   8.3s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.958) total time=   8.3s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.944) total time=   7.9s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.965) total time=   7.5s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.961) total time=   7.5s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.945) total time=   7.1s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.965) total time=   8.8s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.961) total time=   8.9s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.945) total time=   8.2s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.965) total time=   9.0s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.961) total time=   8.9s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.945) total time=   8.4s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.965) total time=   9.1s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.961) total time=   9.2s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.945) total time=   8.8s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.965) total time=   8.4s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.959) total time=   7.6s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.946) total time=   7.1s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.965) total time=   9.1s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.959) total time=   8.8s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.946) total time=   8.5s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.965) total time=   9.3s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.959) total time=   9.1s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.946) total time=   8.9s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.965) total time=   9.4s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.959) total time=   9.1s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.946) total time=   8.9s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.968) total time=   4.2s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.958) total time=   4.2s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.943) total time=   4.0s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.968) total time=   5.3s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.958) total time=   5.3s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.943) total time=   5.1s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.968) total time=   5.7s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.958) total time=   5.7s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.943) total time=   5.5s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.968) total time=   5.9s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.958) total time=   5.9s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.943) total time=   5.7s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.965) total time=   4.7s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.959) total time=   4.5s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.944) total time=   4.4s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.965) total time=   5.9s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.959) total time=   5.5s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.944) total time=   5.6s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.965) total time=   6.2s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.959) total time=   6.1s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.944) total time=   6.0s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.965) total time=   6.3s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.959) total time=   6.4s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.944) total time=   6.1s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.965) total time=   4.7s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.959) total time=   4.6s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.945) total time=   4.5s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.965) total time=   5.8s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.959) total time=   5.7s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.945) total time=   5.6s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.965) total time=   6.3s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.959) total time=   6.3s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.945) total time=   6.0s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.965) total time=   6.4s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.959) total time=   6.3s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.945) total time=   6.1s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.964) total time=   2.4s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.959) total time=   2.9s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.947) total time=   2.4s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.964) total time=   5.1s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.959) total time=   4.7s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.947) total time=   5.5s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.964) total time=   4.9s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.959) total time=   4.5s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.947) total time=   4.7s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.964) total time=   6.1s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.959) total time=   5.1s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=3, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.947) total time=   4.8s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.964) total time=   3.0s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.959) total time=   2.8s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.945) total time=   2.7s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.964) total time=   4.2s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.959) total time=   4.2s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.945) total time=   4.0s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.964) total time=   4.6s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.959) total time=   5.5s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.945) total time=   4.1s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.964) total time=   4.8s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.959) total time=   5.4s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=4, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.945) total time=   4.5s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.962) total time=   2.6s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.956) total time=   2.5s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=500;, score=(train=1.000, test=0.945) total time=   2.5s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.962) total time=   3.6s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.956) total time=   3.7s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=800;, score=(train=1.000, test=0.945) total time=   3.5s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.962) total time=   4.0s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.956) total time=   4.0s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=900;, score=(train=1.000, test=0.945) total time=   3.9s\n",
      "[CV 1/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.962) total time=   4.3s\n",
      "[CV 2/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.956) total time=   4.2s\n",
      "[CV 3/3] END gamma=0.08, learning_rate=0.5, max_depth=5, min_child_weight=1, n_estimators=950;, score=(train=1.000, test=0.945) total time=   4.2s\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = XGBClassifier()\n",
    "# params = {\n",
    "#     'n_estimators': [10,50,100,1000],\n",
    "#     'learning_rate': [0.01,0.1,1,10],\n",
    "#     'max_depth': [3,4,5],\n",
    "#     'min_child_weight':[1],\n",
    "#     'gamma':[0,0.1,0.2],\n",
    "# }\n",
    "# {'gamma': 0,\n",
    "#  'learning_rate': 0.1,\n",
    "#  'max_depth': 4,\n",
    "#  'min_child_weight': 1,\n",
    "#  'n_estimators': 1000}\n",
    "# 0.961\n",
    "params = {\n",
    "    'n_estimators': [500,800 ,900,950],\n",
    "    'learning_rate': [0.05,0.1,0.5],\n",
    "    'max_depth': [3,4,5],\n",
    "    'min_child_weight':[1],\n",
    "    'gamma':[0,0.05, 0.08],\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=5, return_train_score=True,refit=True)\n",
    "grid_model = grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = grid_model.predict(x_test)\n",
    "result_train = grid_model.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result_train).to_csv(\"./Result/proba_xgb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0,\n",
       " 'learning_rate': 0.05,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 950}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9578430090033422"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,f1_score,precision_score,accuracy_score,recall_score,precision_recall_fscore_support\n",
    "def evaluation_test(y,y_pred):\n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    disp = ConfusionMatrixDisplay(cm,display_labels=['AFIB','SB','SR','GSVT'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    n_classes = len(cm)\n",
    "    result = []\n",
    "    accuracy_overall = accuracy_score(y, y_pred)\n",
    "    for c in range(n_classes):\n",
    "        tp = cm[c,c]\n",
    "        fp = sum(cm[:,c]) - cm[c,c]\n",
    "        fn = sum(cm[c,:]) - cm[c,c]\n",
    "        tn = sum(np.delete(sum(cm)-cm[c,:],c))\n",
    "        acc = (tp+tn) / (tp+fn+tn+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        specificity = tn/(tn+fp)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "        if c+1 == 1:\n",
    "            Rhythm = 'AFIB'\n",
    "        elif c+1 == 2:\n",
    "            Rhythm = 'SB'\n",
    "        elif c+1 == 3:\n",
    "            Rhythm = 'SR'\n",
    "        else:\n",
    "            Rhythm = 'GSVT'\n",
    "        result.append([Rhythm,acc,recall,precision,f1_score,specificity])\n",
    "    p_macro,r_macro,f_macro,support_macro = precision_recall_fscore_support(y,y_pred,average='macro')\n",
    "    p_micro,r_micro,f_micro,support_micro = precision_recall_fscore_support(y,y_pred,average='micro')\n",
    "    p_weighted,r_weighted,f_weighted,support_weighted = precision_recall_fscore_support(y,y_pred,average='weighted')\n",
    "    result.append(['macro avg',None,f_macro,p_macro,r_macro,None])\n",
    "    result.append(['micro avg',None,f_micro,p_micro,r_micro,None])\n",
    "    result.append(['weighted avg',None,f_weighted,p_weighted,r_weighted,None])\n",
    "    result.append(['overall',accuracy_overall,None,None,None,None])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhythm Group</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFIB</td>\n",
       "      <td>0.969014</td>\n",
       "      <td>0.934831</td>\n",
       "      <td>0.918322</td>\n",
       "      <td>0.926503</td>\n",
       "      <td>0.978042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.990610</td>\n",
       "      <td>0.989717</td>\n",
       "      <td>0.984655</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.991124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SR</td>\n",
       "      <td>0.989202</td>\n",
       "      <td>0.973034</td>\n",
       "      <td>0.975225</td>\n",
       "      <td>0.974128</td>\n",
       "      <td>0.993472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSVT</td>\n",
       "      <td>0.974178</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.986811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.956893</td>\n",
       "      <td>0.957355</td>\n",
       "      <td>0.956538</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>micro avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961502</td>\n",
       "      <td>0.961502</td>\n",
       "      <td>0.961502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961491</td>\n",
       "      <td>0.961574</td>\n",
       "      <td>0.961502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>overall</td>\n",
       "      <td>0.961502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rhythm Group       ACC  F1-score  Precision    Recall  specificity\n",
       "0          AFIB  0.969014  0.934831   0.918322  0.926503     0.978042\n",
       "1            SB  0.990610  0.989717   0.984655  0.987179     0.991124\n",
       "2            SR  0.989202  0.973034   0.975225  0.974128     0.993472\n",
       "3          GSVT  0.974178  0.928571   0.951220  0.939759     0.986811\n",
       "4     macro avg       NaN  0.956893   0.957355  0.956538          NaN\n",
       "5     micro avg       NaN  0.961502   0.961502  0.961502          NaN\n",
       "6  weighted avg       NaN  0.961491   0.961574  0.961502          NaN\n",
       "7       overall  0.961502       NaN        NaN       NaN          NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test = evaluation_test(y_test,result_test)\n",
    "df_evaluation_test = pd.DataFrame(data=evaluation_test,columns=[\"Rhythm Group\",\"ACC\",\"F1-score\",\"Precision\",\"Recall\",\"specificity\"])\n",
    "df_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation_test.to_csv(\"./Result/XGB.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testdatasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
